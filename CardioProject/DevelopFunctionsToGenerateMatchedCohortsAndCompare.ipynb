{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T12:45:21.109425Z",
     "start_time": "2018-08-08T12:45:16.611981Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir,mkdir,makedirs\n",
    "from os.path import isfile, join, isdir,exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from myplots import roundup, rounddown, find_decimal_fold, percentile_cut_off, rarefaction_calc, rarefaction_plot,draw_correlation_scatter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import cPickle as pickle\n",
    "from Bio.SeqUtils import GC\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy.stats import pearsonr,fisher_exact\n",
    "from skbio.diversity.alpha import shannon, simpson, berger_parker_d\n",
    "\n",
    "from pop_organize import get_sample_data, get_sample_with_dfs\n",
    "from SufficientStatistics.SufficientStatistics import *\n",
    "from MyFunctionsShani import *\n",
    "import math\n",
    "from myplots import roundup, rounddown, find_decimal_fold\n",
    "from skbio.stats.distance import mantel\n",
    "from scipy.spatial.distance import braycurtis, pdist, euclidean\n",
    "\n",
    "\n",
    "from GeneralFeaturePhenotypeInteractions.Feature_phenotype_functions import * \n",
    "from TCR_microbiome_interactions.TCR_microbiome_interactions_functions import *\n",
    "from TCR_microbiome_interactions.TCR_microbiome_interactions_functions2 import *\n",
    "from SampleLists.SampleFileFunctions import *\n",
    "from PhenotypicData.PhenotypeGenerationFunctions import *\n",
    "from CardioProject.CardioFunctions import *\n",
    "from PredictionPipeline.PredictionFunctions import *\n",
    "from TCR_feature_generation.SubsamplingFunctions import *\n",
    "\n",
    "import os\n",
    "from Utils import cacheOnDisk\n",
    "from SegalQueue.qp import qp,fakeqp\n",
    "from addloglevels import sethandlers\n",
    "\n",
    "#ML imports:\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import GroupKFold,StratifiedKFold, KFold\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from sklearn import metrics, preprocessing\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel,SelectKBest,chi2,mutual_info_classif,f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "MyPath='/net/mraid08/export/genie/Lab/Personal/ShaniBAF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T12:45:24.429730Z",
     "start_time": "2018-08-08T12:45:24.418343Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "cdate=str(time.strftime(\"%d%m%Y\"))\n",
    "cdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plan"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function 1:\n",
    "2. subsample PNP and cardio, compare phenotypes\n",
    "3. produce common TCRdfs to use with permanova and mantel\n",
    "4. run permanova/mantel pipeline to define which phenotypes are in interaction with TCRdf structure\n",
    "Function 2: \n",
    "5. generate matched cohorts based on phenotypes described in 4\n",
    "6. compare phenotypes to validate\n",
    "\n",
    "function 3: when the matched cohorts are good:\n",
    "7. generate a folder with all samples\n",
    "8. compare TCR features\n",
    "9. generate TCRdf\n",
    "10. compare sharing rates between PNP and cardio\n",
    "11. try to seperate by PCA on 10perc binary TCR\n",
    "12. find unique sequences per cohort and their identity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function 1: subsampling, generate TCRdfs and run permanova/mantel"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function testPhenotypeAffectsOnsubsampledCohorts was copied to subsamplingFunction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run for ss=12500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-17T10:47:14.460248Z",
     "start_time": "2018-07-17T10:32:48.670354Z"
    }
   },
   "outputs": [],
   "source": [
    "ss=12500\n",
    "repeat=1\n",
    "ssPNP=False #True/False. subsample only if not exist\n",
    "ssCardio=False #True/False. subsample only if not exist\n",
    "genTCRdfPNP=False #True/False. \n",
    "genTCRdfCardio=False #True/False. \n",
    "\n",
    "\n",
    "testPhenotypeAffectsOnsubsampledCohorts(ss,repeat,ssPNP,ssCardio,genTCRdfPNP,genTCRdfCardio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function 2: generate matched cohorts and compare phenotypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## improve matching function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-31T08:53:17.564262Z",
     "start_time": "2018-07-31T08:53:17.555774Z"
    }
   },
   "source": [
    "function findClosestSample was copied to subsamplingFunction.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate well-matched cohorts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### prepare phenotype DF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-19T13:13:41.159240Z",
     "start_time": "2018-07-19T13:13:40.207893Z"
    }
   },
   "outputs": [],
   "source": [
    "# get full phenotype DFs for PNP and Cardio:\n",
    "f1='%s/TCR_real_data/NewPhenotypicData/PNP530_phen_new_dummies.xlsx' %MyPath\n",
    "PNP530_phen_new_dummies=pd.read_excel(f1).set_index('BD')\n",
    "\n",
    "f2='%s/TCR_real_data/CardioSamples/phenotypicData/Cardio126_phen_new_dummies.xlsx' %MyPath\n",
    "Cardio126_phen_new_dummies=pd.read_excel(f2).set_index('BD')\n",
    "\n",
    "#filter for ss12500 samples and save:\n",
    "folder='%s/TCR_real_data/PNP530_SubSampled12500data_rep1/SamplesForAnalysis_corrected' %MyPath\n",
    "PNP530ss12500sampleList=gen_sampleList_from_Folder(folder,toSaveName=None)\n",
    "\n",
    "PNP530ss12500_phen_new_dummies=PNP530_phen_new_dummies.loc[PNP530ss12500sampleList,:]\n",
    "\n",
    "f3='%s/TCR_real_data/NewPhenotypicData/PNP530ss12500_phen_new_dummies.xlsx' %MyPath\n",
    "PNP530ss12500_phen_new_dummies.to_excel(f3)\n",
    "\n",
    "\n",
    "folder='%s/TCR_real_data/CardioSamples/Cardio126_SubSampled12500data_rep1/SamplesForAnalysis_corrected' %MyPath\n",
    "Cardio126ss12500sampleList=gen_sampleList_from_Folder(folder,toSaveName=None)\n",
    "\n",
    "Cardio126ss12500_phen_new_dummies=Cardio126_phen_new_dummies.loc[Cardio126ss12500sampleList,:]\n",
    "\n",
    "f4='%s/TCR_real_data/CardioSamples/phenotypicData/Cardio126ss12500_phen_new_dummies.xlsx' %MyPath\n",
    "Cardio126ss12500_phen_new_dummies.to_excel(f4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run matching function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-02T15:28:25.983479Z",
     "start_time": "2018-08-02T15:28:16.469288Z"
    }
   },
   "outputs": [],
   "source": [
    "f3='%s/TCR_real_data/NewPhenotypicData/PNP530ss12500_phen_new_dummies.xlsx' %MyPath\n",
    "PNP530ss12500_phen_new_dummies=pd.read_excel(f3).set_index('BD')\n",
    "\n",
    "f4='%s/TCR_real_data/CardioSamples/phenotypicData/Cardio126ss12500_phen_new_dummies.xlsx' %MyPath\n",
    "Cardio126ss12500_phen_new_dummies=pd.read_excel(f4).set_index('BD')\n",
    "\n",
    "phenotypeList=[('Gender_Male','identity',None,True),('Age','delta',9,True),('Smoking_Past','identity',None,True),('Smoking_Yes','identity',None,True),\n",
    "               ('BMI','delta',4,False),('eGFR_CKD-EPI_new','delta',None,False),('WBC','delta',3,False)]\n",
    "columnsToUse=[x[0] for x in phenotypeList]\n",
    "restrictedPhenotypes=[x[0] for x in phenotypeList if x[3]==True]\n",
    "print restrictedPhenotypes\n",
    "\n",
    "cohort1phenotypeDF=Cardio126ss12500_phen_new_dummies\n",
    "cohort1name='Cardio126ss12500'\n",
    "cohort2phenotypeDF=PNP530ss12500_phen_new_dummies\n",
    "cohort2name='PNP530ss12500'\n",
    "\n",
    "folderToSaveLists='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss12500rep1' %MyPath\n",
    "random_state=5\n",
    "               \n",
    "matchedCardio12500samples,matchedPNP12500samples=gen_matched_cohorts_by_phenotypes(cohort1phenotypeDF,cohort1name,cohort2phenotypeDF,cohort2name, \n",
    "                                      phenotypeList, columnsToUse,restrictedPhenotypes,folderToSaveLists,random_state)\n",
    "                \n",
    "#phenotypeList is a list of tuples, in each tuple the first item is the phenotype name (string)the second is the conditionType-'identity' or 'delta',\n",
    "#the third is the delta (int) or None and the forth is isStopingCrit (True/False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function 3: generate a folder with all samples, compare features, seperate by PCA and find unique sequences  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "function compareTCRforMatchedCohorts was copied to subsamplingFunction.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T12:19:27.137708Z",
     "start_time": "2018-08-08T12:19:25.557523Z"
    }
   },
   "outputs": [],
   "source": [
    "def compareTCRforMatchedCohorts(ss,repeat,PNPmatchedSampleList,CardioMatchedSampleList,\n",
    "                                copySamples,compareFeatures,compareSharing, genSepTCRdf,nSharedMin,\n",
    "                                delFolderFirst=False,genOrigComTCRdf=False,genComTCRdf=True,n_comp=None,percSharedCom=10,\n",
    "                                identityColumnForPie='Pathology_McPAS'):\n",
    "    \n",
    "    from shutil import copyfile,rmtree\n",
    "    \n",
    "    datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss%srep%s' %(MyPath,ss,repeat)\n",
    "    FeatureMeanSummary_all_dataSets=[]\n",
    "    \n",
    "    #(1) generate a folder with all matched samples:\n",
    "    \n",
    "    matchedSampleFolder='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "    if copySamples:\n",
    "        if delFolderFirst:\n",
    "            rmtree(matchedSampleFolder)\n",
    "        if not isdir(matchedSampleFolder):\n",
    "            makedirs(matchedSampleFolder)\n",
    "        #look for data files of all PNP samples that were matched to cardio sample and copy them to the common folder:\n",
    "        PNPsourceFolder='%s/TCR_real_data/PNP530_SubSampled%sdata_rep%s/SamplesForAnalysis_corrected' %(MyPath,ss,repeat)\n",
    "        CardiosourceFolder='%s/TCR_real_data/CardioSamples/Cardio126_SubSampled%sdata_rep%s/SamplesForAnalysis_corrected' %(MyPath,ss,repeat)\n",
    "\n",
    "        folderTuple=[('PNP',PNPsourceFolder,PNPmatchedSampleList),('Cardio',CardiosourceFolder,CardioMatchedSampleList)]\n",
    "        for folder in folderTuple:\n",
    "            print 'now copying files from %s folder' %folder[0]\n",
    "            files=[f for f in listdir(folder[1]) if isfile(join(folder[1],f))]\n",
    "            print 'number of %s files = %s' %(folder[0],len(files))\n",
    "            count=0                           \n",
    "            for f in files:\n",
    "                    f1=f.replace('b','')\n",
    "                    f1=f1.replace('a','')\n",
    "                    f1=f1.split('_')[0]\n",
    "                    f1=f1.split('.')[0]\n",
    "        #             print f1\n",
    "                    if f1 in folder[2]:\n",
    "                        src='%s/%s' %(folder[1],f)\n",
    "                        dst='%s/%s' %(matchedSampleFolder,f)\n",
    "                        copyfile(src, dst)\n",
    "                        count=count+1\n",
    "                    else:\n",
    "    #                     print 'file %s is not in the %s matched samples list' %(f,folder[0])\n",
    "                        pass\n",
    "\n",
    "            print '%s files were copied from %s folder' %(count,folder[0])\n",
    "        print 'in total, %s files were copied' %len([f for f in listdir(matchedSampleFolder) if isfile(join(matchedSampleFolder,f))])\n",
    "        print 'done copying sample data files'\n",
    "    \n",
    "    #(2) compare features:\n",
    "    if compareFeatures:\n",
    "        data_folder1='TCR_real_data/CardioSamples/Cardio126_SubSampled%sdata_rep%s' %(ss,repeat)\n",
    "        data_folder2='TCR_real_data/PNP530_SubSampled%sdata_rep%s' %(ss,repeat)\n",
    "        datasetName1='Cardio126_ss%s_rep%s' %(ss,repeat)\n",
    "        datasetName2='PNP530_ss%s_rep%s' %(ss,repeat)\n",
    "\n",
    "        TakeSameSamples=False\n",
    "        filteringList1=CardioMatchedSampleList\n",
    "        filteringList2=PNPmatchedSampleList\n",
    "        filteringList1Name='CardioMatchedss%srep%s' %(ss,repeat)\n",
    "        filteringList2Name='PNPMatchedss%srep%s' %(ss,repeat)\n",
    "\n",
    "        print 'comparing features between datasets:'\n",
    "        FeatureMeanSummary_all_dataSets=compare_features_between_datasets(data_folder1, datasetName1,  data_folder2, datasetName2,TakeSameSamples, \n",
    "                                          filteringList1,filteringList2,filteringList1Name,filteringList2Name)\n",
    "\n",
    "        print 'comparing geneset usage between datasets:'\n",
    "        plotType='bar'\n",
    "        plot_gene_usage_comparison(data_folder1, datasetName1,  data_folder2, datasetName2,plotType, TakeSameSamples, \n",
    "                                   filteringList1,filteringList2,filteringList1Name,filteringList2Name)\n",
    "\n",
    "        #check significance of the results for different types of results:\n",
    "        FeatComp=FeatureMeanSummary_all_dataSets.copy()\n",
    "        FeatComp_T=FeatComp[FeatComp.index.str.contains('_T')]\n",
    "\n",
    "        ## generate the geneUsageDF:\n",
    "        regexList=[('vFamily','V.._T'),('vGene','V..-.._T'),('jGene','J..-.._T'),('dFamily','D.._T'),\n",
    "                  ('VJ','V.._J.._T'),('DJ','D.._J..-.._T')]\n",
    "        df_list=[]\n",
    "        for regex in regexList:\n",
    "            regex_item= re.compile(regex[1])\n",
    "            indices=[n for n in FeatComp.index if re.match(regex_item, n)]\n",
    "            df=FeatComp.loc[indices, :]\n",
    "            df_list.append(df)\n",
    "\n",
    "        geneUsageResults_T=pd.concat(df_list)\n",
    "        print len(geneUsageResults_T)\n",
    "\n",
    "        nonGeneUsageResults_T=FeatComp.loc[[x for x in FeatComp_T.index if x not in geneUsageResults_T.index], :]\n",
    "        print len(nonGeneUsageResults_T)\n",
    "\n",
    "        ## check sig with FDR for each result df seperately:\n",
    "        resultDFlist=[('all',FeatComp),('onlyTotal',FeatComp_T),('onlyGeneUsage_T',geneUsageResults_T),('onlyFeatures_T',\n",
    "                nonGeneUsageResults_T)]\n",
    "        resultFolder='%s/featureSummaryDFs/comparisonResults' %datasetFolder\n",
    "        if not isdir(resultFolder):\n",
    "            makedirs(resultFolder)\n",
    "\n",
    "        for resultDF in resultDFlist:\n",
    "            print '******** %s *********' %resultDF[0]\n",
    "            nTests=len(resultDF[1])\n",
    "            print nTests\n",
    "            FDR=0.1\n",
    "\n",
    "            pValueColumnList=['ks_p','t_p']\n",
    "            for pValueColumn in pValueColumnList:\n",
    "                print pValueColumn\n",
    "                resultDF_FDR=add_corrected_pValues(resultDF[1],pValueColumn,nTests,FDR)\n",
    "                resultDF_FDR=resultDF_FDR.rename(columns={'Sig by bonferroni corrected pVal':'%s_Sig by bonferroni corrected pVal'\\\n",
    "    %pValueColumn, 'sig. by FDR=0.1':'%s_sig. by FDR=0.1' %pValueColumn})\n",
    "                sigResults=resultDF_FDR[resultDF_FDR['%s_sig. by FDR=0.1' %pValueColumn]==1]\n",
    "                print 'number of sig results with FDR=0.1 is %s' %len(sigResults)\n",
    "                print 'sig results:'\n",
    "                print sigResults\n",
    "                f1='%s/sigResults_%s_%s.xlsx' %(resultFolder,resultDF[0],pValueColumn)\n",
    "                sigResults.to_excel(f1)\n",
    "                print 'results were saved to file'\n",
    "    #(3) generate TCRdf, calculate sharing rates and seperate by PCA:\n",
    "    # general definition, define anyway so they will be accessible: \n",
    "    print '*****generating %s perc TCRdfs******' %percSharedCom\n",
    "    \n",
    "    publicAnalysisFolder='%s/publicAnalysis' %datasetFolder\n",
    "    if not isdir(publicAnalysisFolder):\n",
    "        makedirs(publicAnalysisFolder)\n",
    "    \n",
    "    DFtype='TCR'\n",
    "    genDF=genOrigComTCRdf #False=generate new df\n",
    "    toBinary=True\n",
    "    mbLevel='g'\n",
    "    useShortName=True\n",
    "    \n",
    "\n",
    "    datasetName='MatchedSamples_ss%srep%s' %(ss,repeat)\n",
    "    minVal=None    #minVal can be None,0, float, or 'dfMinVal' or dfMinVal2:\n",
    "    minSharedT=None #minimal number of samples shared by seq/species required to leave sample in the database (int or None)\n",
    "    percShared=percSharedCom #minimal number of samples shared by seq/species required to leave sample in the database (int [ percentage]\n",
    "                    #or None)\n",
    "    removeOutliers=True\n",
    "    normData=True\n",
    "    logTransform=True\n",
    "    extractUniqueAA=True # use True when this is the first time to analyze this dataset, otherwise, use False\n",
    "    minNshared=2\n",
    "    onlyProductive=True\n",
    "    mbDataFolder='AllSeqProjects'\n",
    "\n",
    "    SampleList=[f for f in listdir(matchedSampleFolder) if isfile(join(matchedSampleFolder,f))]\n",
    "    SampleListName='MatchedSamples_ss%srep%s' %(ss,repeat)\n",
    "    libPrepMethod=None\n",
    "    filterGenotek=True\n",
    "    filterMinimalReads=9000000\n",
    "    filterlibPrepMethod=libPrepMethod\n",
    "    groupFunction='noOutlierMean'\n",
    "    nSTD=5\n",
    "    nMinSamples=3\n",
    "    ignoreNotSameYear=True\n",
    "    removeSamePerson=False\n",
    "    \n",
    "    \n",
    "    if genComTCRdf:\n",
    "        print 'generating %sperc TCRdfs' %percSharedCom\n",
    "        TCRdf0=genTCRorMBdfWithManipulations(DFtype,genDF,toBinary,removeOutliers,normData,logTransform,\n",
    "                                         minVal,minSharedT,percShared,\n",
    "                                         mbLevel,useShortName,datasetFolder,datasetName,extractUniqueAA,\n",
    "                                        minNshared,onlyProductive,mbDataFolder,SampleList,\n",
    "                                          SampleListName,filterlibPrepMethod,filterGenotek, \n",
    "                                          groupFunction, nSTD, nMinSamples, ignoreNotSameYear, removeSamePerson)\n",
    "    \n",
    "    print 'loading %sperc TCRdfs' %percSharedCom\n",
    "    TCRdfFileName='sharingMatrix_MatchedSamples_ss%srep%s_minNshared2_RA_onlyProductiveTrue__percShared%s_OLtrimmed_binary' %(ss,repeat,percSharedCom)\n",
    "    TCRdfShortName='TCRdf_percShared%s_binary' %percSharedCom\n",
    "    f1='%s/%s_sharingAnalysis/%s' %(datasetFolder,SampleListName,TCRdfFileName)\n",
    "    TCRdf=pd.read_pickle(f1)\n",
    "    print 'TCRdf shape is %s_%s' %(TCRdf.shape[0],TCRdf.shape[1])\n",
    "    print 'TCRdf head:'\n",
    "    print TCRdf.iloc[:4,:4]\n",
    "    \n",
    "    ##get PCAdf:\n",
    "    ## **generate PCs as features:\n",
    "    if n_comp is None:\n",
    "        n_comp=5\n",
    "    try:\n",
    "        TCRdf=TCRdf.set_index('BD')\n",
    "    except:\n",
    "        print 'TCRdf already has BD column as index'\n",
    "    print 'generating PCAdf with %s PCs based on TCRdf:' %n_comp\n",
    "    fig2,ax2=plt.subplots(figsize=(8,6))\n",
    "    print 'percSharedCom=%s' %percSharedCom\n",
    "    print 'percShared=%s' %percShared\n",
    "    PCAdf,ax2,p_ttest_PC1,p_ttest_PC2=PCAfunc(TCRdf,n_comp,isSparse=True,ax=ax2)\n",
    "    ax2.set_title('PC1 - PC2 TCRdf %sperc-shared sequences' %percShared)\n",
    "    ax2.set_xlabel('PC1')\n",
    "    ax2.set_ylabel('PC2')\n",
    "    ax2.annotate('p_ttest_PC1=%s\\np_ttest_PC2=%s' %(round(p_ttest_PC1,4),round(p_ttest_PC2,4)), xy=(0.96, 0.95), xycoords='axes fraction', \n",
    "                    fontsize=12, horizontalalignment='right', verticalalignment='top', fontweight='bold')\n",
    "    print 'PCAdf shape is %s_%s' %(PCAdf.shape[0],PCAdf.shape[1])\n",
    "#     print 'PCAdf HEAD:'\n",
    "    PCAplotFile='%s/PC1PC2_%spercShared' %(publicAnalysisFolder, percSharedCom)\n",
    "    fig2.savefig(PCAplotFile,dpi=200)\n",
    "#     print PCAdf.iloc[:4,:4]\n",
    "    \n",
    "    #(4) compare public sequences between cohorts:\n",
    "    ## number of public sequence per sample distributions, total numbers of shared sequences, identity of shared sequences\n",
    "    if compareSharing:\n",
    "        TCRdfInfoTuple=[('PNP',PNPmatchedSampleList,'PNPmatchedSampleList'),('Cardio',CardioMatchedSampleList,'CardioMatchedSampleList')]\n",
    "        TCRdfDict={}\n",
    "        uniqueSeqDict={}\n",
    "        if genSepTCRdf:\n",
    "            #loop over PNP and Cardio matched samples (seperately) and generate TCRdf of shared sequences for each, seperately\n",
    "            for TCRdfInfo in TCRdfInfoTuple:\n",
    "                minSharedT=2 #minimal number of samples shared by seq/species required to leave sample in the database (int or None)\n",
    "                percShared=None #minimal number of samples shared by seq/species required to leave sample in the database (int [ percentage]\n",
    "                                #or None)\n",
    "                removeOutliers=True\n",
    "                normData=False\n",
    "                logTransform=False\n",
    "    #             extractUniqueAA=False\n",
    "\n",
    "                SampleList=TCRdfInfo[1]\n",
    "                SampleListName=TCRdfInfo[2]\n",
    "\n",
    "                print 'generating TCRdf only for %s samples from the matched samples:' %TCRdfInfo[0]\n",
    "                TCRdfDict['%s' %TCRdfInfo[0]]=genTCRorMBdfWithManipulations(DFtype,genDF,toBinary,removeOutliers,normData,logTransform,\n",
    "                                                     minVal,minSharedT,percShared,\n",
    "                                                     mbLevel,useShortName,datasetFolder,datasetName,extractUniqueAA,\n",
    "                                                    minNshared,onlyProductive,mbDataFolder,SampleList,\n",
    "                                                      SampleListName,filterlibPrepMethod,filterGenotek, \n",
    "                                                      groupFunction, nSTD, nMinSamples, ignoreNotSameYear, removeSamePerson)\n",
    "\n",
    "        ## load number of unique sequence per sample:\n",
    "        f3='%s/featureSummaryDFs/PNP530Cardio126_ss%srep%s_Matched_allFeatures' %(datasetFolder,ss,repeat)\n",
    "        featuresDF=pd.read_pickle(f3)\n",
    "        featuresDF=editSampleNames(featuresDF)\n",
    "        nUnique=pd.DataFrame(featuresDF['NT count_1'])\n",
    "        ##load binary DFs and compare number of shared sequences per sample distribution between PNP and cardio:\n",
    "        ## +load uniqueAA file for each\n",
    "        for TCRdfInfo in TCRdfInfoTuple:     \n",
    "            print 'loading seperate minSharedT2 TCRdfs for %s' %TCRdfInfo[0]\n",
    "            TCRdfFileName='sharingMatrix_%s_minNshared2_RA_onlyProductiveTrue__minSharedT2_OLtrimmed_binary'  %datasetName\n",
    "            f2='%s/%s_sharingAnalysis/%s' %(datasetFolder,TCRdfInfo[2],TCRdfFileName)\n",
    "            TCRdfDict['%s' %TCRdfInfo[0]]=pd.read_pickle(f2)\n",
    "            print '%s TCRdf shape is %s_%s' %(TCRdfInfo[0],TCRdfDict['%s' %TCRdfInfo[0]].shape[0],TCRdfDict['%s' %TCRdfInfo[0]].shape[1])\n",
    "            print '%s TCRdf head:' %TCRdfInfo[0]\n",
    "            print TCRdfDict['%s' %TCRdfInfo[0]].iloc[:4,:4]\n",
    "            \n",
    "            print 'loading uniqueSeqWithCounts....'\n",
    "            f4='%s/%s_sharingAnalysis/AllUniqueWithCounts' %(datasetFolder,TCRdfInfo[2])\n",
    "            AllUniqueWithCounts=pd.read_pickle(f4)\n",
    "            AllUniqueWithCounts=AllUniqueWithCounts[AllUniqueWithCounts['nShared']>=nSharedMin] # take only shared by more than nShared\n",
    "            UniqueSequencesWithCounts=AllUniqueWithCounts.drop(['Sample','frequencyCount (%)','prod_stat','isPublic'], axis=1)\n",
    "            UniqueSequencesWithCounts= UniqueSequencesWithCounts[~UniqueSequencesWithCounts.index.duplicated(keep='first')]   \n",
    "            uniqueSeqDict['%s' %TCRdfInfo[0]]=UniqueSequencesWithCounts\n",
    "\n",
    "            \n",
    "        #calculate percentage of public sequences out of all unique and plot distributions of this statistic in both cohorts:\n",
    "        PNP_nShared=pd.merge(pd.DataFrame(TCRdfDict['PNP'].sum(axis=1)),nUnique, how='left', left_index=True,right_index=True)\n",
    "        Cardio_nShared=pd.merge(pd.DataFrame(TCRdfDict['Cardio'].sum(axis=1)),nUnique, how='left', left_index=True,right_index=True)\n",
    "        PNP_nShared['percPublic']=100*PNP_nShared[0]/PNP_nShared['NT count_1']\n",
    "        Cardio_nShared['percPublic']=100*Cardio_nShared[0]/Cardio_nShared['NT count_1']\n",
    "         \n",
    "        data1=Cardio_nShared['percPublic']\n",
    "        data2=PNP_nShared['percPublic']\n",
    "        data1=data1[data1.notnull()].tolist()\n",
    "        data2=data2[data2.notnull()].tolist()\n",
    "        data1Name='Cardio'\n",
    "        data2Name='PNP'\n",
    "        folderToSave=publicAnalysisFolder\n",
    "        fig1,ax=plt.subplots(figsize=(8,6))\n",
    "        title='Comparing percent of public sequences between cohorts'\n",
    "        showLegend=True\n",
    "        nBins=20\n",
    "        \n",
    "        ax,ks_p_cohort1_cohort2,t_p_cohort1_cohort2,mean1,mean2,filename=plotHistComprison(data1,data2,data1Name,data2Name,folderToSave,ax,title,showLegend,nBins)\n",
    "        fig1.savefig(filename,dpi=200)\n",
    "        plt.show()\n",
    "       \n",
    "        #merge tables and get statistics : how much are public in one cohort but not the other:\n",
    "        mergedPublicList=pd.merge(uniqueSeqDict['PNP'],uniqueSeqDict['Cardio'],how='outer',left_index=True, right_index=True)\n",
    "        for col in mergedPublicList.columns:\n",
    "            newCol=col.replace('_x','PNP')\n",
    "            newCol=newCol.replace('_y','Cardio')\n",
    "            mergedPublicList= mergedPublicList.rename(columns={col:newCol})\n",
    "#         print mergedPublicList.head(20)\n",
    "        \n",
    "        publicInBoth=mergedPublicList[(mergedPublicList['nSharedPNP'].notnull())&(mergedPublicList['nSharedCardio'].notnull())]\n",
    "        publicOnlyInPNP=mergedPublicList[(mergedPublicList['nSharedPNP'].notnull())&(mergedPublicList['nSharedCardio'].isnull())]\n",
    "        publicOnlyInCardio=mergedPublicList[(mergedPublicList['nSharedPNP'].isnull())&(mergedPublicList['nSharedCardio'].notnull())]\n",
    "        \n",
    "        print 'number of sequence shared by %s or more samples in both cohorts: %s (%s perc)' %(nSharedMin,\n",
    "                                                    len(publicInBoth),100*float( len(publicInBoth))/len(mergedPublicList))\n",
    "        print 'number of sequence shared by %s or more samples only in the PNP cohort: %s (%s perc)' %(nSharedMin,\n",
    "                                                            len(publicOnlyInPNP),100*float(len(publicOnlyInPNP))/len(mergedPublicList))\n",
    "        print 'number of sequence shared by %s or more samples only in the Cardio cohort: %s (%s perc)' %(nSharedMin,\n",
    "                                                            len(publicOnlyInCardio),100*float( len(publicOnlyInCardio))/len(mergedPublicList))\n",
    "        print 'total=%s' %(len(publicInBoth)+len(publicOnlyInPNP)+len(publicOnlyInCardio))\n",
    "        print 'merged public list length length=%s' %len(mergedPublicList)\n",
    "        \n",
    "        #plot venn diagram:\n",
    "        from matplotlib_venn import venn2\n",
    "        fig3,ax3=plt.subplots(figsize=(8,6))\n",
    "        venn=venn2([set(uniqueSeqDict['PNP'].index.tolist()), set(uniqueSeqDict['Cardio'].index.tolist())],\n",
    "                   set_labels = ('PNP', 'Cardio'),ax=ax3)\n",
    "        ax3.set_title('Number of Public sequences in each cohort')\n",
    "        VennPlotFile='%s/PublicSeq_VennPlot_nSharedMin%s' %(publicAnalysisFolder,nSharedMin)\n",
    "        fig3.savefig(VennPlotFile,dpi=200)\n",
    "        plt.show()\n",
    "        \n",
    "        #add sequence identities:\n",
    "        print 'analyzing public sequence identities...'\n",
    "        identsFile='%s/TCR CDR3 sequence databases/CDR3identityTable_06082018.xlsx' %MyPath\n",
    "        identsProcessedFile='%s/TCR CDR3 sequence databases/CDR3identityTable_06082018_processed.xlsx' %MyPath\n",
    "        identsDF=pd.read_excel(identsFile)\n",
    "        identsProcessedDF=pd.read_excel(identsProcessedFile)\n",
    "        \n",
    "        publicDFlist=[('Both',publicInBoth),('onlyPNP',publicOnlyInPNP),('onlyCardio',publicOnlyInCardio)]\n",
    "        fig4,axes=plt.subplots(nrows=1,ncols=3,figsize=(30,8))\n",
    "        valueCountDict={}\n",
    "        for n,publicDF in enumerate(publicDFlist):\n",
    "            print n,publicDF[0]\n",
    "            publicDFwithIdents=pd.merge(publicDF[1],identsDF,how='left',left_index=True,right_index=True)\n",
    "            f1='%s/publicDFwithIdents_%s.xlsx' %(publicAnalysisFolder,publicDF[0])\n",
    "            publicDFwithIdents.to_excel(f1)\n",
    "            \n",
    "            publicDFwithIdents_processed=pd.merge(publicDF[1],identsProcessedDF,how='left',left_index=True,right_index=True)\n",
    "            df=publicDFwithIdents_processed\n",
    "            ax=axes[n]\n",
    "            nSharedThreshold=None\n",
    "            useMore=True\n",
    "            column=identityColumnForPie\n",
    "            dropna=True          \n",
    "            size=None\n",
    "            ax,valueCountsgrouped2=plot_identity_pie_plot(ax,df,nSharedThreshold,useMore,column,dropna,size)\n",
    "            valueCountDict[publicDF[0]]=valueCountsgrouped2\n",
    "#             print valueCountsgrouped2\n",
    "        publicIdentsFigFile='%s/publicIdentsFig_%s' %(publicAnalysisFolder,identityColumnForPie)\n",
    "                \n",
    "        #generate contingency table and calculate chi test:\n",
    "        valueCountComb=pd.merge(pd.DataFrame(valueCountDict['onlyPNP']),pd.DataFrame(valueCountDict['onlyCardio']),how='outer',\n",
    "                               left_index=True,right_index=True)\n",
    "        valueCountComb2=valueCountComb.T.fillna(0)\n",
    "#         print valueCountComb2\n",
    "        from scipy.stats import chi2_contingency\n",
    "        chi, p, dof, expctd = chi2_contingency(valueCountComb2)\n",
    "        ax.annotate('p_chi square test (only PNP vs. only Cardio=%s' %round(p,4), xy=(0.96, 1.15), xycoords='axes fraction', \n",
    "                    fontsize=22, horizontalalignment='right', verticalalignment='top', fontweight='bold')\n",
    "        fig4.subplots_adjust(left=0.09, right=0.9, top=0.8, bottom=0.02, wspace=0.5,hspace=0.1)\n",
    "        fig4.savefig(publicIdentsFigFile,dpi=200)\n",
    "        plt.show()\n",
    "        \n",
    "        print 'end of function!'\n",
    "    \n",
    "    return FeatureMeanSummary_all_dataSets\n",
    "    \n",
    "    \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T12:08:36.655215Z",
     "start_time": "2018-08-08T12:08:36.616929Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_identity_pie_plot(ax,df,nSharedThreshold,useMore,column,dropna,size=None):\n",
    "    \n",
    "    #(1) DEFINE PARAMETERS:\n",
    "    if nSharedThreshold is None:\n",
    "        df2=df.copy()\n",
    "        title='TCR identites distribution (%s),(%s sequences)' %(column,len(df2))\n",
    "    else:\n",
    "        if useMore:\n",
    "            df2=df[df['nShared']>=nSharedThreshold]\n",
    "            sharedBy='more'\n",
    "        else:\n",
    "            df2=df[df['nShared']<=nSharedThreshold]\n",
    "            sharedBy='less'\n",
    "        title='TCR identites distribution (%s)\\nSequences shared by %s or %s samples\\n(%s sequences)' %(column,nSharedThreshold,sharedBy,len(df2))\n",
    "    \n",
    "    #(2) CALCULATE NORMALIZED NUMBER OF IDENTITITES AND PLOT\n",
    "    valueCounts=pd.DataFrame(df2[column].value_counts(dropna=dropna,normalize=True))\n",
    "    valueCounts['count2']=np.where(valueCounts[column]>valueCounts[column].min()*2,\n",
    "                                             valueCounts.index,'Other')\n",
    "    valueCounts['count2']=valueCounts['count2'].astype(str)\n",
    "    valueCountsgrouped=valueCounts.groupby('count2').sum()\n",
    "    #print valueCountsgrouped.head()\n",
    "    valueCountsgrouped=valueCountsgrouped.sort_values(by=column,ascending=False)\n",
    "    cmap = plt.cm.get_cmap('Spectral')\n",
    "    colors =[cmap(x*20) for x in range(len(valueCountsgrouped))]\n",
    "\n",
    "    ax.pie(valueCountsgrouped[column],labels=valueCountsgrouped.index,autopct='%.2f',colors=colors,textprops={'fontsize': 14})\n",
    "#     valueCountsgrouped[column].plot.pie(ax=ax,autopct='%.2f')\n",
    "    ax.set_ylabel('')\n",
    "    ax.set_title(title,fontsize=20)\n",
    "    \n",
    "    #(3) CALCULATE NON-NORMALIZED NUMBER OF IDENTITES TO ENABLE RETURNING COUNTS:\n",
    "    valueCounts2=pd.DataFrame(df2[column].value_counts(dropna=dropna,normalize=False))\n",
    "    valueCounts2['count2']=np.where(valueCounts2[column]>valueCounts2[column].min()*2,\n",
    "                                             valueCounts2.index,'Other')\n",
    "    valueCounts2['count2']=valueCounts2['count2'].astype(str)\n",
    "    valueCountsgrouped2=valueCounts2.groupby('count2').sum()\n",
    "\n",
    "    \n",
    "    return ax,valueCountsgrouped2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T12:51:50.924814Z",
     "start_time": "2018-08-08T12:46:16.933608Z"
    }
   },
   "outputs": [],
   "source": [
    "ss=12500\n",
    "repeat=1\n",
    "\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss%srep%s' %(MyPath,ss,repeat)\n",
    "\n",
    "PNPListFile='%s/PNP530ss12500_samples_matchedTo_Cardio126ss12500_n70_resByGenderMaleAgeSmokingPastSmokingYes_rs5' %datasetFolder\n",
    "with open(PNPListFile,'rb') as fp:\n",
    "    PNPmatchedSampleList=pickle.load(fp)\n",
    "\n",
    "CardioListFile='%s/Cardio126ss12500_samples_matchedTo_PNP530ss12500_n70_resByGenderMaleAgeSmokingPastSmokingYes_rs5' %datasetFolder\n",
    "with open(CardioListFile,'rb') as fp:\n",
    "    CardioMatchedSampleList=pickle.load(fp)\n",
    "    \n",
    "delFolderFirst=True\n",
    "copySamples=True\n",
    "\n",
    "compareFeatures=True\n",
    "\n",
    "genOrigComTCRdf=True\n",
    "genComTCRdf=True\n",
    "n_comp=10\n",
    "percSharedCom=10\n",
    "\n",
    "compareSharing=True\n",
    "genSepTCRdf=True\n",
    "nSharedMin=2\n",
    "identityColumnForPie='Pathology_McPAS' #'Epitope species_VDJDB'/'Pathology_McPAS'\n",
    "\n",
    "FeatureMeanSummary_all_dataSets=compareTCRforMatchedCohorts(ss,repeat,PNPmatchedSampleList,CardioMatchedSampleList,\n",
    "                            copySamples,compareFeatures,compareSharing, genSepTCRdf,nSharedMin,delFolderFirst,\n",
    "                            genOrigComTCRdf,genComTCRdf,n_comp,percSharedCom,identityColumnForPie)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T11:59:29.073085Z",
     "start_time": "2018-08-08T11:59:21.779466Z"
    }
   },
   "outputs": [],
   "source": [
    "identsFile='%s/TCR CDR3 sequence databases/CDR3identityTable_06082018.xlsx' %MyPath\n",
    "identsProcessedFile='%s/TCR CDR3 sequence databases/CDR3identityTable_06082018_processed.xlsx'  %MyPath\n",
    "identsDF=pd.read_excel(identsFile)\n",
    "identsProcessedDF=pd.read_excel(identsProcessedFile)\n",
    "\n",
    "print  identsProcessedDF.index\n",
    "identsProcessedDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T08:01:41.967783Z",
     "start_time": "2018-08-08T08:01:41.544027Z"
    }
   },
   "outputs": [],
   "source": [
    "a=set([2,3,4,5,6,7])\n",
    "b=set([1,2])\n",
    "\n",
    "fig3,ax3=plt.subplots(figsize=(8,6))\n",
    "\n",
    "from matplotlib_venn import venn2\n",
    "venn=venn2([a, b],ax=ax3)\n",
    "f1='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss12500rep1/publicAnalysis/trial2' %MyPath\n",
    "fig3.savefig(f1, dpi=200)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-08T10:06:39.002557Z",
     "start_time": "2018-08-08T10:06:38.996391Z"
    }
   },
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "480px",
    "left": "3px",
    "right": "20px",
    "top": "133px",
    "width": "246px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
