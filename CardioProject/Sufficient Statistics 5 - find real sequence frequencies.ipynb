{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1\n",
      "done2\n"
     ]
    }
   ],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from myplots import roundup, rounddown, find_decimal_fold, percentile_cut_off, rarefaction_calc, rarefaction_plot,draw_correlation_scatter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import cPickle as pickle\n",
    "from Bio.SeqUtils import GC\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "from pop_organize import get_sample_data, get_sample_with_dfs\n",
    "from SufficientStatistics import *\n",
    "from MyFunctionsShani import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "p(CDR3)=logP(V)+logP(D|J)+logP(J)+logP(delv|v)+logP(delD5|D)+logP(delD3|D)+logP(delJ|J)+logP(ins1)+logP(ins2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for each sequence:\n",
    "(1) get identities of each recombination event\n",
    "(2) calculate the probs for each event, and sum their logs\n",
    "(3)calculate in how many samples we will expect this sequence to appear "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/trainSetSamples','rb') as f1:\n",
    "    trainSetSamples=pickle.load(f1)\n",
    "f1.close()\n",
    "\n",
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/TestSetSamples','rb') as f2:\n",
    "    TestSetSamples=pickle.load(f2)\n",
    "f2.close()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## at first stage, take only 1 sample from the test set and get the values for relevant parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#choose the first sample in the test set:\n",
    "TestSetSamples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate list of all sequences in the sample and the following parameters:\n",
    "# v,d,j,delv,deld5,deld3,delj,ins1length,ins2length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get the relevant parameters for sample HIP13933\n",
    "\n",
    "from Bio.Seq import Seq\n",
    "\n",
    "sample_name='HIP13933'\n",
    "sample_df = pd.read_table(\"/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/%s.tsv\" % sample_name) \n",
    "sample_df_non_prod = sample_df[sample_df['sequenceStatus'] != 'In']\n",
    "\n",
    "\n",
    "## v,d,j,delv,deld5,deld3,delj,ins1length,ins2length\n",
    "RelevantParams_HIP13933=sample_df_non_prod[['nucleotide','vGeneName','dFamilyName','jGeneName','vDeletion','d5Deletion','d3Deletion',\n",
    "                                             'jDeletion','n1Index','n2Index','dIndex','jIndex']]\n",
    "df=RelevantParams_HIP13933\n",
    "for n,i in enumerate(df.index):\n",
    "    print n\n",
    "    n1Index=df.loc[i,'n1Index']\n",
    "    dIndex=df.loc[i,'dIndex']\n",
    "    n2Index=df.loc[i,'n2Index']\n",
    "    jIndex=df.loc[i,'jIndex']\n",
    "    if n1Index == -1 or dIndex == -1:\n",
    "        df.loc[i,'n1InsSeq']=None\n",
    "        df.loc[i,'n1InsLen']=None \n",
    "    else:\n",
    "        n1InsSeq = df.loc[i,'nucleotide'][n1Index:dIndex]\n",
    "        df.loc[i,'n1InsSeq']=n1InsSeq\n",
    "        df.loc[i,'n1InsLen']=len(n1InsSeq) \n",
    "    if n2Index == -1 or jIndex == -1:\n",
    "        df.loc[i,'n2InsSeq']=None\n",
    "        df.loc[i,'n2InsLen']=None \n",
    "    else:\n",
    "        n2InsSeqRev = df.loc[i,'nucleotide'][n2Index:jIndex]\n",
    "        n2InsSeqRev2 = Seq(n2InsSeqRev)\n",
    "        n2InsSeq = n2InsSeqRev2.reverse_complement()\n",
    "        n2InsSeq = ''.join(n2InsSeq)\n",
    "        n2InsLen = len(n2InsSeq)\n",
    "        df.loc[i,'n2InsSeq']=n2InsSeq\n",
    "        df.loc[i,'n2InsLen']=n2InsLen\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/RelevantParams_HIP13933'\n",
    "RelevantParams_HIP13933.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#check duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#below are checks for duplications. \n",
    "\n",
    "#the conclusions are:\n",
    "\n",
    "#no row is duplicated compleletly. \n",
    "#removing the 'nucleotide' parameter, 1402 rows are duplicated.\n",
    "# Most non-unique combinations occure 2 times, except for 4 combinations that occure 3 times and 1 combination that occurs 4 times. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "RelevantParams_HIP13933.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "columns_to_check=['vGeneName', 'dFamilyName', 'jGeneName', 'vDeletion',\n",
    "       'd5Deletion', 'd3Deletion', 'jDeletion', 'n1InsSeq', 'n2InsSeq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "trial=RelevantParams_HIP13933[RelevantParams_HIP13933.duplicated(subset=columns_to_check,keep=False)]\n",
    "trial[(trial['vGeneName']=='TCRBV27-01')&(trial['vDeletion']==11)]\n",
    "print len(trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/duplicateRows_RelevantParams_HIP13933.xlsx'\n",
    "trial.to_excel(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## see how many replicates for each duplication:\n",
    "trial.groupby(columns_to_check).count().sort_values(by='nucleotide')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#generate a similar df for ALL samples in the test set together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#define the function for a specific sample:\n",
    "\n",
    "# this function was copied to eclipse- SuffStat_RunCDR3CalculTestSet.py\n",
    "\n",
    "def gen_params_summary_df_for_oneSample(sample_name):\n",
    "    from Bio.Seq import Seq\n",
    "\n",
    "    print sample_name\n",
    "    sample_df = pd.read_table(\"/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/%s.tsv\" % sample_name) \n",
    "    sample_df_non_prod = sample_df[sample_df['sequenceStatus'] != 'In']\n",
    "\n",
    "\n",
    "    ## v,d,j,delv,deld5,deld3,delj,ins1length,ins2length\n",
    "    df=sample_df_non_prod[['nucleotide','vGeneName','dFamilyName','jGeneName','vDeletion','d5Deletion','d3Deletion',\n",
    "                                                 'jDeletion','n1Index','n2Index','dIndex','jIndex']]\n",
    "    df=df[:20] ## delete when real!\n",
    "    for n,i in enumerate(df.index):\n",
    "        if n%5000==0:\n",
    "            print n\n",
    "        n1Index=df.loc[i,'n1Index']\n",
    "        dIndex=df.loc[i,'dIndex']\n",
    "        n2Index=df.loc[i,'n2Index']\n",
    "        jIndex=df.loc[i,'jIndex']\n",
    "        if n1Index == -1 or dIndex == -1:\n",
    "            df.loc[i,'n1InsSeq']=None\n",
    "            df.loc[i,'n1InsLen']=None \n",
    "        else:\n",
    "            n1InsSeq = df.loc[i,'nucleotide'][n1Index:dIndex]\n",
    "            df.loc[i,'n1InsSeq']=n1InsSeq\n",
    "            df.loc[i,'n1InsLen']=len(n1InsSeq) \n",
    "        if n2Index == -1 or jIndex == -1:\n",
    "            df.loc[i,'n2InsSeq']=None\n",
    "            df.loc[i,'n2InsLen']=None \n",
    "        else:\n",
    "            n2InsSeqRev = df.loc[i,'nucleotide'][n2Index:jIndex]\n",
    "            n2InsSeqRev2 = Seq(n2InsSeqRev)\n",
    "            n2InsSeq = n2InsSeqRev2.reverse_complement()\n",
    "            n2InsSeq = ''.join(n2InsSeq)\n",
    "            n2InsLen = len(n2InsSeq)\n",
    "            df.loc[i,'n2InsSeq']=n2InsSeq\n",
    "            df.loc[i,'n2InsLen']=n2InsLen\n",
    "    df['Sample']=sample_name\n",
    "        \n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#run for 3 samples:\n",
    "\n",
    "df_list=[]\n",
    "for n, sample_name in enumerate(TestSetSamples[:3]):\n",
    "    print n\n",
    "    df=gen_params_summary_df_for_sampleset(sample_name)\n",
    "    df_list.append(df)\n",
    "params_summary_df_for_sampleset=pd.concat(df_list)\n",
    "params_summary_df_for_sampleset = params_summary_df_for_sampleset.set_index('Sample')\n",
    "params_summary_df_for_sampleset.index = params_summary_df_for_sampleset.index.str.replace(\"HIP\", \"\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "calculate for each sequence:\n",
    "1. predicted frequency of value combinations by train set\n",
    "2. predicted frequency of value combination by test set\n",
    "2. observed frequency of value combination in test set\n",
    "4. observed frequency of value combination in train set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valueCombinations_HIP13933=RelevantParams_HIP13933.groupby(columns_to_check).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valueCombinations_HIP13933.rename(columns={'nucleotide':'count'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valueCombinations_HIP13933.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valueCombinations_HIP13933['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valueCombinations_HIP13933['count'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valueCombinations_HIP13933['frequency']=valueCombinations_HIP13933['count']/valueCombinations_HIP13933['count'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "valueCombinations_HIP13933.index[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "list(valueCombinations_HIP13933.index.names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "firstValueCombination=valueCombinations_HIP13933.index[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## defining functions needed to calculate the log prob of a specific parameters combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#calculate the sum of logs of conditional probs for a specific combination:\n",
    "\n",
    "def calc_cond_prob(indParVal, depParVal,condProbDF):\n",
    "    \n",
    "    CondProb=condProbDF.loc[indParVal,depParVal]\n",
    "    logCondProb=np.log10(CondProb)\n",
    "    return logCondProb\n",
    "\n",
    "def calc_all_condProbs(seqParamsValDict,setType):\n",
    "    indPar_list=['jGeneName','vGeneName','dFamilyName','dFamilyName','jGeneName']\n",
    "    depPar_list=['dFamilyName','vDeletion','d5Deletion','d3Deletion','jDeletion']\n",
    "    condProb_Train_df_list=[condProb_jGeneName_dFamilyName_Train_293,condProb_vGeneName_vDeletion_Train_293,\n",
    "                           condProb_dFamilyName_d5Deletion_Train_293,condProb_dFamilyName_d3Deletion_Train_293,\n",
    "                           condProb_jGeneName_jDeletion_Train_293]\n",
    "    condProb_Test_df_list=[condProb_jGeneName_dFamilyName_Test_294,condProb_vGeneName_vDeletion_Test_294,\n",
    "                           condProb_dFamilyName_d5Deletion_Test_294,condProb_dFamilyName_d3Deletion_Test_294,\n",
    "                           condProb_jGeneName_jDeletion_Test_294]\n",
    "\n",
    "    totalLogCondPro=0   \n",
    "    \n",
    "    for n in range(len(indPar_list)):\n",
    "        indPar=indPar_list[n]\n",
    "        depPar=depPar_list[n]\n",
    "        #print indPar,depPar\n",
    "        indParVal=seqParamsValDict[indPar]\n",
    "        depParVal=seqParamsValDict[depPar]\n",
    "        if setType=='Train':\n",
    "            condProbDF=condProb_Train_df_list[n]\n",
    "        else:\n",
    "            condProbDF=condProb_Test_df_list[n]\n",
    "        logCondPro=calc_cond_prob(indParVal, depParVal,condProbDF)\n",
    "        totalLogCondPro=totalLogCondPro+logCondPro\n",
    "\n",
    "\n",
    "    return totalLogCondPro\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_train_probs_files():\n",
    "    \n",
    "    \n",
    "    global vGeneTrainProbs_294,jGeneTrainProbs_294,condProb_jGeneName_dFamilyName_Train_293, \\\n",
    "            condProb_vGeneName_vDeletion_Train_293,condProb_jGeneName_jDeletion_Train_293, \\\n",
    "            condProb_dFamilyName_d5Deletion_Train_293,condProb_dFamilyName_d3Deletion_Train_293, \\\n",
    "            nt1FreqsDictDict_Train_ins1, lengthCount_Train_ins1, dinucNormDFDict_Train_ins1,nt1FreqsDictDict_Train_ins2,  \\\n",
    "            lengthCount_Train_ins2, dinucNormDFDict_Train_ins2\n",
    "    \n",
    "    \n",
    "    #V:\n",
    "    file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/vGeneTrainProbs_294'\n",
    "    vGeneTrainProbs_294=pd.read_pickle(file1)\n",
    "\n",
    "    #J:\n",
    "    file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/jGeneTrainProbs_294'\n",
    "    jGeneTrainProbs_294=pd.read_pickle(file2)\n",
    "\n",
    "    #D|J:\n",
    "    file3='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/condProb_jGeneName_dFamilyName_Train_293'\n",
    "    condProb_jGeneName_dFamilyName_Train_293=pd.read_pickle(file3)\n",
    "\n",
    "    #delV|V:\n",
    "    file4='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/condProb_vGeneName_vDeletion_Train_293'\n",
    "    condProb_vGeneName_vDeletion_Train_293=pd.read_pickle(file4)\n",
    "\n",
    "    #delD5|D:\n",
    "    file5='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/condProb_dFamilyName_d5Deletion_Train_293'\n",
    "    condProb_dFamilyName_d5Deletion_Train_293=pd.read_pickle(file5)\n",
    "\n",
    "    #delD3|D:\n",
    "    file6='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/condProb_dFamilyName_d3Deletion_Train_293'\n",
    "    condProb_dFamilyName_d3Deletion_Train_293=pd.read_pickle(file6)\n",
    "\n",
    "    #delJ|J:\n",
    "    file7='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/condProb_jGeneName_jDeletion_Train_293'\n",
    "    condProb_jGeneName_jDeletion_Train_293=pd.read_pickle(file7)\n",
    "    \n",
    "    #ins1, ins2 parameters:\n",
    "\n",
    "    file11='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/nt1FreqsDictDict_train_ins1'\n",
    "    nt1FreqsDictDict_Train_ins1=pd.read_pickle(file11)\n",
    "\n",
    "    file12='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/nt1FreqsDictDict_train_ins2'\n",
    "    nt1FreqsDictDict_Train_ins2=pd.read_pickle(file12)\n",
    "\n",
    "    file13='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/lengthCount_train_ins1'\n",
    "    lengthCount_Train_ins1=pd.read_pickle(file13)\n",
    "\n",
    "    file14='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/lengthCount_train_ins2'\n",
    "    lengthCount_Train_ins2=pd.read_pickle(file14)\n",
    "\n",
    "    file15='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/dinucNormDFDict_train_ins1'\n",
    "    dinucNormDFDict_Train_ins1=pd.read_pickle(file15)\n",
    "\n",
    "    file16='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/dinucNormDFDict_train_ins2'\n",
    "    dinucNormDFDict_Train_ins2=pd.read_pickle(file16)\n",
    "    \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def load_all_test_probs_files():\n",
    "    \n",
    "    global vGeneTestProbs_293,jGeneTestProbs_293,condProb_jGeneName_dFamilyName_Test_294, \\\n",
    "    condProb_vGeneName_vDeletion_Test_294,     condProb_jGeneName_jDeletion_Test_294, \\\n",
    "    condProb_dFamilyName_d5Deletion_Test_294,condProb_dFamilyName_d3Deletion_Test_294, \\\n",
    "    nt1FreqsDictDict_Test_ins1, lengthCount_Test_ins1, dinucNormDFDict_Test_ins1,nt1FreqsDictDict_Test_ins2, \\\n",
    "    lengthCount_Test_ins2,     dinucNormDFDict_Test_ins2\n",
    "    \n",
    "    #V:\n",
    "    file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/vGeneTestProbs_293'\n",
    "    vGeneTestProbs_293=pd.read_pickle(file1)\n",
    "\n",
    "    #J:\n",
    "    file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/jGeneTestProbs_293'\n",
    "    jGeneTestProbs_293=pd.read_pickle(file2)\n",
    "\n",
    "    #D|J:\n",
    "    file3='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/condProb_jGeneName_dFamilyName_Test_294'\n",
    "    condProb_jGeneName_dFamilyName_Test_294=pd.read_pickle(file3)\n",
    "\n",
    "    #delV|V:\n",
    "    file4='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/condProb_vGeneName_vDeletion_Test_294'\n",
    "    condProb_vGeneName_vDeletion_Test_294=pd.read_pickle(file4)\n",
    "\n",
    "    #delD5|D:\n",
    "    file5='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/condProb_dFamilyName_d5Deletion_Test_294'\n",
    "    condProb_dFamilyName_d5Deletion_Test_294=pd.read_pickle(file5)\n",
    "\n",
    "    #delD3|D:\n",
    "    file6='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/condProb_dFamilyName_d3Deletion_Test_294'\n",
    "    condProb_dFamilyName_d3Deletion_Test_294=pd.read_pickle(file6)\n",
    "\n",
    "    #delJ|J:\n",
    "    file7='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/condProb_jGeneName_jDeletion_Test_294'\n",
    "    condProb_jGeneName_jDeletion_Test_294=pd.read_pickle(file7)\n",
    "    \n",
    "    #ins1, ins2 parameters:\n",
    "\n",
    "    file11='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/nt1FreqsDictDict_test_ins1'\n",
    "    nt1FreqsDictDict_Test_ins1=pd.read_pickle(file11)\n",
    "\n",
    "    file12='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/nt1FreqsDictDict_test_ins2'\n",
    "    nt1FreqsDictDict_Test_ins2=pd.read_pickle(file12)\n",
    "\n",
    "    file13='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/lengthCount_test_ins1'\n",
    "    lengthCount_Test_ins1=pd.read_pickle(file13)\n",
    "\n",
    "    file14='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/lengthCount_test_ins2'\n",
    "    lengthCount_Test_ins2=pd.read_pickle(file14)\n",
    "\n",
    "    file15='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/dinucNormDFDict_test_ins1'\n",
    "    dinucNormDFDict_Test_ins1=pd.read_pickle(file15)\n",
    "\n",
    "    file16='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/dinucNormDFDict_test_ins2'\n",
    "    dinucNormDFDict_Test_ins2=pd.read_pickle(file16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# a function calculating the probability of a specific combination based on either the train or test data set:\n",
    "#when generalizing this function. need to take the read_pickles out\n",
    "\n",
    "def calc_logProb_per_seq(seqParamsValDict,setType):\n",
    "    totalLogProb=0\n",
    "       \n",
    "    load_all_train_probs_files()\n",
    "    load_all_test_probs_files()\n",
    "       \n",
    "    \n",
    "    #calculate sum of logs of conditional probs and add to the total log prob:\n",
    "    totalLogCondPro=calc_all_condProbs(seqParamsValDict,setType)\n",
    "    totalLogProb=+totalLogCondPro\n",
    "    \n",
    "    #calc log probs for v and j and add to the total log prob:\n",
    "    if setType=='Train':\n",
    "        vGeneProbsDF=vGeneTrainProbs_294\n",
    "        jGeneProbsDF=jGeneTrainProbs_294\n",
    "    else: \n",
    "        vGeneProbsDF=vGeneTestProbs_293\n",
    "        jGeneProbsDF=jGeneTestProbs_293          \n",
    "       \n",
    "    vGeneName=seqParamsValDict['vGeneName']\n",
    "    vProb=vGeneProbsDF[vGeneName]\n",
    "    #print 'vprob=%s' %vProb\n",
    "    logVProb=np.log10(vProb)\n",
    "    \n",
    "    jGeneName=seqParamsValDict['jGeneName']\n",
    "    jProb=jGeneProbsDF[jGeneName]\n",
    "    #print 'jprob=%s' %jProb\n",
    "    logJProb=np.log10(jProb)\n",
    "   \n",
    "    totalLogProb=totalLogProb+logVProb+logJProb\n",
    "    \n",
    "    #calc log probs for ins1 and ins2 and add to the total log prob:\n",
    "    if setType=='Train':\n",
    "        n1InsSeq=seqParamsValDict['n1InsSeq']\n",
    "        logProbins1Seq=calc_insSeq_prob(n1InsSeq, 20, nt1FreqsDictDict_Train_ins1, dinucNormDFDict_Train_ins1, lengthCount_Train_ins1)\n",
    "        n2InsSeq=seqParamsValDict['n2InsSeq']\n",
    "        logProbins2Seq=calc_insSeq_prob(n2InsSeq, 20, nt1FreqsDictDict_Train_ins2, dinucNormDFDict_Train_ins2, lengthCount_Train_ins2)\n",
    "    else:\n",
    "        n1InsSeq=seqParamsValDict['n1InsSeq']\n",
    "        logProbins1Seq=calc_insSeq_prob(n1InsSeq, 20, nt1FreqsDictDict_Test_ins1, dinucNormDFDict_Test_ins1, lengthCount_Test_ins1)\n",
    "        n2InsSeq=seqParamsValDict['n2InsSeq']\n",
    "        logProbins2Seq=calc_insSeq_prob(n2InsSeq, 20, nt1FreqsDictDict_Test_ins2, dinucNormDFDict_Test_ins2, lengthCount_Test_ins2)\n",
    "        \n",
    "        \n",
    "        \n",
    "    totalLogProb=totalLogProb+logProbins1Seq+logProbins2Seq\n",
    "    \n",
    "    #print 'ins1 prob=%s' %10**logProbins1Seq\n",
    "    #print 'ins2 prob=%s' %10**logProbins2Seq\n",
    "    \n",
    "    return totalLogProb\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/params_summary_TestSet_grouped_replicates'\n",
    "params_summary_TestSet_grouped_replicates=pd.read_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n=0\n",
    "seqParamsVals=params_summary_TestSet_grouped_replicates.index[n]\n",
    "paramsNames=params_summary_TestSet_grouped_replicates.index.names\n",
    "\n",
    "seqParamsValDict=dict(zip(paramsNames, seqParamsVals))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "totalLogProb=calc_logProb_per_seq(seqParamsValDict,'Test')\n",
    "totalLogProb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "totalLogProb=calc_logProb_per_seq(seqParamsValDict,'Train')\n",
    "totalLogProb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generating a df with all combinations in the test set\n",
    "# generating a df with all combinations in the test set *that repeat more than once*:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the function gen_params_summary_df_for_oneSample(sample_name) was run for all samples using the eclipse (parallel runs)\n",
    "# the resulting dfs needs to be concatenate to one:\n",
    "\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/gen_params_summary_df_for_sampleset'\n",
    "params_summary_TestSet=concat_summarizing_dfs(dfs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_summary_TestSet.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_summary_TestSet.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the complete df\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/params_summary_TestSet'\n",
    "params_summary_TestSet.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#save the complete df\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/params_summary_TestSet'\n",
    "params_summary_TestSet=pd.read_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate df of all possible parameters combinations and their count:\n",
    "params_summary_TestSet_grouped=params_summary_TestSet.groupby(columns_to_check).count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_summary_TestSet_grouped.rename(columns={'nucleotide':'count'},inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_summary_TestSet_grouped.drop(['n1Index','n2Index','dIndex','jIndex','n1InsLen','n2InsLen'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_summary_TestSet_grouped.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_summary_TestSet_grouped.sort_values(by=['count'],ascending=False,inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "params_summary_TestSet_grouped.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/params_summary_TestSet_grouped'\n",
    "params_summary_TestSet_grouped.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print len(params_summary_TestSet_grouped.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# generate a sub-df which contains only combinations that repeat more than once in the test set (~2% of the combinations)\n",
    "\n",
    "params_summary_TestSet_grouped_replicates=params_summary_TestSet_grouped[params_summary_TestSet_grouped['count']>1]\n",
    "print len(params_summary_TestSet_grouped_replicates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "171100./8352567"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/params_summary_TestSet_grouped_replicates'\n",
    "params_summary_TestSet_grouped_replicates.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run on each repeated combination and check its predicted and observed freqs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "a function to run on each combination in params_summary_TestSet_grouped_replicates\n",
    "calculates:\n",
    "1. predicted freq by the train set\n",
    "2. predicted freq by the test set\n",
    "3. observed freq in the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compare_cdr3_prediction(min_comb,max_comb,df):\n",
    "\n",
    "    file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/params_summary_TestSet_grouped_replicates'\n",
    "    params_summary_TestSet_grouped_replicates=pd.read_pickle(file1)\n",
    "        \n",
    "    n_combinations_testSet=8352567\n",
    "    \n",
    "    \n",
    "    n_list=[]\n",
    "    totalLogProb_Train_list=[]\n",
    "    totalLogProb_Test_list=[]\n",
    "    logObsFreqInTestSet_list=[]\n",
    "   \n",
    "    for n in range(min_comb,max_comb):\n",
    "        print n\n",
    "        seqParamsVals=df.index[n]\n",
    "        paramsNames=df.index.names\n",
    "        seqParamsValDict=dict(zip(paramsNames, seqParamsVals))\n",
    "        \n",
    "        totalLogProb_Test=calc_logProb_per_seq(seqParamsValDict,'Test')\n",
    "        totalLogProb_Train=calc_logProb_per_seq(seqParamsValDict,'Train')\n",
    "        obsfreq=float(params_summary_TestSet_grouped_replicates['count'][n])/n_combinations_testSet\n",
    "        logObsFreqInTestSet=np.log10(obsfreq)\n",
    "        \n",
    "        \n",
    "        #exp_n_comb_appears_in_sample=n_combinations_sample*10**totalLogProb\n",
    "        exp_n_comb_appears_in_testSet=n_combinations_testSet*10**totalLogProb\n",
    "        real_n_in_testSet=params_summary_TestSet_grouped_replicates['count'][n]\n",
    "        \n",
    "        \n",
    "        n_list.append(n)\n",
    "        totalLogProb_Train_list.append(totalLogProb_Train)\n",
    "        totalLogProb_Test_list.append(totalLogProb_Test)\n",
    "        logObsFreqInTestSet_list.append(logObsFreqInTestSet)\n",
    "\n",
    "    cdr3_prediction_compare_df=pd.DataFrame({'n':n_list, 'cdr3LogProb_byTrainSet':totalLogProb_Train_list,\n",
    "                                        'cdr3LogProb_byTestSet':totalLogProb_Test_list,\n",
    "                                        'cdr3LogObsFreq': logObsFreqInTestSet_list})\n",
    "        \n",
    "        \n",
    "        \n",
    "    return cdr3_prediction_compare_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "7.0/50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0.14*170000/3600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/params_summary_TestSet_grouped'\n",
    "params_summary_TestSet_grouped=pd.read_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/params_summary_TestSet_grouped_replicates'\n",
    "params_summary_TestSet_grouped_replicates=pd.read_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(params_summary_TestSet_grouped_replicates.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "df=params_summary_TestSet_grouped_replicates\n",
    "df2=params_summary_TestSet_grouped\n",
    "cdr3_prediction_compare_df=compare_cdr3_prediction(0,20,df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "170000/2000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr3_prediction_compare_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=cdr3_prediction_compare_df['cdr3LogProb_byTrainSet']\n",
    "y=cdr3_prediction_compare_df['cdr3LogProb_byTestSet']\n",
    "z=cdr3_prediction_compare_df['cdr3LogObsFreq']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correl between test and train set predictions:\n",
    "r,p=MyPearsonr(x,y)\n",
    "print r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correl between train prediction and observed :\n",
    "r,p=MyPearsonr(x,z)\n",
    "print r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#correl between test prediction and observed :\n",
    "r,p=MyPearsonr(y,z)\n",
    "print r,p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print '%.5f' %x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## combine the results for all combinations in the test set that appears more than once:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function compare_cdr3_prediction was run on all repeating combinations (171100 combinations summarized in 'params_summary_TestSet_grouped_replicates')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/compare_cdr3_prediction'\n",
    "compare_cdr3_prediction_allRepeatingSeqs=concat_summarizing_dfs(dfs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "compare_cdr3_prediction_allRepeatingSeqs['logFoldDiffObsToPredict']=compare_cdr3_prediction_allRepeatingSeqs['cdr3LogObsFreq']-compare_cdr3_prediction_allRepeatingSeqs['cdr3LogProb_byTrainSet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_cdr3_prediction_allRepeatingSeqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_cdr3_prediction_allRepeatingSeqs.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/compare_cdr3_prediction_allRepeatingSeqs'\n",
    "compare_cdr3_prediction_allRepeatingSeqs.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/WholeCDR3SeqPred/params_summary_tables/compare_cdr3_prediction_allRepeatingSeqs'\n",
    "compare_cdr3_prediction_allRepeatingSeqs=pd.read_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for the sequences with the higher predicted frequency:\n",
    "highestPredictionsDF=compare_cdr3_prediction_allRepeatingSeqs[compare_cdr3_prediction_allRepeatingSeqs['cdr3LogProb_byTrainSet']>-8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params_summary_TestSet_grouped_replicates.index[159024]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "highestPredictionsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in highestPredictionsDF.index:\n",
    "    print params_summary_TestSet_grouped_replicates.index[n]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#look for the sequences with the lowest predicted frequency:\n",
    "LowestPredictionsDF=compare_cdr3_prediction_allRepeatingSeqs[compare_cdr3_prediction_allRepeatingSeqs['cdr3LogProb_byTrainSet']<-42]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LowestPredictionsDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "LowestPredictionsDF=LowestPredictionsDF.set_index('n')\n",
    "for n in LowestPredictionsDF.index:\n",
    "    print params_summary_TestSet_grouped_replicates.index[n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation between predictions by train and set session-only high!\n",
    "\n",
    "df=highestPredictionsDF\n",
    "x_var = 'cdr3LogProb_byTrainSet'\n",
    "y_var = 'cdr3LogProb_byTestSet'\n",
    "\n",
    "x=df[x_var]\n",
    "y=df[y_var]\n",
    "ymean=df[y_var].mean()\n",
    "filename = '/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/SuffStat Images/CDR3_freqs_predictions_correl-highestPredictionsDF'\n",
    "\n",
    "\n",
    "\n",
    "draw_correlation_scatter_onePlotperFigure(x, y, figsize = (3, 3), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = 'pearson', ms=4, logd = False,\\\n",
    "                             xlab = x_var, ylab = y_var, filename = filename, title = None,\n",
    "                             color = \"#a0a0a0\", grid = True, dpi = 200, xticklabels = None, \n",
    "                             xticklabelsSize=7, yticklabelsSize=7, xticksAlign=None, contour = False)\n",
    "# fit with np.polyfit\n",
    "nx=np.isnan(x)\n",
    "ny=np.isnan(y)\n",
    "n=nx+ny\n",
    "newx=list(x[~n])\n",
    "newy=list(y[~n])\n",
    "plt.plot(np.unique(newx), np.poly1d(np.polyfit(newx, newy, 1))(np.unique(newx)))\n",
    "plt.plot(x=x,c='black', linewidth=4)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation between predictions by train and set session-first 5000 combinations:\n",
    "\n",
    "df=compare_cdr3_prediction_allRepeatingSeqs[:5000]\n",
    "x_var = 'cdr3LogProb_byTrainSet'\n",
    "y_var = 'cdr3LogProb_byTestSet'\n",
    "\n",
    "x=df[x_var]\n",
    "y=df[y_var]\n",
    "ymean=df[y_var].mean()\n",
    "filename = '/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/SuffStat Images/CDR3_freqs_predictions_correl-first5000combinations'\n",
    "\n",
    "\n",
    "\n",
    "draw_correlation_scatter_onePlotperFigure(x, y, figsize = (3, 3), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = 'pearson', ms=4, logd = False,\\\n",
    "                             xlab = x_var, ylab = y_var, filename = filename, title = None,\n",
    "                             color = \"#a0a0a0\", grid = True, dpi = 200, xticklabels = None, \n",
    "                             xticklabelsSize=7, yticklabelsSize=7, xticksAlign=None, contour = False)\n",
    "# fit with np.polyfit\n",
    "nx=np.isnan(x)\n",
    "ny=np.isnan(y)\n",
    "n=nx+ny\n",
    "newx=list(x[~n])\n",
    "newy=list(y[~n])\n",
    "plt.plot(np.unique(newx), np.poly1d(np.polyfit(newx, newy, 1))(np.unique(newx)))\n",
    "plt.plot(x=x,c='black', linewidth=4)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation between predictions by train and set session\n",
    "\n",
    "df=highestPredictionsDF\n",
    "x_var = 'cdr3LogProb_byTrainSet'\n",
    "y_var = 'cdr3LogObsFreq'\n",
    "\n",
    "x=df[x_var]\n",
    "y=df[y_var]\n",
    "ymean=df[y_var].mean()\n",
    "filename = '/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/SuffStat Images/CDR3_freqs_obs_to_predict_correl-highestPredictionsDF'\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "draw_correlation_scatter_onePlotperFigure(x, y, figsize = (3, 3), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = 'pearson', ms=4, logd = False,\\\n",
    "                             xlab = x_var, ylab = y_var, filename = filename, title = None,\n",
    "                             color = \"#a0a0a0\", grid = True, dpi = 200, xticklabels = None, \n",
    "                             xticklabelsSize=7, yticklabelsSize=7, xticksAlign=None, contour = False)\n",
    "# fit with np.polyfit\n",
    "nx=np.isnan(x)\n",
    "ny=np.isnan(y)\n",
    "n=nx+ny\n",
    "newx=list(x[~n])\n",
    "newy=list(y[~n])\n",
    "plt.plot(np.unique(newx), np.poly1d(np.polyfit(newx, newy, 1))(np.unique(newx)))\n",
    "plt.plot(x=x,c='black', linewidth=4)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot correlation between predictions by train and set session, first 5000 combinations:\n",
    "\n",
    "df=compare_cdr3_prediction_allRepeatingSeqs[-5000:]\n",
    "x_var = 'cdr3LogProb_byTrainSet'\n",
    "y_var = 'cdr3LogObsFreq'\n",
    "\n",
    "x=df[x_var]\n",
    "y=df[y_var]\n",
    "ymean=df[y_var].mean()\n",
    "filename = '/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/SuffStat Images/CDR3_freqs_obs_to_predict_correl-first5000combinations'\n",
    "\n",
    "\n",
    "\n",
    "draw_correlation_scatter_onePlotperFigure(x, y, figsize = (3, 3), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = 'pearson', ms=4, logd = False,\\\n",
    "                             xlab = x_var, ylab = y_var, filename = filename, title = None,\n",
    "                             color = \"#a0a0a0\", grid = True, dpi = 200, xticklabels = None, \n",
    "                             xticklabelsSize=7, yticklabelsSize=7, xticksAlign=None, contour = False)\n",
    "# fit with np.polyfit\n",
    "nx=np.isnan(x)\n",
    "ny=np.isnan(y)\n",
    "n=nx+ny\n",
    "newx=list(x[~n])\n",
    "newy=list(y[~n])\n",
    "plt.plot(np.unique(newx), np.poly1d(np.polyfit(newx, newy, 1))(np.unique(newx)))\n",
    "plt.plot(x=x,c='black', linewidth=4)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compare_cdr3_prediction_allRepeatingSeqs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df=compare_cdr3_prediction_allRepeatingSeqs.sort_values(by='cdr3LogObsFreq')[-5000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>cdr3LogObsFreq</th>\n",
       "      <th>cdr3LogProb_byTestSet</th>\n",
       "      <th>cdr3LogProb_byTrainSet</th>\n",
       "      <th>n</th>\n",
       "      <th>logFoldDiffObsToPredict</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-13.671936</td>\n",
       "      <td>-13.671185</td>\n",
       "      <td>105970</td>\n",
       "      <td>7.050395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1968</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-17.000765</td>\n",
       "      <td>-17.006995</td>\n",
       "      <td>105968</td>\n",
       "      <td>10.386205</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1954</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-15.861177</td>\n",
       "      <td>-15.846868</td>\n",
       "      <td>105954</td>\n",
       "      <td>9.226078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1955</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-13.604174</td>\n",
       "      <td>-13.587427</td>\n",
       "      <td>105955</td>\n",
       "      <td>6.966637</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1956</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-11.569301</td>\n",
       "      <td>-11.588902</td>\n",
       "      <td>105956</td>\n",
       "      <td>4.968112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1957</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-14.527693</td>\n",
       "      <td>-14.515023</td>\n",
       "      <td>105957</td>\n",
       "      <td>7.894233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1958</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-15.357657</td>\n",
       "      <td>-15.362452</td>\n",
       "      <td>105958</td>\n",
       "      <td>8.741662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1959</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-29.904584</td>\n",
       "      <td>-29.858379</td>\n",
       "      <td>105959</td>\n",
       "      <td>23.237589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1969</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-13.081124</td>\n",
       "      <td>-13.116516</td>\n",
       "      <td>105969</td>\n",
       "      <td>6.495726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1960</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-12.853359</td>\n",
       "      <td>-12.890930</td>\n",
       "      <td>105960</td>\n",
       "      <td>6.270140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1962</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-13.701730</td>\n",
       "      <td>-13.673515</td>\n",
       "      <td>105962</td>\n",
       "      <td>7.052725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1963</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-13.895297</td>\n",
       "      <td>-13.875929</td>\n",
       "      <td>105963</td>\n",
       "      <td>7.255139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1964</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-12.115384</td>\n",
       "      <td>-12.158955</td>\n",
       "      <td>105964</td>\n",
       "      <td>5.538165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1965</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-19.826582</td>\n",
       "      <td>-19.834969</td>\n",
       "      <td>105965</td>\n",
       "      <td>13.214179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1966</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-17.281294</td>\n",
       "      <td>-17.269163</td>\n",
       "      <td>105966</td>\n",
       "      <td>10.648373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1967</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-11.544867</td>\n",
       "      <td>-11.545828</td>\n",
       "      <td>105967</td>\n",
       "      <td>4.925038</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1961</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-14.218121</td>\n",
       "      <td>-14.205201</td>\n",
       "      <td>105961</td>\n",
       "      <td>7.584411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-14.822526</td>\n",
       "      <td>-14.857966</td>\n",
       "      <td>116023</td>\n",
       "      <td>8.237176</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1987</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-14.254417</td>\n",
       "      <td>-14.293950</td>\n",
       "      <td>105987</td>\n",
       "      <td>7.673160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1989</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-24.435577</td>\n",
       "      <td>-24.449008</td>\n",
       "      <td>105989</td>\n",
       "      <td>17.828218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-13.380886</td>\n",
       "      <td>-13.391915</td>\n",
       "      <td>116008</td>\n",
       "      <td>6.771125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-16.217121</td>\n",
       "      <td>-16.201927</td>\n",
       "      <td>116009</td>\n",
       "      <td>9.581137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-12.666215</td>\n",
       "      <td>-12.657042</td>\n",
       "      <td>116010</td>\n",
       "      <td>6.036252</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-12.996748</td>\n",
       "      <td>-12.992670</td>\n",
       "      <td>116011</td>\n",
       "      <td>6.371880</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-16.706430</td>\n",
       "      <td>-16.693727</td>\n",
       "      <td>116012</td>\n",
       "      <td>10.072937</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-13.568317</td>\n",
       "      <td>-13.531833</td>\n",
       "      <td>116013</td>\n",
       "      <td>6.911043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-17.814205</td>\n",
       "      <td>-17.790747</td>\n",
       "      <td>116007</td>\n",
       "      <td>11.169957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-14.146132</td>\n",
       "      <td>-14.153515</td>\n",
       "      <td>116014</td>\n",
       "      <td>7.532725</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-11.168985</td>\n",
       "      <td>-11.178500</td>\n",
       "      <td>116016</td>\n",
       "      <td>4.557710</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-6.620790</td>\n",
       "      <td>-26.794841</td>\n",
       "      <td>-26.768943</td>\n",
       "      <td>116017</td>\n",
       "      <td>20.148153</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>-5.745729</td>\n",
       "      <td>-15.407539</td>\n",
       "      <td>-15.409474</td>\n",
       "      <td>30</td>\n",
       "      <td>9.663745</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>-5.717700</td>\n",
       "      <td>-17.611096</td>\n",
       "      <td>-17.605726</td>\n",
       "      <td>28</td>\n",
       "      <td>11.888026</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>-5.717700</td>\n",
       "      <td>-16.944313</td>\n",
       "      <td>-16.943873</td>\n",
       "      <td>27</td>\n",
       "      <td>11.226173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-5.717700</td>\n",
       "      <td>-12.802490</td>\n",
       "      <td>-12.814696</td>\n",
       "      <td>26</td>\n",
       "      <td>7.096996</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>-5.717700</td>\n",
       "      <td>-10.500384</td>\n",
       "      <td>-10.519780</td>\n",
       "      <td>25</td>\n",
       "      <td>4.802080</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-5.717700</td>\n",
       "      <td>-26.848713</td>\n",
       "      <td>-26.758339</td>\n",
       "      <td>24</td>\n",
       "      <td>21.040639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>-5.666547</td>\n",
       "      <td>-15.182001</td>\n",
       "      <td>-15.173847</td>\n",
       "      <td>23</td>\n",
       "      <td>9.507299</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>-5.643066</td>\n",
       "      <td>-11.600916</td>\n",
       "      <td>-11.618508</td>\n",
       "      <td>22</td>\n",
       "      <td>5.975442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-5.643066</td>\n",
       "      <td>-16.585454</td>\n",
       "      <td>-16.639591</td>\n",
       "      <td>21</td>\n",
       "      <td>10.996524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>-5.620790</td>\n",
       "      <td>-15.918760</td>\n",
       "      <td>-15.931641</td>\n",
       "      <td>20</td>\n",
       "      <td>10.310851</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>-5.620790</td>\n",
       "      <td>-11.080888</td>\n",
       "      <td>-11.089596</td>\n",
       "      <td>19</td>\n",
       "      <td>5.468806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-5.620790</td>\n",
       "      <td>-15.295244</td>\n",
       "      <td>-15.293409</td>\n",
       "      <td>18</td>\n",
       "      <td>9.672619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>-5.599601</td>\n",
       "      <td>-10.881120</td>\n",
       "      <td>-10.892486</td>\n",
       "      <td>17</td>\n",
       "      <td>5.292886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-5.579397</td>\n",
       "      <td>-22.972234</td>\n",
       "      <td>-22.932834</td>\n",
       "      <td>16</td>\n",
       "      <td>17.353437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>-5.506847</td>\n",
       "      <td>-11.559209</td>\n",
       "      <td>-11.574646</td>\n",
       "      <td>15</td>\n",
       "      <td>6.067800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>-5.474662</td>\n",
       "      <td>-16.449625</td>\n",
       "      <td>-16.474695</td>\n",
       "      <td>13</td>\n",
       "      <td>11.000033</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-5.474662</td>\n",
       "      <td>-23.129566</td>\n",
       "      <td>-23.092148</td>\n",
       "      <td>14</td>\n",
       "      <td>17.617486</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>-5.416670</td>\n",
       "      <td>-18.362312</td>\n",
       "      <td>-18.349464</td>\n",
       "      <td>12</td>\n",
       "      <td>12.932794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>-5.403306</td>\n",
       "      <td>-10.840735</td>\n",
       "      <td>-10.808911</td>\n",
       "      <td>11</td>\n",
       "      <td>5.405605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>-5.403306</td>\n",
       "      <td>-10.940993</td>\n",
       "      <td>-10.918379</td>\n",
       "      <td>10</td>\n",
       "      <td>5.515073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>-5.377752</td>\n",
       "      <td>-18.198251</td>\n",
       "      <td>-18.185140</td>\n",
       "      <td>9</td>\n",
       "      <td>12.807388</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>-5.365517</td>\n",
       "      <td>-9.502029</td>\n",
       "      <td>-9.516703</td>\n",
       "      <td>8</td>\n",
       "      <td>4.151186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>-5.353618</td>\n",
       "      <td>-13.515327</td>\n",
       "      <td>-13.527902</td>\n",
       "      <td>7</td>\n",
       "      <td>8.174283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-5.319760</td>\n",
       "      <td>-11.062606</td>\n",
       "      <td>-11.077759</td>\n",
       "      <td>6</td>\n",
       "      <td>5.757999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>-5.298571</td>\n",
       "      <td>-12.010372</td>\n",
       "      <td>-12.018808</td>\n",
       "      <td>5</td>\n",
       "      <td>6.720238</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-5.259062</td>\n",
       "      <td>-13.720593</td>\n",
       "      <td>-13.735152</td>\n",
       "      <td>4</td>\n",
       "      <td>8.476090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-5.115640</td>\n",
       "      <td>-13.891303</td>\n",
       "      <td>-13.880698</td>\n",
       "      <td>3</td>\n",
       "      <td>8.765058</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.992401</td>\n",
       "      <td>-15.764890</td>\n",
       "      <td>-15.770428</td>\n",
       "      <td>2</td>\n",
       "      <td>10.778027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-4.967577</td>\n",
       "      <td>-55.784834</td>\n",
       "      <td>-55.721740</td>\n",
       "      <td>1</td>\n",
       "      <td>50.754163</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-4.325223</td>\n",
       "      <td>-11.609434</td>\n",
       "      <td>-11.605006</td>\n",
       "      <td>0</td>\n",
       "      <td>7.279783</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5000 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      cdr3LogObsFreq  cdr3LogProb_byTestSet  cdr3LogProb_byTrainSet       n  \\\n",
       "1970       -6.620790             -13.671936              -13.671185  105970   \n",
       "1968       -6.620790             -17.000765              -17.006995  105968   \n",
       "1954       -6.620790             -15.861177              -15.846868  105954   \n",
       "1955       -6.620790             -13.604174              -13.587427  105955   \n",
       "1956       -6.620790             -11.569301              -11.588902  105956   \n",
       "1957       -6.620790             -14.527693              -14.515023  105957   \n",
       "1958       -6.620790             -15.357657              -15.362452  105958   \n",
       "1959       -6.620790             -29.904584              -29.858379  105959   \n",
       "1969       -6.620790             -13.081124              -13.116516  105969   \n",
       "1960       -6.620790             -12.853359              -12.890930  105960   \n",
       "1962       -6.620790             -13.701730              -13.673515  105962   \n",
       "1963       -6.620790             -13.895297              -13.875929  105963   \n",
       "1964       -6.620790             -12.115384              -12.158955  105964   \n",
       "1965       -6.620790             -19.826582              -19.834969  105965   \n",
       "1966       -6.620790             -17.281294              -17.269163  105966   \n",
       "1967       -6.620790             -11.544867              -11.545828  105967   \n",
       "1961       -6.620790             -14.218121              -14.205201  105961   \n",
       "23         -6.620790             -14.822526              -14.857966  116023   \n",
       "1987       -6.620790             -14.254417              -14.293950  105987   \n",
       "1989       -6.620790             -24.435577              -24.449008  105989   \n",
       "8          -6.620790             -13.380886              -13.391915  116008   \n",
       "9          -6.620790             -16.217121              -16.201927  116009   \n",
       "10         -6.620790             -12.666215              -12.657042  116010   \n",
       "11         -6.620790             -12.996748              -12.992670  116011   \n",
       "12         -6.620790             -16.706430              -16.693727  116012   \n",
       "13         -6.620790             -13.568317              -13.531833  116013   \n",
       "7          -6.620790             -17.814205              -17.790747  116007   \n",
       "14         -6.620790             -14.146132              -14.153515  116014   \n",
       "16         -6.620790             -11.168985              -11.178500  116016   \n",
       "17         -6.620790             -26.794841              -26.768943  116017   \n",
       "...              ...                    ...                     ...     ...   \n",
       "30         -5.745729             -15.407539              -15.409474      30   \n",
       "28         -5.717700             -17.611096              -17.605726      28   \n",
       "27         -5.717700             -16.944313              -16.943873      27   \n",
       "26         -5.717700             -12.802490              -12.814696      26   \n",
       "25         -5.717700             -10.500384              -10.519780      25   \n",
       "24         -5.717700             -26.848713              -26.758339      24   \n",
       "23         -5.666547             -15.182001              -15.173847      23   \n",
       "22         -5.643066             -11.600916              -11.618508      22   \n",
       "21         -5.643066             -16.585454              -16.639591      21   \n",
       "20         -5.620790             -15.918760              -15.931641      20   \n",
       "19         -5.620790             -11.080888              -11.089596      19   \n",
       "18         -5.620790             -15.295244              -15.293409      18   \n",
       "17         -5.599601             -10.881120              -10.892486      17   \n",
       "16         -5.579397             -22.972234              -22.932834      16   \n",
       "15         -5.506847             -11.559209              -11.574646      15   \n",
       "13         -5.474662             -16.449625              -16.474695      13   \n",
       "14         -5.474662             -23.129566              -23.092148      14   \n",
       "12         -5.416670             -18.362312              -18.349464      12   \n",
       "11         -5.403306             -10.840735              -10.808911      11   \n",
       "10         -5.403306             -10.940993              -10.918379      10   \n",
       "9          -5.377752             -18.198251              -18.185140       9   \n",
       "8          -5.365517              -9.502029               -9.516703       8   \n",
       "7          -5.353618             -13.515327              -13.527902       7   \n",
       "6          -5.319760             -11.062606              -11.077759       6   \n",
       "5          -5.298571             -12.010372              -12.018808       5   \n",
       "4          -5.259062             -13.720593              -13.735152       4   \n",
       "3          -5.115640             -13.891303              -13.880698       3   \n",
       "2          -4.992401             -15.764890              -15.770428       2   \n",
       "1          -4.967577             -55.784834              -55.721740       1   \n",
       "0          -4.325223             -11.609434              -11.605006       0   \n",
       "\n",
       "      logFoldDiffObsToPredict  \n",
       "1970                 7.050395  \n",
       "1968                10.386205  \n",
       "1954                 9.226078  \n",
       "1955                 6.966637  \n",
       "1956                 4.968112  \n",
       "1957                 7.894233  \n",
       "1958                 8.741662  \n",
       "1959                23.237589  \n",
       "1969                 6.495726  \n",
       "1960                 6.270140  \n",
       "1962                 7.052725  \n",
       "1963                 7.255139  \n",
       "1964                 5.538165  \n",
       "1965                13.214179  \n",
       "1966                10.648373  \n",
       "1967                 4.925038  \n",
       "1961                 7.584411  \n",
       "23                   8.237176  \n",
       "1987                 7.673160  \n",
       "1989                17.828218  \n",
       "8                    6.771125  \n",
       "9                    9.581137  \n",
       "10                   6.036252  \n",
       "11                   6.371880  \n",
       "12                  10.072937  \n",
       "13                   6.911043  \n",
       "7                   11.169957  \n",
       "14                   7.532725  \n",
       "16                   4.557710  \n",
       "17                  20.148153  \n",
       "...                       ...  \n",
       "30                   9.663745  \n",
       "28                  11.888026  \n",
       "27                  11.226173  \n",
       "26                   7.096996  \n",
       "25                   4.802080  \n",
       "24                  21.040639  \n",
       "23                   9.507299  \n",
       "22                   5.975442  \n",
       "21                  10.996524  \n",
       "20                  10.310851  \n",
       "19                   5.468806  \n",
       "18                   9.672619  \n",
       "17                   5.292886  \n",
       "16                  17.353437  \n",
       "15                   6.067800  \n",
       "13                  11.000033  \n",
       "14                  17.617486  \n",
       "12                  12.932794  \n",
       "11                   5.405605  \n",
       "10                   5.515073  \n",
       "9                   12.807388  \n",
       "8                    4.151186  \n",
       "7                    8.174283  \n",
       "6                    5.757999  \n",
       "5                    6.720238  \n",
       "4                    8.476090  \n",
       "3                    8.765058  \n",
       "2                   10.778027  \n",
       "1                   50.754163  \n",
       "0                    7.279783  \n",
       "\n",
       "[5000 rows x 5 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax=None\n",
    "\n",
    "df=df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_var = 'cdr3LogProb_byTrainSet'\n",
    "y_var = 'cdr3LogObsFreq'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x=df[x_var]\n",
    "y=df[y_var]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "defined variables...\n"
     ]
    }
   ],
   "source": [
    "ymean=df[y_var].mean()\n",
    "filename = '/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/SuffStat Images/CDR3_freqs_obs_to_predict_correl-first5000combinations'\n",
    "print 'defined variables...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "plotted graph...\n"
     ]
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "if ax is None:\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(x,y, marker='o', linestyle='', ms=6) \n",
    "#label=name,c=color_list[count])\n",
    "\n",
    "print 'plotted graph...'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "added labels...\n"
     ]
    }
   ],
   "source": [
    "ax.set_xlabel(x_var)\n",
    "ax.set_ylabel(y_var)\n",
    "plt.suptitle('CDR3_freqs_obs_to_predict_correl\\n First5000combinations',fontsize=14)\n",
    "\n",
    "#ax.legend(loc=1)\n",
    "print 'added labels...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# fit with np.polyfit\n",
    "nx=np.isnan(x)\n",
    "ny=np.isnan(y)\n",
    "n=nx+ny\n",
    "newx=list(x[~n])\n",
    "newy=list(y[~n])\n",
    "ax.plot(np.unique(newx), np.poly1d(np.polyfit(newx, newy, 1))(np.unique(newx)),c='black')\n",
    "ax.plot(x=x,c='black', linewidth=4)\n",
    "\n",
    "print 'fitted regression line...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#get positions for text:\n",
    "\n",
    "ylim=ax.get_ylim()\n",
    "ypos=ylim[1]\n",
    "xlim=ax.get_xlim()\n",
    "xpos=xlim[0]\n",
    "        \n",
    "#calculate pearson:\n",
    "r,p=MyPearsonr(x,y)\n",
    "\n",
    "print 'calculated pearson...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ax.text(xpos,ypos,\"r=%.4f p=%.6f\" %(r,p),  verticalalignment = 'top', ha = 'left',fontsize=14,color='red')\n",
    "fig.subplots_adjust(top=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ax=None\n",
    "\n",
    "df=df\n",
    "x_var = 'cdr3LogProb_byTrainSet'\n",
    "y_var = 'cdr3LogObsFreq'\n",
    "\n",
    "x=df[x_var]\n",
    "y=df[y_var]\n",
    "ymean=df[y_var].mean()\n",
    "filename = '/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/SuffStat/SuffStat Images/CDR3_freqs_obs_to_predict_correl-first5000combinations'\n",
    "print 'defined variables...'\n",
    "\n",
    "fig = plt.figure()\n",
    "if ax is None:\n",
    "    ax = fig.add_subplot(111)\n",
    "\n",
    "ax.plot(x,y, marker='o', linestyle='', ms=6) \n",
    "#label=name,c=color_list[count])\n",
    "\n",
    "print 'plotted graph...'\n",
    "\n",
    "ax.set_xlabel(x_var)\n",
    "ax.set_ylabel(y_var)\n",
    "plt.suptitle('CDR3_freqs_obs_to_predict_correl\\n First5000combinations',fontsize=14)\n",
    "\n",
    "#ax.legend(loc=1)\n",
    "print 'added labels...'\n",
    "\n",
    "# fit with np.polyfit\n",
    "nx=np.isnan(x)\n",
    "ny=np.isnan(y)\n",
    "n=nx+ny\n",
    "newx=list(x[~n])\n",
    "newy=list(y[~n])\n",
    "ax.plot(np.unique(newx), np.poly1d(np.polyfit(newx, newy, 1))(np.unique(newx)),c='black')\n",
    "ax.plot(x=x,c='black', linewidth=4)\n",
    "\n",
    "print 'fitted regression line...'\n",
    "        \n",
    "#get positions for text:\n",
    "\n",
    "ylim=ax.get_ylim()\n",
    "ypos=ylim[1]\n",
    "xlim=ax.get_xlim()\n",
    "xpos=xlim[0]\n",
    "        \n",
    "#calculate pearson:\n",
    "r,p=MyPearsonr(x,y)\n",
    "\n",
    "print 'calculated pearson...'\n",
    "    \n",
    "\n",
    "ax.text(xpos,ypos,\"r=%.4f p=%.6f\" %(r,p),  verticalalignment = 'top', ha = 'left',fontsize=14,color='red')\n",
    "fig.subplots_adjust(top=0.8)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "show correlation plots in the ppt and summarize\n",
    "go to igur:\n",
    "predict events probabilities for all sequences in a specific sample and then use this sample for 'within samples' analysis.\n",
    "if plausible, predict events probabilities for all samples, and use 'between samples 0.5:0.5' method to repeat the analysis.\n",
    "try to predict productive sequences by the non-productive model (start with one sample!)\n",
    "\n",
    "go to the 'non-productive' clonality issues...\n",
    "predicting ethnicity or age by the repertoire?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
