{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T14:18:17.605596Z",
     "start_time": "2018-05-13T14:18:14.569463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done1\n",
      "stop\n",
      "stop\n",
      "done1\n",
      "stop\n",
      "done\n",
      "done\n"
     ]
    }
   ],
   "source": [
    "from os import listdir,mkdir,makedirs\n",
    "from os.path import isfile, join, isdir,exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from myplots import roundup, rounddown, find_decimal_fold, percentile_cut_off, rarefaction_calc, rarefaction_plot,draw_correlation_scatter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import cPickle as pickle\n",
    "from Bio.SeqUtils import GC\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "from skbio.diversity.alpha import shannon, simpson, berger_parker_d\n",
    "\n",
    "from pop_organize import get_sample_data, get_sample_with_dfs\n",
    "from SufficientStatistics import *\n",
    "from MyFunctionsShani import *\n",
    "import math\n",
    "from myplots import roundup, rounddown, find_decimal_fold\n",
    "from skbio.stats.distance import mantel\n",
    "from scipy.spatial.distance import braycurtis, pdist\n",
    "from GeneralFeaturePhenotypeInteractions.Feature_phenotype_functions import * \n",
    "from TCR_microbiome_interactions.TCR_microbiome_interactions_functions import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-05-13T14:18:17.751440Z",
     "start_time": "2018-05-13T14:18:17.742114Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'13052018'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "cdate=str(time.strftime(\"%d%m%Y\"))\n",
    "cdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# explore BD-FD table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "readCountFolder='Metabolon2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/updatedBDandFDlists/final_BD_FD_converter_mergedOnYear_RCfolder%s_18032018.xlsx' %readCountFolder\n",
    "final_BD_FD_converter_mergedOnYear_16032018=pd.read_excel(file1)\n",
    "final_BD_FD_converter_mergedOnYear_16032018.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# how many samples are genotek and how many are swabs?\n",
    "final_BD_FD_converter_mergedOnYear_16032018['isGenotek'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_BD_FD_converter_mergedOnYear_16032018['BD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#divide sample to Genotek and no Genotek\n",
    "noGenotek=final_BD_FD_converter_mergedOnYear_16032018[final_BD_FD_converter_mergedOnYear_16032018['isGenotek']!=1]\n",
    "Genotek=final_BD_FD_converter_mergedOnYear_16032018[final_BD_FD_converter_mergedOnYear_16032018['isGenotek']==1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noGenotek['BD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio=final_BD_FD_converter_mergedOnYear_16032018[final_BD_FD_converter_mergedOnYear_16032018['BD_index']>949]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cardio.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define pnp samples only:\n",
    "pnp=final_BD_FD_converter_mergedOnYear_16032018[final_BD_FD_converter_mergedOnYear_16032018['BD_index']<951]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnp.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique BDs in the PNP cohort:\n",
    "pnp['BD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define pnp swab samples only. there are 1446 such samples\n",
    "pnp_swabs=pnp[pnp['isGenotek']!=1]\n",
    "print len(pnp_swabs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#with currently 869 unique BD matched\n",
    "pnp_swabs['BD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pnp BD samples with matched FD that has postHGF info: (921 samples currently)\n",
    "pnp_postHGF=pnp[pnp['PostHGF'].notnull()]\n",
    "pnp_postHGF['BD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pnp BD swab samples with postHGF info-two ways to calculate - in both we get 636 samples\n",
    "pnp_postHGF_swab1=pnp_postHGF[pnp_postHGF['isGenotek']!=1]\n",
    "pnp_postHGF_swab2=pnp_swabs[pnp_swabs['PostHGF'].notnull()]\n",
    "print pnp_postHGF_swab1['BD'].nunique()\n",
    "print pnp_postHGF_swab2['BD'].nunique()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/BD lists/PNP434samples','rb') as fp:\n",
    "    pnp434samples=pickle.load(fp)\n",
    "pnp434samples[-10:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#431 samples in this cohort have matched FD\n",
    "pnp[pnp['BD'].isin(pnp434samples)]['BD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are 405 out of 434 samples in the PNP434 cohort that have at least one swab FD sample:\n",
    "pnp_swabs_434=pnp_swabs[pnp_swabs['BD'].isin(pnp434samples)]\n",
    "print pnp_swabs_434['BD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pnp_postHGF_434=pnp_postHGF[pnp_postHGF['BD'].isin(pnp434samples)]\n",
    "print pnp_postHGF_434['BD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#only 270 out of these samples have read count info!\n",
    "pnp_swabs_434[pnp_swabs_434['PostHGF'].notnull()]['BD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#266 out of 270 samples have at least 9000000 read counts.\n",
    "pnp_swabs_434[pnp_swabs_434['PostHGF']>9000000]['BD'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#266 out of 270 samples have at least 9000000 read counts.\n",
    "pnp_swabs_434[pnp_swabs_434['PostHGF']>8000000]['BD'].nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NEED TO UNDERSTAND WHY SO MANY SAMPLES DON'T HAVE READ COUNT INFO!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## explore how many samples in the original file don't have this data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "folder='/net/mraid08/export/jafar/Microbiome/Analyses/AllSeqProjects/DFOut'\n",
    "filenames = [f for f in listdir(folder) if isfile(join(folder, f))]\n",
    "filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1='/net/mraid08/export/jafar/Microbiome/Analyses/AllSeqProjects/DFOut/ReadCountSpidDF.dat'\n",
    "ReadCountSpidDF=pd.read_pickle(f1)\n",
    "ReadCountSpidDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReadCountSpidDF=ReadCountSpidDF.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(ReadCountSpidDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ReadCountSpidDF[ReadCountSpidDF['PostHGF'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FDlist=list(ReadCountSpidDF['FD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1='/net/mraid08/export/jafar/Microbiome/Analyses/AllSeqProjects/DFOut/MPASpid.dat'\n",
    "MPASpid=pd.read_pickle(f1)\n",
    "MPASpid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(MPASpid.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in MPASpid.columns.values:\n",
    "    newColumn=column.split('_')[0]\n",
    "#     print column\n",
    "#     print newColumn\n",
    "    MPASpid=MPASpid.rename(columns={column:newColumn})\n",
    "MPASpid.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# check if all FDs in MPA file exist in read count file:\n",
    "a=MPASpid.columns.values\n",
    "b=FDlist\n",
    "print len(set(a).intersection(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all samples in MPA file appear in the read count file! and thus have read count info"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# filtering FD-based data:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.take data df, \n",
    "2. merge with BD-FD conversion table\n",
    "3.Edit sample names\n",
    "4.Filter on isGenotek=0\n",
    "5.Filter on minimal number of reads\n",
    "6.Filter on meet location\n",
    "7.Filter same person\n",
    "8. Filter outliers\n",
    "9. filter out non-complete matches if there is at least one complete match for the BD\n",
    "9. filter for specific BD samples\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### THIS FUNCTION WAS COPIED TO Feature_phenotype_functions.py - UPDATE THERE!!!\n",
    "\n",
    "this function takes an FD-based data table (can use also other identifiers such as SPID, connection)\n",
    "merge it with the BD-FD conversion table, and then filter the data based on specific sample list, only\n",
    "swab samples and/or minimal reads per sample.\n",
    "\n",
    "the required input:\n",
    "dataDF: FD-based table, with samples as rows and phenotypes as columns (for example - microbiome species \n",
    "relative abundances) ####make sure the column to merge on is not the index!! ###\n",
    "dataDFname - a string, such as MPA_s\n",
    "dataMergeOn- the name of the column in the dataDF table to merge on ###don't forget to reset_index if necessary\n",
    "BDFDMergeOn- the name of the column in the BD_FD table to merge on\n",
    "Sample list - None, or python list of BD numbers in the format: ['BD1','BD2'...]\n",
    "SampleListName-None or the list name\n",
    "filterGenotek - True/False. True will lead to filtering out of all samples with isGenotek==1. samples with\n",
    "no indication at all won't be filtered out.\n",
    "filterMinimalReads - None, or a number. recommended value is 9000000\n",
    "folderToSave=None or full path to the required folder\n",
    "\n",
    "'''\n",
    "\n",
    "\n",
    "def filter_data_on_FDproperties(readCountFolder,dataDF,dataDFname,dataMergeOn,BDFDMergeOn,SampleList=None,\n",
    "                                SampleListName=None,filterGenotek=False, filterMinimalReads=9000000,\n",
    "                               folderToSave=None):\n",
    "    \n",
    "      if BD_FD is None:\n",
    "        print 'using BD_FD converter based on AllSeqProjects folder, date 17042018'\n",
    "        f1 = '/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/updatedBDandFDlists/final_BD_FD_converter_mergedOnYear_RCfolderAllSeqProjects_17042018'          \n",
    "        BD_FD = pd.read_pickle(f1)\n",
    "    print 'row number in BD_FD table is %s' % len(BD_FD)\n",
    "    \n",
    "    #merging:\n",
    "    print 'merging dataDF with FD-BD table:'\n",
    "\n",
    "    dataWithMeta=pd.merge(dataDF,BD_FD,how='left', left_on=dataMergeOn, right_on=BDFDMergeOn)\n",
    "    print 'row number in dataDF before merging was %s' %len(dataDF)\n",
    "    print 'row number after merging is %s' %len(dataWithMeta)\n",
    "    \n",
    "    ### if required - filter on specific BDs, if not-filter on samples that have any BD:\n",
    "    if SampleList is None:\n",
    "        print 'filtering out all FD samples without BDs'\n",
    "        dataWithMeta=dataWithMeta[dataWithMeta['BD'].notnull()]\n",
    "        print 'row number after filtering is %s' %len(dataWithMeta)\n",
    "    else:\n",
    "        print 'filtering out all FD that are not matched to any BD in the sample list' \n",
    "        dataWithMeta=dataWithMeta[dataWithMeta['BD'].isin(SampleList)]\n",
    "        print 'row number after filtering is %s' %len(dataWithMeta)\n",
    "        \n",
    "    ### if required filter on isGenotek\n",
    "    if filterGenotek:\n",
    "        print 'filtering out genotek samples'\n",
    "        dataWithMeta=dataWithMeta[dataWithMeta['isGenotek']!=1]\n",
    "        print 'row number after filtering is %s' %len(dataWithMeta)\n",
    "        \n",
    "    ### if required, filter on minimal number of reads\n",
    "    if filterMinimalReads is not None:\n",
    "        print 'filtering out samples with read number after HGF=%s' %filterMinimalReads\n",
    "        dataWithMeta=dataWithMeta[dataWithMeta['PostHGF']>filterMinimalReads]\n",
    "        print 'row number after filtering is %s' %len(dataWithMeta)\n",
    "        \n",
    "    ### indicating final number of BDs and FDs in the table:\n",
    "    nBDs=dataWithMeta['BD'].nunique()\n",
    "    nFDs=dataWithMeta['FD'].nunique()\n",
    "\n",
    "    print 'final number of unique BDs is %s and unique FDs is %s' %(nBDs, nFDs)\n",
    "    \n",
    "    ### save to file:\n",
    "    fileName='%s_SampleList%s_filterGenotek%s_filterMinimalRead%s' %(dataDFname,SampleListName,filterGenotek,\n",
    "                                                                filterMinimalReads)\n",
    "    if folderToSave is None:\n",
    "        folderToSave='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/FilteredDataTables'\n",
    "\n",
    "    print 'saving filtered data table to folder %s' % folderToSave   \n",
    "    if not isdir(folderToSave):\n",
    "            makedirs(folderToSave)\n",
    "    f1='%s/%s' %(folderToSave,fileName)    \n",
    "    dataWithMeta.to_pickle(f1)\n",
    "    \n",
    "    return dataWithMeta\n",
    "    \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RUN FUNCTION:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPECIES LEVEL, PNP434samples, no additional filtering:\n",
    "\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/notFiltered/MPA_s_Metabolon2_RA'\n",
    "MPAlevel=pd.read_pickle(f1)\n",
    "\n",
    "#LOAD pnp434 sample list:\n",
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/BD lists/PNP434samples','rb') as fp:\n",
    "    PNP434samples=pickle.load(fp)\n",
    "    \n",
    "\n",
    "readCountFolder='Metabolon2'\n",
    "dataDF=MPAlevel.reset_index()\n",
    "dataDFname='MPA_s_Metabolon2'\n",
    "dataMergeOn='FD'\n",
    "BDFDMergeOn='FD'\n",
    "SampleList=PNP434samples\n",
    "SampleListName='PNP434'\n",
    "filterGenotek=False\n",
    "filterMinimalReads=None\n",
    "folderToSave='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/Filtered'\n",
    "\n",
    "\n",
    "\n",
    "dataWithMeta=filter_data_on_FDproperties(readCountFolder,dataDF,dataDFname,dataMergeOn,BDFDMergeOn,SampleList=SampleList,\n",
    "                                SampleListName=SampleListName,filterGenotek=filterGenotek, filterMinimalReads=filterMinimalReads,\n",
    "                               folderToSave=folderToSave)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#species level, only pnp434 samples, only swabs, only readcounts>9000000\n",
    "\n",
    "\n",
    "#LOAD DATA DF:\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/notFiltered/MPA_s_Metabolon2_RA'\n",
    "MPAlevel=pd.read_pickle(f1)\n",
    "\n",
    "#LOAD pnp434 sample list:\n",
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/BD lists/PNP434samples','rb') as fp:\n",
    "    PNP434samples=pickle.load(fp)\n",
    "\n",
    "readCountFolder='Metabolon2'\n",
    "dataDF=MPAlevel.reset_index()\n",
    "dataDFname='MPA_s_Metabolon2'\n",
    "dataMergeOn='FD'\n",
    "BDFDMergeOn='FD'\n",
    "SampleList=PNP434samples\n",
    "SampleListName='PNP434'\n",
    "filterGenotek=True\n",
    "filterMinimalReads=9000000\n",
    "folderToSave='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/Filtered'\n",
    "\n",
    "\n",
    "\n",
    "dataWithMeta=filter_data_on_FDproperties(readCountFolder,dataDF,dataDFname,dataMergeOn,BDFDMergeOn,SampleList=SampleList,\n",
    "                                SampleListName=SampleListName,filterGenotek=filterGenotek, filterMinimalReads=filterMinimalReads,\n",
    "                               folderToSave=folderToSave)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## develop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "level='s'\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/notFiltered/MPA_%s_RA' %level\n",
    "MPAlevel=pd.read_pickle(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPAlevel.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MPAlevel.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge with bd-fd table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load bd-fd table (can change the BD-FD converter version by changing the date in the file name)\n",
    "print 'loading BD_FD table'\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/updatedBDandFDlists/final_BD_FD_converter_mergedOnYear_16032018'\n",
    "BD_FD=pd.read_pickle(f1)\n",
    "print 'row number in BD_FD table is %s' %len(BD_FD)\n",
    "BD_FD.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#merging:\n",
    "dataDF=MPAlevel.reset_index() #dataMergedOn shouldnt be the df index!\n",
    "dataMergeOn='FD'\n",
    "BDFDMergeOn='FD'\n",
    "\n",
    "\n",
    "print 'merging dataDF with FD-BD table:'\n",
    "dataWithMeta=pd.merge(dataDF,BD_FD,how='left', left_on=dataMergeOn, right_on=BDFDMergeOn)\n",
    "print 'row number in dataDF before merging was %s' %len(dataDF)\n",
    "print 'row number after merging is %s' %len(dataWithMeta)\n",
    "\n",
    "dataWithMeta.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithMeta[dataWithMeta['PostHGF'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF[dataDF['PostHGF'].isnull()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if required - filter on specific BDs, if not-filter on samples that have any BD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/BD lists/PNP434samples','rb') as fp:\n",
    "    pnp434samples=pickle.load(fp)\n",
    "    \n",
    "SampleList=pnp434samples\n",
    "SampleListName='PNP434'\n",
    "# SampleList=None\n",
    "\n",
    "\n",
    "if SampleList is None:\n",
    "    print 'filtering out all FD samples without BDs'\n",
    "    dataWithMeta=dataWithMeta[dataWithMeta['BD'].notnull()]\n",
    "    print 'row number after filtering is %s' %len(dataWithMeta)\n",
    "else:\n",
    "    print 'filtering out all FD that are not matched to any BD in the sample list' \n",
    "    dataWithMeta=dataWithMeta[dataWithMeta['BD'].isin(SampleList)]\n",
    "    print 'row number after filtering is %s' %len(dataWithMeta)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if required filter on isGenotek"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterGenotek=True\n",
    "\n",
    "if filterGenotek:\n",
    "    print 'filtering out genotek samples'\n",
    "    dataWithMeta=dataWithMeta[dataWithMeta['isGenotek']!=1]\n",
    "    print 'row number after filtering is %s' %len(dataWithMeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if required, filter on minimal number of reads"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterMinimalReads=9000000\n",
    "\n",
    "if filterMinimalReads is not None:\n",
    "    print 'filtering out samples with read number after HGF=%s' %filterMinimalReads\n",
    "    dataWithMeta=dataWithMeta[dataWithMeta['PostHGF']>filterMinimalReads]\n",
    "    print 'row number after filtering is %s' %len(dataWithMeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### indicating final number of BDs and FDs in the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nBDs=dataWithMeta['BD'].nunique()\n",
    "nFDs=dataWithMeta['FD'].nunique()\n",
    "\n",
    "print 'final number of unique BDs is %s and unique FDs is %s' %(nBDs, nFDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "266./434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filtering out FDs with non complete match to BD - not implmented, as it seems that there no BDs with both complete and incomplete match...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filterIncompleteMatches=True\n",
    "\n",
    "# if filterIncompleteMatches:\n",
    "#     BDlist=list(dataWithMeta['BD'])\n",
    "#     for BD in BDlist:\n",
    "#         nBD=BDlist.count(BD)\n",
    "# #         print BD,nBD\n",
    "#         if nBD>1:\n",
    "#             BDdf=dataWithMeta[dataWithMeta['BD']==BD]\n",
    "#             FDlist=list(BDdf['FD'])\n",
    "#             print BD,nBD,FDlist\n",
    "            \n",
    "#             nNonComments=len(BDdf[BDdf['Comment']!='Not the same Year!!'])\n",
    "#             print nNonComments\n",
    "# #             print BDdf['Comment']\n",
    "#             if nNonComments>0:\n",
    "#                 for n in BDdf.index:\n",
    "#                     if BDdf.loc[n,'Comment']=='Not the same Year!!':\n",
    "#                         print BDdf.loc[:,['BD','FD','Comment']]\n",
    "#                         print 'dropping sample %s' %dataWithMeta.loc[n,'FD']\n",
    "#                         print BDdf.loc[n,['BD','FD','Comment']]\n",
    "#                         dataWithMeta=dataWithMeta.drop(n,axis=0) \n",
    "                        \n",
    "            \n",
    "            \n",
    "            \n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save filtered list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folderToSave=None\n",
    "dataDFname='MPA_s'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileName='%s_SampleList%s_filterGenotek%s_filterMinimalRead%s' %(dataDFname,SampleListName,filterGenotek,\n",
    "                                                                filterMinimalReads)\n",
    "if folderToSave is None:\n",
    "    folderToSave='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/FilteredDataTables'\n",
    "    \n",
    "print 'saving filtered data table to folder %s' % folderToSave\n",
    "if not isdir(folderToSave):\n",
    "            makedirs(folderToSave)\n",
    "\n",
    "f1='%s/%s' %(folderToSave,fileName)    \n",
    "dataWithMeta.to_pickle(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithMeta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# merging on BD numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "### THIS FUNCTION WAS COPIED TO Feature_phenotype_functions.py - UPDATE THERE!!!\n",
    "\n",
    "the following functions takes DF tables that include 'BD' column and groups the data based on this column\n",
    "\n",
    "\n",
    "input:\n",
    "*DFtoGroup - sampleXphenotype dataframe, 'BD' column should exist\n",
    "*DFtoGroupName - a string\n",
    "*groupFunction='noOutlierMean'/'mean'/'mostFrequent'/'binarySelection'\n",
    "*filterOutlierSamples=True/False\n",
    "*filterSamePerson=True/False\n",
    "*folderToSave=None/full path to folder\n",
    "\n",
    "*nSTD - must be None if mergeFunction is not 'noOutlierMean' this defines the number of STD from the mean\n",
    "to define low/high threshold for non-outlier samples. this apply to the BD merging procedure and not the \n",
    "outlier removal which is currently constant at 3. \n",
    "*nMinSamples - must be None if mergeFunction is not 'noOutlierMean'.this defines the minimal number of \n",
    "samples to apply samples filtering. this apply to the BD merging procedure and not the \n",
    "outlier removal which is currently constant at 3. \n",
    "\n",
    "'''\n",
    "\n",
    "def mergeOnBD(DFtoGroup,DFtoGroupName,groupFunction,filterOutlierSamples,filterSamePerson,folderToSave,nSTD=None,\n",
    "              nMinSamples=None):\n",
    "    print 'loading again BD_FD table'\n",
    "    f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/updatedBDandFDlists/final_BD_FD_converter_mergedOnYear_16032018'\n",
    "    BD_FD=pd.read_pickle(f1)\n",
    "    \n",
    "    for column in DFtoGroup.columns.values:\n",
    "        if column!='BD':\n",
    "            if column in BD_FD.columns.values:\n",
    "                DFtoGroup=DFtoGroup.drop(column,axis=1)\n",
    "    \n",
    "    \n",
    "    ### group on BD, using the selected mergeFunction:\n",
    "    print 'df length before grouping is %s' %len(DFtoGroup)\n",
    "    print 'grouping on BD using %s' %groupFunction\n",
    "    if groupFunction=='noOutlierMean':\n",
    "        groupedDF=DFtoGroup.groupby('BD').agg(lambda x: noOutlierMean(x,nSTD,nMinSamples))\n",
    "    elif groupFunction=='mean':\n",
    "        groupedDF=DFtoGroup.groupby('BD').mean()\n",
    "    elif groupFunction=='mostFrequent':   \n",
    "        import collections\n",
    "        groupedDF=DFtoGroup.groupby('BD').agg(lambda x: collections.Counter(x).most_common()[0][0])\n",
    "    elif groupFunction=='binarySelection':\n",
    "        groupedDF=DFtoGroup.groupby('BD').agg(lambda x: 1 if 1 in list(x) else 0)\n",
    "    print 'grouped table length after grouping by BD and outlier removal=%s' %len(groupedDF)\n",
    "    \n",
    "    ### filter same person:\n",
    "    if filterSamePerson:     \n",
    "        # get again UserIDs for BD samples:\n",
    "\n",
    "        BD_FD_toUse=BD_FD[['BD','UserID']]\n",
    "        BD_FD_toUse=BD_FD_toUse.drop_duplicates()\n",
    "        print 'number of BD-UserID pairs is %s' %len(BD_FD_toUse)\n",
    "\n",
    "        print 'merging UserID info to BDgrouped table:'\n",
    "        groupedDF=pd.merge(groupedDF,BD_FD_toUse,how='left',left_index=True,right_on='BD')\n",
    "\n",
    "        # counting how many User IDs have more than one BD:\n",
    "        BDrepeats=pd.DataFrame(groupedDF['UserID'].value_counts())\n",
    "        nRepeatingBDs=len(BDrepeats[BDrepeats['UserID']>1])\n",
    "        print '%s UserIDs have more than one BD' %nRepeatingBDs\n",
    "        \n",
    "        #dropping same person samples (leaving the last one)\n",
    "        print 'groupedDF length before dropping same person samples is %s' %len(groupedDF)\n",
    "        groupedDF=groupedDF.drop_duplicates(subset='UserID',keep='last')\n",
    "        print 'groupedDF length after dropping same person samples is %s' %len(groupedDF)\n",
    "        \n",
    "    ### if required, filter outlier samples:\n",
    "    if filterOutlierSamples:\n",
    "        print 'filtering outlier samples...'\n",
    "        groupedDF=filter_phenotypiclly_outlier_samples(groupedDF,nSTD=3,nMinSamples=3)\n",
    "        print 'groupedDF length after dropping outlier samples is %s' %len(groupedDF)\n",
    "        groupedDF=groupedDF.set_index('BD')\n",
    "        \n",
    "    ### save groupedDF:\n",
    "    ### save to file:\n",
    "    fileName='%s_%snSTD%snMinSamples%s_filterOutlierSample%s_filterSamePerson%s' %(DFtoGroupName,groupFunction,\n",
    "                                                                nSTD,nMinSamples,filterOutlierSamples,\n",
    "                                                                filterSamePerson,)\n",
    "\n",
    "    if folderToSave is None:\n",
    "        folderToSave='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/MergedOnBDDataTables'\n",
    "\n",
    "    print 'saving mergedOnBDs data table to folder %s' % folderToSave   \n",
    "    if not isdir(folderToSave):\n",
    "            makedirs(folderToSave)\n",
    "    f1='%s/%s' %(folderToSave,fileName)    \n",
    "    groupedDF.to_pickle(f1)\n",
    "    \n",
    "    print 'done!'\n",
    "    \n",
    "    return groupedDF    \n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### run function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##take pnp434 non filtered MPA_s and merge on BD,filter same person but not outliers:\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/Filtered/MPA_s_Metabolon2_SampleListPNP434_filterGenotekFalse_filterMinimalReadNone'\n",
    "MPA_PNP434_notfiltered=pd.read_pickle(f1)\n",
    "\n",
    "\n",
    "DFtoGroup=MPA_PNP434_notfiltered\n",
    "DFtoGroupName='MPA_s_Metabolon2_PNP434_notfiltered'\n",
    "groupFunction='noOutlierMean'\n",
    "filterOutlierSamples=False\n",
    "filterSamePerson=True\n",
    "folderToSave='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/FilteredAndMergedOnBD'\n",
    "nSTD=3,\n",
    "nMinSamples=3\n",
    "\n",
    "groupedDF=mergeOnBD(DFtoGroup,DFtoGroupName,groupFunction,filterOutlierSamples,filterSamePerson,folderToSave,nSTD=nSTD,\n",
    "              nMinSamples=nMinSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##take pnp434 non filtered MPA_s and merge on BD,filter same person but not outliers ### grouping function is mean!\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/Filtered/MPA_s_Metabolon2_SampleListPNP434_filterGenotekFalse_filterMinimalReadNone'\n",
    "MPA_PNP434_notfiltered=pd.read_pickle(f1)\n",
    "\n",
    "\n",
    "DFtoGroup=MPA_PNP434_notfiltered\n",
    "DFtoGroupName='MPA_s_Metabolon2_PNP434_notfiltered'\n",
    "groupFunction='mean'\n",
    "filterOutlierSamples=False\n",
    "filterSamePerson=True\n",
    "folderToSave='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/FilteredAndMergedOnBD'\n",
    "nSTD=3,\n",
    "nMinSamples=3\n",
    "\n",
    "groupedDF=mergeOnBD(DFtoGroup,DFtoGroupName,groupFunction,filterOutlierSamples,filterSamePerson,folderToSave,nSTD=nSTD,\n",
    "              nMinSamples=nMinSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##take pnp434 MPA_s filtered on swabs and minimal read count and merge on BD,\n",
    "#then filter same person but not outliers:\n",
    "\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/Filtered/MPA_s_Metabolon2_SampleListPNP434_filterGenotekTrue_filterMinimalRead9000000'\n",
    "MPA_PNP434_filGenotek_fil9000000reads=pd.read_pickle(f1)\n",
    "\n",
    "\n",
    "DFtoGroup=MPA_PNP434_filGenotek_fil9000000reads\n",
    "DFtoGroupName='MPA_s_Metabolon2_PNP434_filGenotek_fil9000000reads'\n",
    "groupFunction='noOutlierMean'\n",
    "filterOutlierSamples=False\n",
    "filterSamePerson=True\n",
    "folderToSave='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/FilteredAndMergedOnBD'\n",
    "nSTD=3,\n",
    "nMinSamples=3\n",
    "\n",
    "groupedDF=mergeOnBD(DFtoGroup,DFtoGroupName,groupFunction,filterOutlierSamples,filterSamePerson,folderToSave,nSTD=nSTD,\n",
    "              nMinSamples=nMinSamples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##take pnp434 MPA_s filtered on swabs and minimal read count and merge on BD,#### group function is mean!!\n",
    "#then filter same person but not outliers:\n",
    "\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/Filtered/MPA_s_Metabolon2_SampleListPNP434_filterGenotekTrue_filterMinimalRead9000000'\n",
    "MPA_PNP434_filGenotek_fil9000000reads=pd.read_pickle(f1)\n",
    "\n",
    "\n",
    "DFtoGroup=MPA_PNP434_filGenotek_fil9000000reads\n",
    "DFtoGroupName='MPA_s_Metabolon2_PNP434_filGenotek_fil9000000reads'\n",
    "groupFunction='mean'\n",
    "filterOutlierSamples=False\n",
    "filterSamePerson=True\n",
    "folderToSave='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/FilteredAndMergedOnBD'\n",
    "nSTD=3,\n",
    "nMinSamples=3\n",
    "\n",
    "groupedDF=mergeOnBD(DFtoGroup,DFtoGroupName,groupFunction,filterOutlierSamples,filterSamePerson,folderToSave,nSTD=nSTD,\n",
    "              nMinSamples=nMinSamples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## develop:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load filtered MPA table: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/Filtered/MPA_s_SampleListNone_filterGenotekFalse_filterMinimalReadNone'\n",
    "MPAnotfiltered=pd.read_pickle(f1)\n",
    "print len(MPAnotfiltered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### group on BD, using the selected mergeFunction:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFtoGroup=MPAnotfiltered\n",
    "groupFunction='noOutlierMean'\n",
    "nSTD=3\n",
    "nMinSamples=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'df length before grouping is %s' %len(DFtoGroup)\n",
    "print 'grouping on BD using %s' %groupFunction\n",
    "if groupFunction=='noOutlierMean':\n",
    "    groupedDF=DFtoGroup.groupby('BD').agg(lambda x: noOutlierMean(x,nSTD,nMinSamples))\n",
    "elif groupFunction=='mean':\n",
    "    groupedDF=DFtoGroup.groupby('BD').mean()\n",
    "elif groupFunction=='mostFrequent':   \n",
    "    import collections\n",
    "    groupedDF=DFtoGroup.groupby('BD').agg(lambda x: collections.Counter(x).most_common()[0][0])\n",
    "elif groupFunction=='binarySelection':\n",
    "    groupedDF=DFtoGroup.groupby('BD').agg(lambda x: 1 if 1 in list(x) else 0)\n",
    "print 'grouped table length after grouping by BD and outlier removal=%s' %len(groupedDF)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedDF.index.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### if required, filter outlier samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterOutlierSamples=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filterOutlierSamples:\n",
    "    print 'filtering outlier samples...'\n",
    "    groupedDF=filter_phenotypiclly_outlier_samples(groupedDF,nSTD=3,nMinSamples=3)\n",
    "    print 'groupedDF length after dropping outlier samples is %s' %len(groupedDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### filter same person:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filterSamePerson=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if filterSamePerson:     \n",
    "    # get again UserIDs for BD samples:\n",
    "    print 'loading again BD_FD table'\n",
    "    f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/updatedBDandFDlists/final_BD_FD_converter_mergedOnYear_16032018'\n",
    "    BD_FD=pd.read_pickle(f1)\n",
    "    BD_FD_toUse=BD_FD[['BD','UserID']]\n",
    "    BD_FD_toUse=BD_FD_toUse.drop_duplicates()\n",
    "    print 'number of BD-UserID pairs is %s' %len(BD_FD_toUse)\n",
    "\n",
    "    print 'merging UserID info to BDgrouped table:'\n",
    "    groupedDF=pd.merge(groupedDF,BD_FD_toUse,how='left',left_index=True,right_on='BD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# counting how many User IDs have more than one BD:\n",
    "BDrepeats=pd.DataFrame(groupedDF['UserID'].value_counts())\n",
    "nRepeatingBDs=len(BDrepeats[BDrepeats['UserID']>1])\n",
    "print '%s UserIDs have more than one BD' %nRepeatingBDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'groupedDF length before dropping same person samples is %s' %len(groupedDF)\n",
    "groupedDF=groupedDF.drop_duplicates(subset='UserID',keep='last')\n",
    "print 'groupedDF length after dropping same person samples is %s' %len(groupedDF)\n",
    "groupedDF=groupedDF.set_index('BD')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groupedDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save groupedDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DFtoGroupName='MPA_s_notFiltered'\n",
    "folderToSave=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### save to file:\n",
    "fileName='%s_%snSTD%snMinSamples%s_filterOutlierSample%s_filterSamePerson%s' %(DFtoGroupName,groupFunction,\n",
    "                                                            nSTD,nMinSamples,filterOutlierSamples,\n",
    "                                                            filterSamePerson,)\n",
    "\n",
    "if folderToSave is None:\n",
    "    folderToSave='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/MergedOnBDDataTables'\n",
    "\n",
    "print 'saving mergedOnBDs data table to folder %s' % folderToSave   \n",
    "if not isdir(folderToSave):\n",
    "        makedirs(folderToSave)\n",
    "f1='%s/%s' %(folderToSave,fileName)    \n",
    "groupedDF.to_pickle(f1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check number of species in differnt files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# original mb file:\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/notFiltered/MPA_s_Metabolon2_RA'\n",
    "MPA_s_Metabolon2_RA=pd.read_pickle(f1)\n",
    "print len(MPA_s_Metabolon2_RA.columns.values)\n",
    "MPA_s_Metabolon2_RA.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered only to 434 samples:\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/Filtered/MPA_s_Metabolon2_SampleListPNP434_filterGenotekFalse_filterMinimalReadNone'\n",
    "MPA_s_Metabolon2_SampleListPNP434_filterGenotekFalse_filterMinimalReadNone=pd.read_pickle(f1)\n",
    "print len(MPA_s_Metabolon2_SampleListPNP434_filterGenotekFalse_filterMinimalReadNone.columns.values)\n",
    "MPA_s_Metabolon2_SampleListPNP434_filterGenotekFalse_filterMinimalReadNone.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered to 434 samples, swabs minimal read counts:\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/Filtered/MPA_s_Metabolon2_SampleListPNP434_filterGenotekTrue_filterMinimalRead9000000'\n",
    "MPA_s_Metabolon2_SampleListPNP434_filterGenotekTrue_filterMinimalRead9000000=pd.read_pickle(f1)\n",
    "print len(MPA_s_Metabolon2_SampleListPNP434_filterGenotekTrue_filterMinimalRead9000000.columns.values)\n",
    "MPA_s_Metabolon2_SampleListPNP434_filterGenotekTrue_filterMinimalRead9000000.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered to 434 samples ONLY.merged onBD\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/FilteredAndMergedOnBD/MPA_s_Metabolon2_PNP434_notfiltered_noOutlierMeannSTD(3,)nMinSamples3_filterOutlierSampleFalse_filterSamePersonTrue'\n",
    "MPA_s_notfiltered_mergedBD=pd.read_pickle(f1)\n",
    "print len(MPA_s_notfiltered_mergedBD.columns.values)\n",
    "MPA_s_notfiltered_mergedBD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered to 434 samples ONLY.merged onBD\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/FilteredAndMergedOnBD/MPA_s_Metabolon2_PNP434_notfiltered_noOutlierMeannSTD(3,)nMinSamples3_filterOutlierSampleFalse_filterSamePersonTrue'\n",
    "MPA_s_notfiltered_mergedBD=pd.read_pickle(f1)\n",
    "print len(MPA_s_notfiltered_mergedBD.columns.values)\n",
    "MPA_s_notfiltered_mergedBD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered to 434 samples ONLY.merged onBD merge function=mean\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/FilteredAndMergedOnBD/MPA_s_Metabolon2_PNP434_notfiltered_meannSTD(3,)nMinSamples3_filterOutlierSampleFalse_filterSamePersonTrue'\n",
    "MPA_s_notfiltered_mergedBD=pd.read_pickle(f1)\n",
    "print len(MPA_s_notfiltered_mergedBD.columns.values)\n",
    "MPA_s_notfiltered_mergedBD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in MPA_s_Metabolon2_SampleListPNP434_filterGenotekFalse_filterMinimalReadNone.columns.values:\n",
    "    if column not in MPA_s_notfiltered_mergedBD.columns.values:\n",
    "        print column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered to 434 samples SWABS ONLY minimal reads.merged onBD\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/FilteredAndMergedOnBD/MPA_s_Metabolon2_PNP434_filGenotek_fil9000000reads_noOutlierMeannSTD(3,)nMinSamples3_filterOutlierSampleFalse_filterSamePersonTrue'\n",
    "MPA_s_filtered_mergedBD=pd.read_pickle(f1)\n",
    "print len(MPA_s_filtered_mergedBD.columns.values)\n",
    "MPA_s_filtered_mergedBD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered to 434 samples SWABS ONLY minimal reads.merged onBD merge function=mean\n",
    "f1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/MicrobiomeDataTables/FilteredAndMergedOnBD/MPA_s_Metabolon2_PNP434_filGenotek_fil9000000reads_meannSTD(3,)nMinSamples3_filterOutlierSampleFalse_filterSamePersonTrue'\n",
    "MPA_s_filtered_mergedBD=pd.read_pickle(f1)\n",
    "print len(MPA_s_filtered_mergedBD.columns.values)\n",
    "MPA_s_filtered_mergedBD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for column in MPA_s_filtered_mergedBD.columns.values:\n",
    "    if column not in MPA_s_notfiltered_mergedBD.columns.values:\n",
    "        print column\n",
    "        n=n+1\n",
    "print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=0\n",
    "for column in MPA_s_notfiltered_mergedBD.columns.values:\n",
    "    if column not in MPA_s_filtered_mergedBD.columns.values:\n",
    "        print column\n",
    "        n=n+1\n",
    "        \n",
    "print n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1=MPA_s_Metabolon2_SampleListPNP434_filterGenotekFalse_filterMinimalReadNone\n",
    "#check for nans:\n",
    "df[df['Acidaminococcus_fermentans'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Acidaminococcus_fermentans'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Acidaminococcus_fermentans'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=1\n",
    "a>=2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a>=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a>=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a>1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "374px",
    "left": "0px",
    "right": "988.636px",
    "top": "111px",
    "width": "250px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
