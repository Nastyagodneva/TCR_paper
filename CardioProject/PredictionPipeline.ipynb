{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T15:40:50.308086Z",
     "start_time": "2018-07-11T15:40:45.335752Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir,mkdir,makedirs\n",
    "from os.path import isfile, join, isdir,exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from myplots import roundup, rounddown, find_decimal_fold, percentile_cut_off, rarefaction_calc, rarefaction_plot,draw_correlation_scatter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import cPickle as pickle\n",
    "from Bio.SeqUtils import GC\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy.stats import pearsonr,fisher_exact\n",
    "from skbio.diversity.alpha import shannon, simpson, berger_parker_d\n",
    "\n",
    "from pop_organize import get_sample_data, get_sample_with_dfs\n",
    "from SufficientStatistics import *\n",
    "from MyFunctionsShani import *\n",
    "import math\n",
    "from myplots import roundup, rounddown, find_decimal_fold\n",
    "from skbio.stats.distance import mantel\n",
    "from scipy.spatial.distance import braycurtis, pdist\n",
    "\n",
    "\n",
    "from GeneralFeaturePhenotypeInteractions.Feature_phenotype_functions import * \n",
    "from TCR_microbiome_interactions.TCR_microbiome_interactions_functions import *\n",
    "from TCR_microbiome_interactions.TCR_microbiome_interactions_functions2 import *\n",
    "from SampleLists.SampleFileFunctions import *\n",
    "from PhenotypicData.PhenotypeGenerationFunctions import *\n",
    "from CardioProject.CardioFunctions import *\n",
    "from PredictionPipeline.PredictionFunctions import *\n",
    "\n",
    "import os\n",
    "from Utils import cacheOnDisk\n",
    "from queue.qp import qp,fakeqp\n",
    "from addloglevels import sethandlers\n",
    "\n",
    "#ML imports:\n",
    "from xgboost import XGBClassifier\n",
    "import lightgbm as lgb\n",
    "from collections import OrderedDict\n",
    "from sklearn.model_selection import GroupKFold,StratifiedKFold, KFold\n",
    "import statsmodels.formula.api as sm\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import shap\n",
    "from sklearn import metrics\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.feature_selection import SelectFromModel,SelectKBest,chi2,mutual_info_classif,f_classif\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "MyPath='/net/mraid08/export/genie/Lab/Personal/ShaniBAF'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T15:40:54.451938Z",
     "start_time": "2018-07-11T15:40:54.443203Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "cdate=str(time.strftime(\"%d%m%Y\"))\n",
    "cdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# prediction function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T10:00:49.116822Z",
     "start_time": "2018-07-10T10:00:48.580674Z"
    }
   },
   "outputs": [],
   "source": [
    "def predictBinaryByDistMat(Y,YName,X,XName,ResultFolder,model,modelName,model_params,n_splits,useCV=True,stratifiedCV=True):\n",
    "    \n",
    "    predResultsDF=pd.DataFrame()\n",
    "    #(1) arrange result folders:\n",
    "    print 'arranging  result folders:'\n",
    "    \n",
    "    predResultsDFFolder='%s/%s/%s_predictions/predictionDFs' %(ResultFolder,modelName,YName) #define folder for all result dfs in this model\n",
    "    if not isdir(predResultsDFFolder):\n",
    "        makedirs(predResultsDFFolder)\n",
    "        print 'generating predResultsDFFolder %s' %predResultsDFFolder      \n",
    "    predResultsfigFolder='%s/%s/%s_predictions/figs' %(ResultFolder,modelName,YName) #define folder for figs in this model\n",
    "    if not isdir(predResultsfigFolder):\n",
    "        makedirs(predResultsfigFolder)\n",
    "        print 'predResultsfigFolder %s' %predResultsfigFolder\n",
    "\n",
    "    #generate result DF name based on model_params:\n",
    "    d=OrderedDict(sorted(model_params.items(), key=lambda t: t[0]))\n",
    "    try:\n",
    "        d2=d.copy()\n",
    "        del d2['numthreads']\n",
    "    except:\n",
    "        d2=d.copy()\n",
    "    predResultsDFName='_'.join(['%s%s' %(key.replace('_',''), value) for (key, value) in d2.items()]) #generate a file name based on params\n",
    "    predResultsDFName=predResultsDFName.replace('.','-')\n",
    "    if model_params=={}:\n",
    "        predResultsDFName='defaultParams'\n",
    "    if useCV:\n",
    "        predResultsDFName='%s_CV%s' %(predResultsDFName,n_splits)\n",
    "    predResultsDFName='%s_%s' %(XName,predResultsDFName)\n",
    "    \n",
    "    predResultsDFfile='%s/%s.xlsx' %(predResultsDFFolder,predResultsDFName)\n",
    "    existingDFs=[f for f in listdir( predResultsDFFolder) if isfile(join(predResultsDFFolder, f))]\n",
    "    \n",
    "\n",
    "    if predResultsDFName not in existingDFs:  \n",
    "        # common processing of X and y:\n",
    "        # leave only common samples in each df (X and seq1data)\n",
    "        X=X.loc[[str(x) for x in X.index.tolist() if x in Y.index],:]\n",
    "        X=X.sort_index()\n",
    "        print 'X shape is %s_%s' %(X.shape[0], X.shape[1])\n",
    "        print 'the 100th sample in X is %s' %X.index[100]\n",
    "        print X.iloc[:3,:3]\n",
    "        Y=Y.loc[[str(x) for x in Y.index.tolist() if x in X.index]]\n",
    "        Y=Y.sort_index()\n",
    "#         oldColName=str(Y.columns.values[0])\n",
    "#         Y=Y.rename(columns={oldColName:'Class'})\n",
    "        print 'Y shape is %s' %(Y.shape[0])\n",
    "        print 'the 100th sample in Y is %s' %Y.index[100]\n",
    "        print Y.head(3)\n",
    "\n",
    "        #(2) model fitting and predictions:\n",
    "        if useCV:\n",
    "            print 'splitting train_test using cross validation with %s splits...' %n_splits\n",
    "            \n",
    "            if stratifiedCV:\n",
    "                group_kfold = StratifiedKFold(n_splits=n_splits)\n",
    "                groups=None\n",
    "            else:\n",
    "                group_kfold = GroupKFold(n_splits=n_splits)\n",
    "                groups = np.array(range(X.shape[0]))\n",
    "                \n",
    "        \n",
    "            y_pred_df = pd.DataFrame(index=Y.index, columns=['pred_proba'])\n",
    "            i=0\n",
    "            for train_index, val_index in group_kfold.split(X, Y,groups):\n",
    "                print i\n",
    "                i+=1\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = Y.loc[X_train.index], Y.loc[X_val.index]\n",
    "                \n",
    "                print 'fraction of 1s in train set=%s' %(float(y_train.sum())/len(y_train))\n",
    "                print 'fraction of 1s in test set=%s' %(float(y_val.sum())/len(y_val))\n",
    "\n",
    "                # creating the model object\n",
    "                m = model(**model_params)\n",
    "\n",
    "                # fitting the training\n",
    "                if modelName=='LGBMClassifier':\n",
    "                    m.fit(X_train, y_train,\n",
    "                            eval_set=[(X_val, y_val)],\n",
    "                            early_stopping_rounds=None, verbose=-1)\n",
    "                else:\n",
    "                    m.fit(X_train, y_train)\n",
    "                # getting the predictions for the test\n",
    "                y_pred_proba = m.predict_proba(X_val)\n",
    "                y_pred_df.loc[y_val.index, :] = np.expand_dims(y_pred_proba[:,1], 1)\n",
    "        else:\n",
    "            test_size = 0.33\n",
    "            print 'using normal train_test split with test_size=%s' %test_size\n",
    "            from sklearn.model_selection import train_test_split  \n",
    "            # seed = 7\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, stratify=Y)\n",
    "            print 'fitting model...'\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            # make predictions for test data\n",
    "            print 'predicting...'\n",
    "            y_pred = model.predict(X_test)\n",
    "            predictions = [round(value) for value in y_pred]\n",
    "            # evaluate predictions\n",
    "            from sklearn.metrics import accuracy_score\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "            y_pred_df = pd.DataFrame(index=Y.index, data={'pred':y_pred})\n",
    "\n",
    "        #(4) plots:\n",
    "        print 'generating plots...'\n",
    "\n",
    "        # this plot shows the probabilities returned by the predictor colored by the class\n",
    "        plt.figure(figsize=(3,2))\n",
    "        plt.scatter(range(y_pred_df.shape[0]), y_pred_df.pred_proba, c=Y)\n",
    "        plt.show()\n",
    "\n",
    "        # plot ROC and PR curves\n",
    "\n",
    "        from sklearn import metrics\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(Y+1, y_pred_df.pred_proba, pos_label=2)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        print roc_auc\n",
    "\n",
    "        plt.figure(figsize=(20,7))\n",
    "        plt.subplot(1,2,1)\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate', fontsize=15)\n",
    "        plt.ylabel('True Positive Rate', fontsize=15)\n",
    "        plt.title('ROC curve - ' , fontsize=20)\n",
    "        plt.legend(loc=\"lower right\", fontsize=15)\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        precision, recall, _ = metrics.precision_recall_curve(Y, y_pred_df.pred_proba)\n",
    "        pr_auc = metrics.auc(recall, precision)\n",
    "\n",
    "        plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "        plt.fill_between(recall, precision, step='post', alpha=0.5,\n",
    "                         color='darkorange', label='Precision Recall curve - AUC = {0:0.3f}'.format(pr_auc))\n",
    "        plt.plot([0, 1], [Y.sum()/Y.shape[0], Y.sum()/Y.shape[0]], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlabel('Recall', fontsize=15)\n",
    "        plt.ylabel('Precision', fontsize=15)\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title('Precision Recall curve', fontsize=20)\n",
    "        plt.legend(loc=\"upper right\", fontsize=15)\n",
    "\n",
    "        if roc_auc>0.55:\n",
    "            predResultsFigfile='%s/%s_ROC-PR.png' %(predResultsfigFolder,predResultsDFName)\n",
    "            plt.savefig(predResultsFigfile, bbox_inches='tight')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        #(5) generate summarizing df:\n",
    "        print 'generating summarizing df'\n",
    "        predResultsDF.loc[0,'Yname']=YName\n",
    "        predResultsDF.loc[0,'Xname']=XName\n",
    "        predResultsDF.loc[0,'modelName']=modelName\n",
    "        predResultsDF.loc[0,'roc_auc']=round(roc_auc,3)\n",
    "        predResultsDF.loc[0,'pr_auc']=round(pr_auc,3)\n",
    "        predResultsDF.loc[0,'perc_pos_target']=round(float(Y.sum())/len(Y),3)\n",
    "        predResultsDF.loc[0,'pr_auc_corrected']=round(pr_auc,3)-round(float(Y.sum())/len(Y),3)\n",
    "        predResultsDF.loc[0,'useCV']=useCV\n",
    "        if useCV:\n",
    "            predResultsDF.loc[0,'n_splits']=n_splits\n",
    "        \n",
    "        \n",
    "        for (key, value) in OrderedDict(sorted(model_params.items(), key=lambda t: t[0])).items():\n",
    "            predResultsDF.loc[0,key]=value\n",
    "        \n",
    "        nPos=int(Y.sum())\n",
    "        nNeg=len(Y)-nPos\n",
    "        \n",
    "        print nPos, nNeg\n",
    "\n",
    "        predResultsDF.loc[0,'nPos']=nPos\n",
    "        predResultsDF.loc[0,'nNeg']=nNeg\n",
    "        \n",
    "        \n",
    "        predResultsDF.to_excel(predResultsDFfile)\n",
    "        print predResultsDFfile\n",
    "        \n",
    "    else:\n",
    "        print 'this prediction already exists'\n",
    "    \n",
    "    return predResultsDF\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction pipeline function\n",
    "calls the prediction function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-10T09:56:57.006323Z",
     "start_time": "2018-07-10T09:56:56.350956Z"
    }
   },
   "outputs": [],
   "source": [
    "def predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList):\n",
    "    \n",
    "    #(1) get phenotypeDF:\n",
    "    if usePhenotype:\n",
    "        if genPhenotypeDF:\n",
    "            ## generate phenotype df if necessary\n",
    "            print 'generating phenotypeDF...'\n",
    "            ### get the original phenotype file(s) - concat if necessary:\n",
    "            \n",
    "            PNPphenotypeFile='%s/TCR_real_data/NewPhenotypicData/PNP530_AgeGenderBMIcreatSmoking.xlsx' %MyPath\n",
    "            CardioPhenotypeFile='%s/TCR_real_data/CardioSamples/phenotypicData/Cardio126phen.xlsx' %MyPath\n",
    "\n",
    "            PNPphenotypeDF=pd.read_excel(PNPphenotypeFile).set_index('BD')\n",
    "            CardiophenotypeDF=pd.read_excel(CardioPhenotypeFile).set_index('BD')\n",
    "\n",
    "            if datasetType=='PNP':\n",
    "                phenotypeDF=PNPphenotypeDF\n",
    "            elif datasetType=='PNP_Cardio':\n",
    "                phenotypeDF=pd.concat([PNPphenotypeDF,CardiophenotypeDF])\n",
    "                phenotypeDF=phenotypeDF.drop(['RegistrationCode','DM','Diagnosis'],axis=1)\n",
    "\n",
    "#             phenotypeDF['isCardio']=np.where(phenotypeDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "            print 'phenotypeDF shape is %s_%s' %(phenotypeDF.shape[0],phenotypeDF.shape[1])\n",
    "            print phenotypeDF.tail()\n",
    "            \n",
    "            ### generate dummy variables:\n",
    "            #the function gen_dummies was copied to Feature_phenotype_functions.py\n",
    "            toDummyColList=['Gender','Smoking','PCRplate']\n",
    "            df=phenotypeDF.copy()\n",
    "            phenotypeDF=gen_dummies(df,toDummyColList)\n",
    "            print 'pehonotypeDF head after dummy addition:'\n",
    "            phenotypeDF.head()\n",
    "            \n",
    "            #save phenotypeDF:\n",
    "            if datasetType=='PNP':\n",
    "                f2='%s/TCR_real_data/NewPhenotypicData/PNP530_AgeGenderBMIcreatSmoking_withDummies.xlsx' %MyPath\n",
    "            elif datasetType=='PNP_Cardio':\n",
    "                f2='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "            phenotypeDF.to_excel(f2)\n",
    "        else:\n",
    "            print 'loading phenotype file...'\n",
    "            phenotypeDF=pd.read_excel(phenotypefile).set_index('BD')\n",
    "            print phenotypeDF.shape\n",
    "            phenotypeDF.tail()\n",
    "            \n",
    "        #\n",
    "        # Xtypes:\n",
    "        allNum=['Age', 'BMI', 'Creatinine', 'isCardio', 'nTemplates', 'Gender_Male', 'Smoking_Past', 'Smoking_Yes',\n",
    "               'PCR_Plate1', 'PCR_Plate10', 'PCR_Plate2', 'PCR_Plate3',\n",
    "               'PCR_Plate4', 'PCR_Plate5', 'PCR_Plate6', 'PCR_Plate7',\n",
    "               'PCR_Plate8', 'PCR_Plate9']\n",
    "        small=[ 'Age', 'BMI', 'Creatinine', 'isCardio', 'Gender_Male','Smoking_Past', 'Smoking_Yes']\n",
    "        smallNoCardio=['Age', 'BMI', 'Creatinine', 'Gender_Male','Smoking_Past', 'Smoking_Yes']\n",
    "        allNumNoPlate=['Age', 'BMI', 'Creatinine', 'isCardio', 'nTemplates', 'Gender_Male', 'Smoking_Past', 'Smoking_Yes']\n",
    "\n",
    "        if phenotypeDFname=='small':\n",
    "            Xcols=small\n",
    "        elif phenotypeDFname=='allNum':\n",
    "            Xcols=allNum\n",
    "        elif phenotypeDFname=='smallNoCardio':\n",
    "            Xcols=smallNoCardio\n",
    "        elif phenotypeDFname=='allNumNoPlate':\n",
    "            Xcols=allNumNoPlate\n",
    "            \n",
    "        phenotypeDF=phenotypeDF[Xcols]\n",
    "        print 'final phenotype shape is %s_%s' %(phenotypeDF.shape[0],phenotypeDF.shape[1])\n",
    "\n",
    "        \n",
    "        #(2) get TCRdf:\n",
    "        if useTCRdf or usePCAdf:\n",
    "            ## ** load shared sequence matrix\n",
    "            print 'loading shared sequence matrix:'\n",
    "            TCRdfShortName=TCRdfName.replace('sharingMatrix_PNP530Cardio126MatchedSamples_','')\n",
    "            TCRdfShortName=TCRdfShortName.replace('__','_')\n",
    "\n",
    "            f1='%s/sharingAnalysis/%s' %(datasetFolder,TCRdfName)\n",
    "            TCRdf=pd.read_pickle(f1)\n",
    "            print 'TCRdf shape is %s_%s' %(TCRdf.shape[0],TCRdf.shape[1])\n",
    "            print 'TCRdf head:'\n",
    "            print TCRdf.iloc[:4,:4]\n",
    "        \n",
    "        #(3) get PCAdf:\n",
    "        if usePCAdf:\n",
    "            ## **generate PCs as features:\n",
    "            if n_comp is None:\n",
    "                n_comp=5\n",
    "            print 'generating PCAdf with %s PCs based on TCRdf:' %n_comp\n",
    "            PCAdf=PCAfunc(TCRdf,n_comp,isSparse)\n",
    "            for c in ['BDindex','isCardio']:\n",
    "                try:\n",
    "                    PCAdf=PCAdf.drop(c,axis=1)\n",
    "                except:\n",
    "                    print 'PCAdf doesnt include %s column' %c\n",
    "            print 'PCAdf shape is %s_%s' %(PCAdf.shape[0],PCAdf.shape[1])\n",
    "            print 'PCAdf HEAD:'\n",
    "            print PCAdf.head()\n",
    "          \n",
    "        #(4) get TCRfeature:\n",
    "        if useTCRfeatures:\n",
    "            if getTCRfeatures:\n",
    "                print 'generating new feature DF...this will take a while and will print out many things...'\n",
    "                ### calculate features - from PopulationAnalaysis_new_version.ipynb\n",
    "                data_folder=datasetFolder.replace('%s/' %MyPath,'')\n",
    "                dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected' %data_folder\n",
    "                filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "                filenames=[f.strip('.tsv') for f in filenames]\n",
    "                filenames=[f.strip('.xlsx') for f in filenames]\n",
    "                print 'number of samples to extract features is %s' %len(filenames)\n",
    "                for n,sample_name in enumerate(filenames): \n",
    "                    print  n,sample_name\n",
    "                    gen_descriptive_stats(sample_name,data_folder,newColumnList=None)\n",
    "                    gen_geneUsageCount(sample_name,data_folder,newColumnList=None)\n",
    "                ### generate feature DFs - based on 'Generate features DF' notebook\n",
    "                seqTypeList = ['Total', 'Prod','nonProd']\n",
    "                dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/Total' %data_folder\n",
    "                FeatureGroups=listdir(dfs_folder)\n",
    "                for seqType in seqTypeList:\n",
    "                    print seqType\n",
    "                    gen_featureSummaryDF_forSeqType(seqType,data_folder,datasetName,FeatureGroups)\n",
    "                    \n",
    "                data_folder=datasetFolder.replace('%s/' %MyPath,'')\n",
    "                gen_merged_feature_df_for_dataset(data_folder,datasetName)\n",
    "            else:\n",
    "                print 'loading featureDF...'\n",
    "                f2='%s/featureSummaryDFs/%s_allFeatures' %(datasetFolder,datasetName)\n",
    "                TCRfeatureDF=pd.read_pickle(f2)\n",
    "                print 'TCRfeatureDF shape is %s_%s' %(TCRfeatureDF.shape[0],TCRfeatureDF.shape[1])\n",
    "                print 'TCRfeatureDF head:'\n",
    "                print TCRfeatureDF.iloc[:4,:4]\n",
    "                \n",
    "            ## ** fillna's in featureDF:\n",
    "            #get number of columns with number of nan values?\n",
    "            print 'fill nans in featureDF...:'\n",
    "            print 'columns with top numbers of nan values:'\n",
    "            print TCRfeatureDF.isnull().sum().sort_values(ascending=False).head()\n",
    "            print 'value counts of nan numbers per column:'\n",
    "            print TCRfeatureDF.isnull().sum().value_counts(dropna=False).sort_values(ascending=False).head()\n",
    "            # find how many columns include nans:\n",
    "            print 'number of columns with nan values = %s' %len(TCRfeatureDF.loc[:,TCRfeatureDF.isnull().sum()>0].columns.tolist())\n",
    "            print 'total number of columns is %s' %len(TCRfeatureDF.columns)\n",
    "            #get list of columns that inlcude nans and should be fillna-ed with 0s:\n",
    "            columnsToFill=TCRfeatureDF.loc[:,TCRfeatureDF.isnull().sum()>0].columns.tolist()\n",
    "            columnsToFill_clean=[x for x in columnsToFill if 'norm' not in x]\n",
    "            print 'number of columns that include nans and their name doesnt include -norm- is %s' %len(columnsToFill_clean)\n",
    "            print 'these columns will be fillna-ed with 0s'\n",
    "\n",
    "            #fillna with zeros\n",
    "            TCRfeatureDF[columnsToFill_clean]=TCRfeatureDF[columnsToFill_clean].fillna(0)\n",
    "\n",
    "            #check how many columns remained with nans:\n",
    "            print 'now the number of columns with nan values is %s' %len(TCRfeatureDF.loc[:,TCRfeatureDF.isnull().sum()>0].columns.tolist())\n",
    "\n",
    "        #(5) get y:\n",
    "        y=targetDF[targetName]\n",
    "        print 'y shape is %s' %y.shape\n",
    "        print 'y head:'\n",
    "        print y.head()\n",
    "        print y.tail()\n",
    "        \n",
    "        \n",
    "        #(6) edit X- filter with sampleList, filter nan columns, fillna, filter for y rows\n",
    "        \n",
    "        #build X from its components:\n",
    "        print 'building X from its components:'\n",
    "        XcomponentList=[]\n",
    "        if usePhenotype:\n",
    "            XcomponentList.append(phenotypeDF)\n",
    "        if useTCRdf:\n",
    "            XcomponentList.append(TCRdf)\n",
    "        if useTCRfeatures:\n",
    "            XcomponentList.append(TCRfeatureDF)\n",
    "        if usePCAdf:\n",
    "            XcomponentList.append(PCAdf)\n",
    "        print 'number of Xcomponents to be used is %s' %len(XcomponentList)\n",
    "        \n",
    "        #edit sample names and merge all X components:\n",
    "        for n,comp in enumerate(XcomponentList):\n",
    "#             print n\n",
    "#             print 'comp shape is %s_%s' %(comp.shape[0],comp.shape[1])\n",
    "#             print 'editing sample names..'\n",
    "            comp=editSampleNames(comp)\n",
    "            if n==0:\n",
    "                X=comp\n",
    "            else:\n",
    "                X=pd.merge(X,comp, how='inner', right_index=True,left_index=True)\n",
    "        print 'combined X shape is %s_%s' %(X.shape[0],X.shape[1])\n",
    "        print len(X.index.tolist())\n",
    "        \n",
    "        #if model is 'logit', drop columns that contains nans, except for phenotype columns; fillna in phenotype columns\n",
    "        #and check for rows with nan values:\n",
    "\n",
    "        if ('log' in modelName) or ('Log' in modelName):\n",
    "            print 'model is logit, dropping nan feature columns and filling nas in phenotype columns with median column values...'\n",
    "            nullSum=X.isnull().sum()\n",
    "            ignoreColumns=nullSum[nullSum>0].index.tolist()\n",
    "            for column in phenotypeDF.columns.values:\n",
    "                if column in ignoreColumns:\n",
    "                    ignoreColumns.remove(column)\n",
    "            X=X.drop(ignoreColumns,axis=1)\n",
    "            print 'X shape after dropping nan columns is %s_%s' %(X.shape[0],X.shape[1])\n",
    "            for column in phenotypeDF.columns.values:\n",
    "                X[column]= X[column].fillna(X[column].median())\n",
    "            X=X.dropna(how='any')\n",
    "            print 'Xshape after dropping rows with nans=%s_%s' %(X.shape[0],X.shape[1])\n",
    "\n",
    "        # drop samples that are not in y\n",
    "        print 'dropping X rows that do not appear in y:'\n",
    "        ysamples=y.index.tolist()\n",
    "        X=X.loc[ysamples,:]\n",
    "        X=X.dropna(how='all')\n",
    "        print 'Xshape after dropping rows that do not appear in y = %s_%s:' %(X.shape[0],X.shape[1])\n",
    "        \n",
    "        #filter X rows by sampleList:\n",
    "        if sampleListName is not None:\n",
    "            print 'filtering X rows with sample List = %s' %sampleListName\n",
    "            X=X.loc[sampleList,:]\n",
    "            print 'Xshape after filtering rows with sample list = %s_%s:' %(X.shape[0],X.shape[1])\n",
    "        \n",
    "        \n",
    "        #(7) edit y\n",
    "        # leave only rows that appear in X\n",
    "        print 'y shape before filtering for X sample is %s' %y.shape[0]\n",
    "        Xsamples=X.index.tolist()\n",
    "        y=y.loc[Xsamples]\n",
    "        # y=y.dropna(how='all')\n",
    "        print 'y shape after filtering for X sample is %s' %y.shape[0]\n",
    "        \n",
    "        #(8) feature selection: placeholder\n",
    "        \n",
    "        #(9) model prediction: yield df, plots\n",
    "        print 'calculating model prediction'\n",
    "        Y=y\n",
    "        predResultsDF=predictBinaryByDistMat(Y,YName,X,XName,ResultFolder,model,modelName,model_params,n_splits,\n",
    "                                             useCV,stratifiedCV)\n",
    "        print predResultsDF\n",
    "        print 'done!!'\n",
    "    \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  define input and call prediction pipeline:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run for PNP530Cardio126Matchedss9000_onlyPhenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T07:55:04.542737Z",
     "start_time": "2018-07-11T07:55:01.564283Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= lgb.LGBMClassifier\n",
    "modelName='LGBMClassifier'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=100\n",
    "max_depth=3\n",
    "model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_onlyPhenotypes'\n",
    "## naming instructions: phenotypes: indicate old or new, TCRdf-indicate threshold to inclusion and binary/RA, \n",
    "## PCA- indicate n_comp and is Sparse, indicate feature selection\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=False #True/False\n",
    "useTCRfeatures=False #True/False\n",
    "usePCAdf=False #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List \n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run for PNP530Cardio126Matchedss9000 - Phenotypes+TCR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T07:56:21.995043Z",
     "start_time": "2018-07-11T07:56:18.295373Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= lgb.LGBMClassifier\n",
    "modelName='LGBMClassifier'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=100\n",
    "max_depth=3\n",
    "model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_Phenotypes&TCRdf' #### always change!!!!\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=True #True/False\n",
    "useTCRfeatures=False #True/False\n",
    "usePCAdf=False #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List \n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run for PNP530Cardio126Matchedss9000 - Phenotypes+PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T07:56:35.937144Z",
     "start_time": "2018-07-11T07:56:33.954966Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= lgb.LGBMClassifier\n",
    "modelName='LGBMClassifier'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=100\n",
    "max_depth=3\n",
    "model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_Phenotypes&PCA' #### always change!!!!\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=False#True/False\n",
    "useTCRfeatures=False #True/False\n",
    "usePCAdf=True #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List \n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run for PNP530Cardio126Matchedss9000 - Phenotypes+features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T07:56:35.937144Z",
     "start_time": "2018-07-11T07:56:33.954966Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= lgb.LGBMClassifier\n",
    "modelName='LGBMClassifier'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=100\n",
    "max_depth=3\n",
    "model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_Phenotypes&TCRfeatures' #### always change!!!!\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=False #True/False\n",
    "useTCRfeatures=True #True/False\n",
    "usePCAdf=False #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List \n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run for PNP530Cardio126Matchedss9000 - Phenotypes only LOGIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T07:56:35.937144Z",
     "start_time": "2018-07-11T07:56:33.954966Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= LogisticRegression\n",
    "modelName='LogisticRegression'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=100\n",
    "max_depth=3\n",
    "# model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "model_params={}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_PhenotypesOnly' #### always change!!!!\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=False #True/False\n",
    "useTCRfeatures=False #True/False\n",
    "usePCAdf=False #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List \n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run for PNP530Cardio126Matchedss9000 - Phenotypes+TCRdf - LOGIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T07:56:38.079991Z",
     "start_time": "2018-07-11T07:56:35.939973Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= LogisticRegression\n",
    "modelName='LogisticRegression'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=100\n",
    "max_depth=3\n",
    "# model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "model_params={}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_Phenotypes&TCRdf' #### always change!!!!\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=True #True/False\n",
    "useTCRfeatures=False #True/False\n",
    "usePCAdf=False #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List \n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run for PNP530Cardio126Matchedss9000 - Phenotypes+PCAdf - LOGIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T07:56:43.746823Z",
     "start_time": "2018-07-11T07:56:40.852239Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= LogisticRegression\n",
    "modelName='LogisticRegression'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=100\n",
    "max_depth=3\n",
    "# model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "model_params={}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_Phenotypes&PCA' #### always change!!!!\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=False #True/False\n",
    "useTCRfeatures=False #True/False\n",
    "usePCAdf=True #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List \n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run for PNP530Cardio126Matchedss9000 - Phenotypes+TCRfeatures - LOGIT!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T07:56:47.933880Z",
     "start_time": "2018-07-11T07:56:45.160052Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= LogisticRegression\n",
    "modelName='LogisticRegression'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=100\n",
    "max_depth=3\n",
    "# model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "model_params={}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_Phenotypes&TCRfeatures' #### always change!!!!\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=False #True/False\n",
    "useTCRfeatures=True #True/False\n",
    "usePCAdf=False #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List \n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run again with regularization:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matched samples, phenotypes+PCA+features, no regularization, LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T08:26:16.623971Z",
     "start_time": "2018-07-11T08:26:10.887073Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= lgb.LGBMClassifier #LogisticRegression/lgb.LGBMClassifier\n",
    "modelName='LGBMClassifier' #'LogisticRegression'/'LGBMClassifier'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=100\n",
    "max_depth=3\n",
    "model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "# model_params={}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_Phenotypes&PCA&TCRfeatures' #### always change!!!!\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=False #True/False\n",
    "useTCRfeatures=True #True/False\n",
    "usePCAdf=True #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List \n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## matched samples, phenotypes+PCA+features, with regularization, LGB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T10:07:51.800985Z",
     "start_time": "2018-07-11T09:51:40.230085Z"
    }
   },
   "outputs": [],
   "source": [
    "# loop over model parameters:\n",
    "\n",
    "n_estimators_list=[20,100,1000]\n",
    "learning_rate_list=[0.01,0.05,0.1]\n",
    "maxDepth_numLeaves_pair_list=[(3,4),(3,8),(6,30),(6,60)]\n",
    "minDataLeaf_list=[20,40]\n",
    "baggingFraction_list=[1,0.5]\n",
    "\n",
    "count=1\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for min_data_in_leaf in minDataLeaf_list:\n",
    "            for bagging_fraction in baggingFraction_list:\n",
    "                for pair in maxDepth_numLeaves_pair_list:\n",
    "                    \n",
    "                    print count\n",
    "                    count=count+1\n",
    "                    \n",
    "                    # setting parameters:\n",
    "                    max_depth=pair[0]\n",
    "                    num_leaves=pair[1]\n",
    "                    \n",
    "                    bagging_freq=1\n",
    "                    bagging_seed=3\n",
    "                    \n",
    "                    \n",
    "                    # (1) general definitions:\n",
    "                    datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "                    #nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "                    #(2) model definitions:\n",
    "                    ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "                    if not isdir(ResultFolder):\n",
    "                        makedirs(ResultFolder)\n",
    "                    model= XGBClassifier #LogisticRegression/lgb.LGBMClassifier/XGBClassifier\n",
    "                    modelName='XGBClassifier' #'LogisticRegression'/'LGBMClassifier'/'XGBClassifier'\n",
    "                    n_splits=3\n",
    "                    useCV=True\n",
    "                    stratifiedCV=True\n",
    "\n",
    "                    model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_leaves':num_leaves,\n",
    "                                  'min_data_in_leaf':min_data_in_leaf,'bagging_fraction':bagging_fraction,'bagging_freq':bagging_freq,'bagging_seed':bagging_seed,\n",
    "                                  'num_threads':2}\n",
    "#                     model_params={}\n",
    "\n",
    "                    #(3) target definition:\n",
    "                    targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "                    targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "                    targetName='isCardio'\n",
    "                    YName=targetName\n",
    "\n",
    "                    #  (4) feature composition:\n",
    "                    XName='PNP530Cardio126Matchedss9000_Phenotypes&PCA&TCRfeatures' #### always change!!!!\n",
    "                    usePhenotype=True #True/False\n",
    "                    useTCRdf=False #True/False\n",
    "                    useTCRfeatures=True #True/False\n",
    "                    usePCAdf=True #True/False\n",
    "\n",
    "                    # (5) phenotypeDF:\n",
    "\n",
    "                    genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "                    phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "                    phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "                    # (6) TCRdf:\n",
    "                    datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "                    datasetName='PNP530Cardio126_ss9000rep1'\n",
    "                    TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "                    #(7) PCAdf (based on the TCRdf selected)\n",
    "                    n_comp=10 # int or None \n",
    "                    isSparse=True #True/False\n",
    "\n",
    "                    #(8) TCRfeatures:\n",
    "                    getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "                    #(9) X and y processing:\n",
    "                    folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "                    sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "                    matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "                    sampleList= matched86List \n",
    "\n",
    "\n",
    "                    predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                                          XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                                          YName,targetDF,\n",
    "                                          genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                                          datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                                          getTCRfeatures,sampleListName,sampleList)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder='%s/TCR_real_data/Predictions/isCardio_predictions/LGBMClassifier/predictionDFs' %MyPath\n",
    "results=concat_summarizing_dfs_excel(folder)\n",
    "results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results=results.sort_values(by='roc_auc', ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f1='%s/TCR_real_data/Predictions/isCardio_predictions/LGBMClassifier/resultSummary_%s.xlsx' %(MyPath, cdate)\n",
    "results.to_excel(f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try sklearn's xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over model parameters:\n",
    "\n",
    "n_estimators_list=[20,100,1000]\n",
    "learning_rate_list=[0.01,0.05,0.1]\n",
    "maxDepth_numLeaves_pair_list=[(3,4),(3,8),(6,30),(6,60)]\n",
    "minDataLeaf_list=[20,40]\n",
    "baggingFraction_list=[1,0.5]\n",
    "\n",
    "count=1\n",
    "for n_estimators in n_estimators_list:\n",
    "    for learning_rate in learning_rate_list:\n",
    "        for min_data_in_leaf in minDataLeaf_list:\n",
    "            for bagging_fraction in baggingFraction_list:\n",
    "                for pair in maxDepth_numLeaves_pair_list:\n",
    "                    \n",
    "                    print count\n",
    "                    count=count+1\n",
    "                    \n",
    "                    # setting parameters:\n",
    "                    max_depth=pair[0]\n",
    "                    num_leaves=pair[1]\n",
    "                    \n",
    "                    bagging_freq=1\n",
    "                    bagging_seed=3\n",
    "                    \n",
    "                    \n",
    "                    # (1) general definitions:\n",
    "                    datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "                    #nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "                    #(2) model definitions:\n",
    "                    ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "                    if not isdir(ResultFolder):\n",
    "                        makedirs(ResultFolder)\n",
    "                    model= lgb.LGBMClassifier #LogisticRegression/lgb.LGBMClassifier\n",
    "                    modelName='LGBMClassifier' #'LogisticRegression'/'LGBMClassifier'\n",
    "                    n_splits=3\n",
    "                    useCV=True\n",
    "                    stratifiedCV=True\n",
    "\n",
    "                    model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_leaves':num_leaves,\n",
    "                                  'min_data_in_leaf':min_data_in_leaf,'bagging_fraction':bagging_fraction,'bagging_freq':bagging_freq,'bagging_seed':bagging_seed,\n",
    "                                  'num_threads':2}\n",
    "#                     model_params={}\n",
    "\n",
    "                    #(3) target definition:\n",
    "                    targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "                    targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "                    targetName='isCardio'\n",
    "                    YName=targetName\n",
    "\n",
    "                    #  (4) feature composition:\n",
    "                    XName='PNP530Cardio126Matchedss9000_Phenotypes&PCA&TCRfeatures' #### always change!!!!\n",
    "                    usePhenotype=True #True/False\n",
    "                    useTCRdf=False #True/False\n",
    "                    useTCRfeatures=True #True/False\n",
    "                    usePCAdf=True #True/False\n",
    "\n",
    "                    # (5) phenotypeDF:\n",
    "\n",
    "                    genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "                    phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "                    phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "                    # (6) TCRdf:\n",
    "                    datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "                    datasetName='PNP530Cardio126_ss9000rep1'\n",
    "                    TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "                    #(7) PCAdf (based on the TCRdf selected)\n",
    "                    n_comp=10 # int or None \n",
    "                    isSparse=True #True/False\n",
    "\n",
    "                    #(8) TCRfeatures:\n",
    "                    getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "                    #(9) X and y processing:\n",
    "                    folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "                    sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "                    matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "                    sampleList= matched86List \n",
    "\n",
    "\n",
    "                    predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                                          XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                                          YName,targetDF,\n",
    "                                          genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                                          datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                                          getTCRfeatures,sampleListName,sampleList)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# develop feature selectio  and feature importance tools:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T13:47:14.298748Z",
     "start_time": "2018-07-11T13:47:09.772783Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= lgb.LGBMClassifier\n",
    "modelName='LGBMClassifier'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=1000\n",
    "max_depth=3\n",
    "model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_phenotypes&PCA&TCRfeature'\n",
    "## naming instructions: phenotypes: indicate old or new, TCRdf-indicate threshold to inclusion and binary/RA, \n",
    "## PCA- indicate n_comp and is Sparse, indicate feature selection\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=False #True/False\n",
    "useTCRfeatures=True #True/False\n",
    "usePCAdf=True #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List\n",
    "\n",
    "filterFeaturesByCorr=None #None or float between 0 and 1\n",
    "featureSelectionUsingModel=False # True/False\n",
    "C=0.5 #None (if none, C will be set to 0.1) or float between 0 and 1\n",
    "filterFeaturesByUnivariate=f_classif     # None/chi2/f_classif/mutual_info_classif\n",
    "k=150 #None (will be set to 50 / int - defines number of k best))\n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList,\n",
    "                      filterFeaturesByCorr,featureSelectionUsingModel,C,\n",
    "                      filterFeaturesByUnivariate,k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try using naive_bayes model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T13:53:51.590517Z",
     "start_time": "2018-07-11T13:53:48.380097Z"
    }
   },
   "outputs": [],
   "source": [
    "# (1) general definitions:\n",
    "datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "#nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "#(2) model definitions:\n",
    "ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= GaussianNB\n",
    "modelName='GaussianNB'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=1000\n",
    "max_depth=3\n",
    "# model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "model_params={}\n",
    "\n",
    "#(3) target definition:\n",
    "targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "targetName='isCardio'\n",
    "YName=targetName\n",
    "\n",
    "#  (4) feature composition:\n",
    "XName='PNP530Cardio126Matchedss9000_phenotypes&PCA&TCRfeature'\n",
    "## naming instructions: phenotypes: indicate old or new, TCRdf-indicate threshold to inclusion and binary/RA, \n",
    "## PCA- indicate n_comp and is Sparse, indicate feature selection\n",
    "usePhenotype=True #True/False\n",
    "useTCRdf=False #True/False\n",
    "useTCRfeatures=True #True/False\n",
    "usePCAdf=True #True/False\n",
    "\n",
    "# (5) phenotypeDF:\n",
    "\n",
    "genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "# (6) TCRdf:\n",
    "datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "datasetName='PNP530Cardio126_ss9000rep1'\n",
    "TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "#(7) PCAdf (based on the TCRdf selected)\n",
    "n_comp=10 # int or None \n",
    "isSparse=True #True/False\n",
    "\n",
    "#(8) TCRfeatures:\n",
    "getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "#(9) X and y processing:\n",
    "folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "sampleList= matched86List\n",
    "\n",
    "filterFeaturesByCorr=None #None or float between 0 and 1\n",
    "featureSelectionUsingModel=False # True/False\n",
    "C=0.5 #None (if none, C will be set to 0.1) or float between 0 and 1\n",
    "filterFeaturesByUnivariate=f_classif     # None/chi2/f_classif/mutual_info_classif\n",
    "k=150 #None (will be set to 50 / int - defines number of k best))\n",
    "\n",
    "   \n",
    "predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                      XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                      YName,targetDF,\n",
    "                      genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                      datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                      getTCRfeatures,sampleListName,sampleList,\n",
    "                      filterFeaturesByCorr,featureSelectionUsingModel,C,\n",
    "                      filterFeaturesByUnivariate,k)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# try different models and different feature selections:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate phenotype only prediction using each model with default parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T14:12:46.211158Z",
     "start_time": "2018-07-11T14:12:37.163787Z"
    }
   },
   "outputs": [],
   "source": [
    "modelAndParams_list=[(LogisticRegression,'LogisticRegression',{}),\n",
    "                   (lgb.LGBMClassifier,'LGBMClassifier',{'learning_rate': 0.1, 'n_estimators': 1000,'max_depth': 3,'num_threads':2}),\n",
    "                   (XGBClassifier,'XGBClassifier',{'learning_rate': 0.05, 'n_estimators': 100,'max_depth': 6,'num_threads':2}),\n",
    "                   (GaussianNB,'GaussianNB',{})]\n",
    "\n",
    "\n",
    "for n,modelAndParams in enumerate(modelAndParams_list):\n",
    "    \n",
    "    model=modelAndParams[0]\n",
    "    modelName=modelAndParams[1]\n",
    "    model_params=modelAndParams[2]\n",
    "    \n",
    "    \n",
    "    print n,modelName\n",
    "    \n",
    "    # (1) general definitions:\n",
    "    datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "    #nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "    #(2) model definitions:\n",
    "    ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "    if not isdir(ResultFolder):\n",
    "        makedirs(ResultFolder)\n",
    "\n",
    "    n_splits=3\n",
    "    useCV=True\n",
    "    stratifiedCV=True\n",
    "\n",
    "    #(3) target definition:\n",
    "    targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "    targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "    targetName='isCardio'\n",
    "    YName=targetName\n",
    "\n",
    "    #  (4) feature composition:\n",
    "    XName='PNP530Cardio126Matchedss9000_phenotypesOnly'\n",
    "    ## naming instructions: phenotypes: indicate old or new, TCRdf-indicate threshold to inclusion and binary/RA, \n",
    "    ## PCA- indicate n_comp and is Sparse, indicate feature selection\n",
    "    usePhenotype=True #True/False\n",
    "    useTCRdf=False #True/False\n",
    "    useTCRfeatures=False #True/False\n",
    "    usePCAdf=False #True/False\n",
    "\n",
    "    # (5) phenotypeDF:\n",
    "\n",
    "    genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "    phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "    phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "    # (6) TCRdf:\n",
    "    datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "    datasetName='PNP530Cardio126_ss9000rep1'\n",
    "    TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "    #(7) PCAdf (based on the TCRdf selected)\n",
    "    n_comp=10 # int or None \n",
    "    isSparse=True #True/False\n",
    "\n",
    "    #(8) TCRfeatures:\n",
    "    getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "    #(9) X and y processing:\n",
    "    folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "    sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "    matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "    sampleList= matched86List\n",
    "\n",
    "    filterFeaturesByCorr=None #None or float between 0 and 1\n",
    "    featureSelectionUsingModel=False # True/False\n",
    "    C=0.5 #None (if none, C will be set to 0.1) or float between 0 and 1\n",
    "    filterFeaturesByUnivariate=None     # None/chi2/f_classif/mutual_info_classif\n",
    "    k=150 #None (will be set to 50 / int - defines number of k best))\n",
    "\n",
    "\n",
    "    predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                          XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                          YName,targetDF,\n",
    "                          genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                          datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                          getTCRfeatures,sampleListName,sampleList,\n",
    "                          filterFeaturesByCorr,featureSelectionUsingModel,C,\n",
    "                          filterFeaturesByUnivariate,k)\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## try different models with different feature selection combinations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T15:45:26.288843Z",
     "start_time": "2018-07-11T15:41:00.216025Z"
    }
   },
   "outputs": [],
   "source": [
    "modelAndParams_list=[(LogisticRegression,'LogisticRegression',{}),\n",
    "                   (lgb.LGBMClassifier,'LGBMClassifier',{'learning_rate': 0.1, 'n_estimators': 1000,'max_depth': 3,'num_threads':2}),\n",
    "                   (XGBClassifier,'XGBClassifier',{'learning_rate': 0.05, 'n_estimators': 100,'max_depth': 6,'num_threads':2}),\n",
    "                   (GaussianNB,'GaussianNB',{})]\n",
    "\n",
    "filterFeaturesByCorr_list=[None]\n",
    "featureSelectionUsingModel_list=[True,False]\n",
    "filterFeaturesByUnivariate_list=[None,f_classif,mutual_info_classif]\n",
    "n_comp_list=[10,100]\n",
    "\n",
    "\n",
    "count=1\n",
    "for modelAndParams in modelAndParams_list:\n",
    "    \n",
    "    model=modelAndParams[0]\n",
    "    modelName=modelAndParams[1]\n",
    "    model_params=modelAndParams[2]\n",
    "    \n",
    "    for filterFeaturesByCorr in filterFeaturesByCorr_list:\n",
    "        for featureSelectionUsingModel in featureSelectionUsingModel_list:\n",
    "            for filterFeaturesByUnivariate in filterFeaturesByUnivariate_list:\n",
    "                for n_comp in n_comp_list:\n",
    "\n",
    "                    print count\n",
    "                    count=count+1\n",
    "                    C=0.5\n",
    "                    k=150\n",
    "\n",
    "                    # (1) general definitions:\n",
    "                    datasetType='PNP_Cardio' #PNP/PNP_Cardio\n",
    "                    #nSeqSS=9000 #5000/9000/15000/'all'\n",
    "\n",
    "                    #(2) model definitions:\n",
    "                    ResultFolder='%s/TCR_real_data/Predictions' %MyPath\n",
    "                    if not isdir(ResultFolder):\n",
    "                        makedirs(ResultFolder)\n",
    "                    n_splits=3\n",
    "                    useCV=True\n",
    "                    stratifiedCV=True\n",
    "\n",
    "                    #(3) target definition:\n",
    "                    targetDF=pd.DataFrame(index=['BD'+str(x) for x in range(1,1100)])\n",
    "                    targetDF['isCardio']=np.where(targetDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "                    targetName='isCardio'\n",
    "                    YName=targetName\n",
    "\n",
    "                    #  (4) feature composition:\n",
    "                    XName='PNP530Cardio126Matchedss9000_phenotypes&PCA&TCRfeature'\n",
    "                    ## naming instructions: phenotypes: indicate old or new, TCRdf-indicate threshold to inclusion and binary/RA, \n",
    "                    ## PCA- indicate n_comp and is Sparse, indicate feature selection\n",
    "                    usePhenotype=True #True/False\n",
    "                    useTCRdf=False #True/False\n",
    "                    useTCRfeatures=True #True/False\n",
    "                    usePCAdf=True #True/False\n",
    "\n",
    "                    # (5) phenotypeDF:\n",
    "\n",
    "                    genPhenotypeDF=False #True/False. no sense for 'True'  if usePhenotype=False\n",
    "                    phenotypefile='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "                    phenotypeDFname='smallNoCardio' #('small','allNum and more- see step #6.2\n",
    "\n",
    "\n",
    "                    # (6) TCRdf:\n",
    "                    datasetFolder='%s/TCR_real_data/PNP530Cardio126Combined/MatchedSamples/ss9000rep1' %MyPath\n",
    "                    datasetName='PNP530Cardio126_ss9000rep1'\n",
    "                    TCRdfName='sharingMatrix_PNP530Cardio126MatchedSamples_minNshared2_RA_onlyProductiveTrue__percShared10__binary'\n",
    "\n",
    "                    #(7) PCAdf (based on the TCRdf selected)\n",
    "                    isSparse=True #True/False\n",
    "\n",
    "                    #(8) TCRfeatures:\n",
    "                    getTCRfeatures=False #True/False. do not use True when useTCRfeatures=False\n",
    "\n",
    "                    #(9) X and y processing:\n",
    "                    folderToSampleList='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "                    sampleListName='matched86List' ################IMPORTANT!!! ###################\n",
    "                    matched86List=gen_sampleList_from_Folder(folderToSampleList,'PNP530Cardio126Matched86')\n",
    "                    sampleList= matched86List\n",
    "\n",
    "                    predictionPipeline(datasetType,ResultFolder,model,modelName,model_params,n_splits, useCV,stratifiedCV,\n",
    "                                          XName,usePhenotype,useTCRdf,useTCRfeatures,usePCAdf,\n",
    "                                          YName,targetDF,\n",
    "                                          genPhenotypeDF,phenotypefile,phenotypeDFname,\n",
    "                                          datasetFolder,datasetName,TCRdfName,n_comp,isSparse,\n",
    "                                          getTCRfeatures,sampleListName,sampleList,\n",
    "                                          filterFeaturesByCorr,featureSelectionUsingModel,C,\n",
    "                                          filterFeaturesByUnivariate,k)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get results for each model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-11T15:51:33.189430Z",
     "start_time": "2018-07-11T15:51:25.904447Z"
    }
   },
   "outputs": [],
   "source": [
    "modelName_list=['LogisticRegression','LGBMClassifier','XGBClassifier','GaussianNB']\n",
    "\n",
    "\n",
    "BestResultDF=pd.DataFrame()\n",
    "for n, modelName in enumerate(modelName_list):\n",
    "    print n, modelName\n",
    "    folder='%s/TCR_real_data/Predictions/isCardio_predictions/%s/predictionDFs' %(MyPath,modelName)\n",
    "    results=concat_summarizing_dfs_excel(folder)\n",
    "    results=results.sort_values(by='roc_auc', ascending=False)\n",
    "    f1='%s/TCR_real_data/Predictions/isCardio_predictions/%s/resultSummary_%s.xlsx' %(MyPath, modelName,cdate)\n",
    "    results.to_excel(f1)\n",
    "    BestResultDF.loc[n,'modelName']=modelName\n",
    "    BestResultDF.loc[n,'best_roc_auc']=results['roc_auc'].max()\n",
    "    BestResultDF.loc[n,'best_pr_auc_corrected']=results['pr_auc_corrected'].max()\n",
    "\n",
    "BestResultDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### compare results from different models:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T06:10:46.315560Z",
     "start_time": "2018-07-15T06:10:46.278964Z"
    }
   },
   "outputs": [],
   "source": [
    "f1='%s/TCR_real_data/Predictions/isCardio_predictions/modelComparison_120718.xlsx' %MyPath\n",
    "results=pd.read_excel(f1)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-15T10:47:26.542874Z",
     "start_time": "2018-07-15T10:47:26.221946Z"
    }
   },
   "outputs": [],
   "source": [
    "results['roc_auc']=results['roc_auc'].astype(float)\n",
    "fig,ax=plt.subplots()\n",
    "colorList=['r','b','g','y']\n",
    "x1=0\n",
    "x2=0.4\n",
    "for n,model in enumerate(results.Model.unique()):\n",
    "    print n,model\n",
    "    df=results[results.Model==model].drop('Model',axis=1).set_index('Features')\n",
    "#     print df\n",
    "    ROC=list(df.loc[:,'roc_auc'])\n",
    "    print ROC\n",
    "    PR=list(df.loc[:,'pr_auc_corrected'])\n",
    "    print PR\n",
    "    \n",
    "\n",
    "#     arrow1=ax.arrow(x1+0.05*(n+1), ROC[0],0, ROC[1]-ROC[0],width=0.005,head_width=0.01, head_length=0.02, \n",
    "#              label=model,fc=colorList[n], ec=colorList[n])\n",
    "#     arrow2=ax.arrow(x2+0.05*(n+1), PR[0],0, PR[1]-PR[0],width=0.005,head_width=0.01, head_length=0.02, \n",
    "#                     fc=colorList[n], ec=colorList[n])\n",
    "\n",
    "    ax.axvline(x=x1+0.05*(n+1),ymin=ROC[0],ymax=ROC[1],lw=4,marker='^',ms=10,color=colorList[n],label=model)\n",
    "    ax.axvline(x=x2+0.05*(n+1),ymin=PR[0],ymax=PR[1],lw=4,marker='^',ms=10,color=colorList[n])\n",
    "#     x1list=[x1+0.05*n for i in range(2)]\n",
    "#     print x1list\n",
    "#     ax.plot(x=x1list,y=PR,color=colorList[n])\n",
    "# #     ax.plot(x=[x2+0.05*n,x2+0.05*n],y=PR,color=colorList[n])\n",
    "plt.xticks([0.1,0.5],['roc_auc','pr_auc_corrected'],fontsize=20)\n",
    "plt.legend()\n",
    "ax.grid(False)\n",
    "ax.set_xlim(0,0.8)\n",
    "# ax.set_xlabel('Metric')\n",
    "ax.set_title('ROC-AUC and PR-AUC (corrected)\\nfor model prediction using only phenotypes and phenotypes+TCRseqPCA+TCRfeatures')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get sample list:\n",
    "if necessary - generate matched cohorts and get the sample list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate new matched cohorts:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** get sample list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T12:28:02.836605Z",
     "start_time": "2018-07-04T12:28:02.831922Z"
    }
   },
   "source": [
    "the function gen_sampleList_from_Folder was copied to SampleFileFunctions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:54:26.096439Z",
     "start_time": "2018-07-08T20:54:26.056099Z"
    }
   },
   "outputs": [],
   "source": [
    "folder='%s/SamplesForAnalysis_corrected' %datasetFolder\n",
    "\n",
    "matched86List=gen_sampleList_from_Folder(folder,'PNP530Cardio126Matched86')\n",
    "print len(matched86List)\n",
    "print matched86List[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** get shared sequence matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## if necessary - generate new shared sequence matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** load shared sequence matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:54:27.468233Z",
     "start_time": "2018-07-08T20:54:27.451464Z"
    }
   },
   "outputs": [],
   "source": [
    "TCRdfShortName=TCRdfName.replace('sharingMatrix_PNP530Cardio126MatchedSamples_','')\n",
    "TCRdfShortName=TCRdfShortName.replace('__','_')\n",
    "\n",
    "f1='%s/sharingAnalysis/%s' %(datasetFolder,TCRdfName)\n",
    "TCRdf=pd.read_pickle(f1)\n",
    "print TCRdf.shape\n",
    "print TCRdf.iloc[:4,:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **generate PCs as features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:54:31.749386Z",
     "start_time": "2018-07-08T20:54:31.007973Z"
    }
   },
   "outputs": [],
   "source": [
    "n_comp=5\n",
    "isSparse=True\n",
    "\n",
    "PCAdf=PCAfunc(TCRdf,n_comp,isSparse)\n",
    "PCAdf=PCAdf.drop(['BDindex','isCardio'],axis=1)\n",
    "PCAdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** get feature DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  generate new feature DF if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "go to notebook 'Generate feature DF' and generate the necessary dfs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate features - from PopulationAnalaysis_new_version.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T13:15:16.078586Z",
     "start_time": "2018-07-04T13:15:16.032396Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder=datasetFolder.replace('%s/' %MyPath,'')\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "print len(filenames)\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "print len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T13:23:42.944403Z",
     "start_time": "2018-07-04T13:16:43.482249Z"
    }
   },
   "outputs": [],
   "source": [
    "for n,sample_name in enumerate(filenames): \n",
    "#     if n>3:\n",
    "        print  n,sample_name\n",
    "        gen_descriptive_stats(sample_name,data_folder,newColumnList=None)\n",
    "        gen_geneUsageCount(sample_name,data_folder,newColumnList=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate feature DFs - based on 'Generate features DF' notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T13:37:57.637390Z",
     "start_time": "2018-07-04T13:37:26.651276Z"
    }
   },
   "outputs": [],
   "source": [
    "seqTypeList = ['Total', 'Prod','nonProd']\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/Total' %data_folder\n",
    "FeatureGroups=listdir(dfs_folder)\n",
    "for seqType in seqTypeList:\n",
    "    print seqType\n",
    "    gen_featureSummaryDF_forSeqType(seqType,data_folder,datasetName,FeatureGroups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-04T13:51:04.754627Z",
     "start_time": "2018-07-04T13:51:00.434523Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder=datasetFolder.replace('%s/' %MyPath,'')\n",
    "gen_merged_feature_df_for_dataset(data_folder,datasetName)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** load feature DF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:54:38.963165Z",
     "start_time": "2018-07-08T20:54:38.903751Z"
    }
   },
   "outputs": [],
   "source": [
    "f2='%s/featureSummaryDFs/%s_allFeatures' %(datasetFolder,datasetName)\n",
    "TCRfeatureDF=pd.read_pickle(f2)\n",
    "print TCRfeatureDF.shape\n",
    "print TCRfeatureDF.iloc[:4,:4]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** fillna's in featureDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:54:43.719942Z",
     "start_time": "2018-07-08T20:54:43.621114Z"
    }
   },
   "outputs": [],
   "source": [
    "#get number of columns with number of nan values?\n",
    "print 'columns with top numbers of nan values:'\n",
    "print TCRfeatureDF.isnull().sum().sort_values(ascending=False).head()\n",
    "\n",
    "print 'value counts of nan numbers per column:'\n",
    "print TCRfeatureDF.isnull().sum().value_counts(dropna=False).sort_values(ascending=False).head()\n",
    "\n",
    "# find how many columns include nans:\n",
    "print 'number of columns with nan values = %s' %len(TCRfeatureDF.loc[:,TCRfeatureDF.isnull().sum()>0].columns.tolist())\n",
    "print 'total number of columns is %s' %len(TCRfeatureDF.columns)\n",
    "\n",
    "#get list of columns that inlcude nans and should be fillna-ed with 0s:\n",
    "columnsToFill=TCRfeatureDF.loc[:,TCRfeatureDF.isnull().sum()>0].columns.tolist()\n",
    "columnsToFill_clean=[x for x in columnsToFill if 'norm' not in x]\n",
    "print 'number of columns that include nans and their name doesnt include -norm- is %s' %len(columnsToFill_clean)\n",
    "print 'these columns will be fillna-ed with 0s'\n",
    "\n",
    "#fillna with zeros\n",
    "TCRfeatureDF[columnsToFill_clean]=TCRfeatureDF[columnsToFill_clean].fillna(0)\n",
    "\n",
    "#check how many columns remained with nans:\n",
    "print 'now the number of columns with nan values is %s' %len(TCRfeatureDF.loc[:,TCRfeatureDF.isnull().sum()>0].columns.tolist())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ** get full phenotype and target DF and filter if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate phenotype df if necessary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get the original phenotype file(s) - concat if necessary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:36:12.477937Z",
     "start_time": "2018-07-05T11:36:12.237379Z"
    }
   },
   "outputs": [],
   "source": [
    "PNPphenotypeFile='%s/TCR_real_data/NewPhenotypicData/PNP530_AgeGenderBMIcreatSmoking.xlsx' %MyPath\n",
    "CardioPhenotypeFile='%s/TCR_real_data/CardioSamples/phenotypicData/Cardio126phen.xlsx' %MyPath\n",
    "\n",
    "PNPphenotypeDF=pd.read_excel(PNPphenotypeFile).set_index('BD')\n",
    "CardiophenotypeDF=pd.read_excel(CardioPhenotypeFile).set_index('BD')\n",
    "\n",
    "if datasetType=='PNP':\n",
    "    phenotypeDF=PNPphenotypeDF\n",
    "elif datasetType=='PNP_Cardio':\n",
    "    phenotypeDF=pd.concat([PNPphenotypeDF,CardiophenotypeDF])\n",
    "    phenotypeDF=phenotypeDF.drop(['RegistrationCode','DM','Diagnosis'],axis=1)\n",
    "\n",
    "\n",
    "phenotypeDF['isCardio']=np.where(phenotypeDF.index.str.replace('BD','').astype(int)>949,1,0)\n",
    "\n",
    "print phenotypeDF.shape\n",
    "print phenotypeDF.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate dummy variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:36:41.578135Z",
     "start_time": "2018-07-05T11:36:41.573645Z"
    }
   },
   "outputs": [],
   "source": [
    "#the function gen_dummies was copied to Feature_phenotype_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:36:32.988220Z",
     "start_time": "2018-07-05T11:36:32.936396Z"
    }
   },
   "outputs": [],
   "source": [
    "df=phenotypeDF\n",
    "toDummyColList=['Gender','Smoking','PCRplate']\n",
    "\n",
    "phenotypeDF_new=gen_dummies(phenotypeDF,toDummyColList)\n",
    "phenotypeDF_new.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:36:37.120902Z",
     "start_time": "2018-07-05T11:36:36.525227Z"
    }
   },
   "outputs": [],
   "source": [
    "f2='%s/TCR_real_data/PNP530Cardio126Combined/Phenotypes/PNP530Cardio126_phen_withDummies.xls' %MyPath\n",
    "phenotypeDF_new.to_excel(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** get phenotype df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:54:50.260618Z",
     "start_time": "2018-07-08T20:54:50.100803Z"
    }
   },
   "outputs": [],
   "source": [
    "phenotypeDF=pd.read_excel(phenotypefile).set_index('BD')\n",
    "print phenotypeDF.shape\n",
    "phenotypeDF.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:54:54.067868Z",
     "start_time": "2018-07-08T20:54:54.056125Z"
    }
   },
   "outputs": [],
   "source": [
    "# Xtypes:\n",
    "allNum=['Age', 'BMI', 'Creatinine', 'isCardio', 'nTemplates', 'Gender_Male', 'Smoking_Past', 'Smoking_Yes',\n",
    "       'PCR_Plate1', 'PCR_Plate10', 'PCR_Plate2', 'PCR_Plate3',\n",
    "       'PCR_Plate4', 'PCR_Plate5', 'PCR_Plate6', 'PCR_Plate7',\n",
    "       'PCR_Plate8', 'PCR_Plate9']\n",
    "small=[ 'Age', 'BMI', 'Creatinine', 'isCardio', 'Gender_Male','Smoking_Past', 'Smoking_Yes']\n",
    "smallNoCardio=['Age', 'BMI', 'Creatinine', 'Gender_Male','Smoking_Past', 'Smoking_Yes']\n",
    "allNumNoPlate=['Age', 'BMI', 'Creatinine', 'isCardio', 'nTemplates', 'Gender_Male', 'Smoking_Past', 'Smoking_Yes']\n",
    "\n",
    "if phenotypeDFname=='small':\n",
    "    Xcols=small\n",
    "elif phenotypeDFname=='allNum':\n",
    "    Xcols=allNum\n",
    "elif phenotypeDFname=='smallNoCardio':\n",
    "    Xcols=smallNoCardio\n",
    "elif phenotypeDFname=='allNumNoPlate':\n",
    "    Xcols=allNumNoPlate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:54:57.543716Z",
     "start_time": "2018-07-08T20:54:57.538195Z"
    }
   },
   "outputs": [],
   "source": [
    "phenotypeDF=phenotypeDF[Xcols]\n",
    "print phenotypeDF.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **get targetDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:55:00.574719Z",
     "start_time": "2018-07-08T20:55:00.567170Z"
    }
   },
   "outputs": [],
   "source": [
    "y=targetDF[targetName]\n",
    "print y.shape\n",
    "print y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **define which features to use in the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:55:03.620383Z",
     "start_time": "2018-07-08T20:55:03.613129Z"
    }
   },
   "outputs": [],
   "source": [
    "#build X from its components:\n",
    "\n",
    "XcomponentList=[]\n",
    "if usePhenotype:\n",
    "    XcomponentList.append(phenotypeDF)\n",
    "if useTCRdf:\n",
    "    XcomponentList.append(TCRdf)\n",
    "if useTCRfeatures:\n",
    "    XcomponentList.append(TCRfeatureDF)\n",
    "if usPCAdf:\n",
    "    XcomponentList.append(PCAdf)\n",
    "print 'number of Xcomponents to be used is %s' %len(XcomponentList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ** process X:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:55:07.558844Z",
     "start_time": "2018-07-08T20:55:06.842735Z"
    }
   },
   "outputs": [],
   "source": [
    "#edit sample names and merge all X components:\n",
    "for n,comp in enumerate(XcomponentList):\n",
    "    print n\n",
    "    print 'comp shape is %s_%s' %(comp.shape[0],comp.shape[1])\n",
    "    print 'editing sample names..'\n",
    "    comp=editSampleNames(comp)\n",
    "    if n==0:\n",
    "        X=comp\n",
    "    else:\n",
    "        X=pd.merge(X,comp, how='inner', right_index=True,left_index=True)\n",
    "print 'combined X shape is %s_%s' %(X.shape[0],X.shape[1])\n",
    "print len(X.index.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:55:11.212798Z",
     "start_time": "2018-07-08T20:55:11.188756Z"
    }
   },
   "outputs": [],
   "source": [
    "#if model is 'logit', drop columns that contains nans, except for phenotype columns; fillna in phenotype columns\n",
    "#and check for rows with nan values:\n",
    "\n",
    "if modelName=='logit':\n",
    "    nullSum=X.isnull().sum()\n",
    "    ignoreColumns=nullSum[nullSum>0].index.tolist()\n",
    "    for column in phenotypeDF.columns.values:\n",
    "        if column in ignoreColumns:\n",
    "            ignoreColumns.remove(column)\n",
    "    X=X.drop(ignoreColumns,axis=1)\n",
    "    print 'X shape after dropping nan columns is %s_%s' %(X.shape[0],X.shape[1])\n",
    "    \n",
    "    for column in phenotypeDF.columns.values:\n",
    "        X[column]= X[column].fillna(X[column].median())\n",
    "        \n",
    "    X=X.dropna(how='any')\n",
    "    print 'Xshape after dropping rows with nans=%s_%s' %(X.shape[0],X.shape[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:55:14.842768Z",
     "start_time": "2018-07-08T20:55:14.833074Z"
    }
   },
   "outputs": [],
   "source": [
    "# drop samples that are not in y\n",
    "\n",
    "ysamples=y.index.tolist()\n",
    "X=X.loc[ysamples,:]\n",
    "X=X.dropna(how='all')\n",
    "print X.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-05T11:18:26.619448Z",
     "start_time": "2018-07-05T11:18:26.616119Z"
    }
   },
   "source": [
    "## enable feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## process Y:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:32:42.234255Z",
     "start_time": "2018-07-08T19:32:42.231258Z"
    }
   },
   "outputs": [],
   "source": [
    "modelName='logit'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T19:32:46.379378Z",
     "start_time": "2018-07-08T19:32:46.349808Z"
    }
   },
   "outputs": [],
   "source": [
    "if modelName=='logit':\n",
    "    thresholdFracNans=0.01\n",
    "elif modelName=='LGBMClassifier':\n",
    "    thresholdFracNans=0.4\n",
    "\n",
    "thresholdNans=len(X)*thresholdFracNans\n",
    "nullSum=X.isnull().sum()\n",
    "\n",
    "ignoreColumns=nullSum[nullSum>thresholdNans].index.tolist()\n",
    "for column in phenotypeDF.columns.values:\n",
    "#     print len(ignoreColumns)\n",
    "#     print column\n",
    "    if column in ignoreColumns:\n",
    "        ignoreColumns.remove(column)\n",
    "# print ignoreColumns\n",
    "print 'number of columns with nan rates larger then %s = %s' %(thresholdFracNans,len(ignoreColumns))\n",
    "X=X.drop(ignoreColumns,axis=1)\n",
    "print 'Xshape after dropping high nan rate columns=%s_%s' %(X.shape[0],X.shape[1])\n",
    "if modelName=='logit':\n",
    "    X=X.dropna(how='any')\n",
    "    print 'Xshape after dropping rows with nans=%s_%s' %(X.shape[0],X.shape[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* if model type = 'logit' - drop columns with more than 15% missing\n",
    "                        \n",
    "* if model type='xgboost' - drop columns with more than 25% missing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:55:18.527003Z",
     "start_time": "2018-07-08T20:55:18.515577Z"
    }
   },
   "outputs": [],
   "source": [
    "# leave only rows that appear in X\n",
    "print 'y shape before filtering for X sample is %s' %y.shape[0]\n",
    "Xsamples=X.index.tolist()\n",
    "y=y.loc[Xsamples]\n",
    "# y=y.dropna(how='all')\n",
    "print 'y shape after filtering for X sample is %s' %y.shape[0]\n",
    "\n",
    "print y.head()\n",
    "print y.tail()\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediction function \n",
    "including CV design, evaluation metrics, plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run both models for the matched samples using all features/drop TCR sequences/drop also TCR features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:59:43.569295Z",
     "start_time": "2018-07-08T20:59:42.996755Z"
    }
   },
   "outputs": [],
   "source": [
    "def predictBinaryByDistMat(Y,YName,X,XName,ResultFolder,model,model_name,model_params,n_splits,useCV=True,stratifiedCV=True):\n",
    "    \n",
    "    #(1) arrange result folders:\n",
    "    print 'arranging  result folders:'\n",
    "    predResultsDF=pd.DataFrame()\n",
    "    \n",
    "    predResultsDFFolder='%s/%s_predictions/predictionDFs' %(ResultFolder,YName) #define folder for all result dfs in this model\n",
    "    if not isdir(predResultsDFFolder):\n",
    "        makedirs(predResultsDFFolder)\n",
    "        print 'generating predResultsDFFolder %s' %predResultsDFFolder\n",
    "        \n",
    "    predResultsfigFolder='%s/%s_predictions/figs' %(ResultFolder,YName) #define folder for figs in this model\n",
    "    if not isdir(predResultsfigFolder):\n",
    "        makedirs(predResultsfigFolder)\n",
    "        print 'predResultsfigFolder %s' %predResultsfigFolder\n",
    "\n",
    "    #generate result DF name based on model_params:\n",
    "    d=OrderedDict(sorted(model_params.items(), key=lambda t: t[0]))\n",
    "    try:\n",
    "        d2=d.copy()\n",
    "        del d2['numthreads']\n",
    "    except:\n",
    "        d2=d.copy()\n",
    "    predResultsDFName='_'.join(['%s%s' %(key.replace('_',''), value) for (key, value) in d2.items()]) #generate a file name based on params\n",
    "    predResultsDFName=predResultsDFName.replace('.','-')\n",
    "    if useCV:\n",
    "        predResultsDFName='%s_CV%s' %(predResultsDFName,n_splits)\n",
    "    \n",
    "    predResultsDFName='%s_%s' %(XName,predResultsDFName)\n",
    "    \n",
    "    predResultsDFfile='%s/%s' %(predResultsDFFolder,predResultsDFName)\n",
    "    existingDFs=[f for f in listdir( predResultsDFFolder) if isfile(join(predResultsDFFolder, f))]\n",
    "    \n",
    "\n",
    "    if predResultsDFName not in existingDFs:  \n",
    "        \n",
    "\n",
    "        # common processing of X and y:\n",
    "        # leave only common samples in each df (X and seq1data)\n",
    "        X=X.loc[[str(x) for x in X.index.tolist() if x in Y.index],:]\n",
    "        X=X.sort_index()\n",
    "        print 'X shape is %s_%s' %(X.shape[0], X.shape[1])\n",
    "        print 'the 100th sample in X is %s' %X.index[100]\n",
    "        print X.iloc[:3,:3]\n",
    "        Y=Y.loc[[str(x) for x in Y.index.tolist() if x in X.index]]\n",
    "        Y=Y.sort_index()\n",
    "#         oldColName=str(Y.columns.values[0])\n",
    "#         Y=Y.rename(columns={oldColName:'Class'})\n",
    "        print 'Y shape is %s' %(Y.shape[0])\n",
    "        print 'the 100th sample in Y is %s' %Y.index[100]\n",
    "        print Y.head(3)\n",
    "\n",
    "        #(2) model fitting and predictions:\n",
    "\n",
    "        if useCV:\n",
    "            print 'splitting train_test using cross validation with %s splits...' %n_splits\n",
    "            \n",
    "            if stratifiedCV:\n",
    "                group_kfold = StratifiedKFold(n_splits=n_splits)\n",
    "                groups=None\n",
    "            else:\n",
    "                group_kfold = GroupKFold(n_splits=n_splits)\n",
    "                groups = np.array(range(X.shape[0]))\n",
    "                \n",
    "        \n",
    "            y_pred_df = pd.DataFrame(index=Y.index, columns=['pred_proba'])\n",
    "            i=0\n",
    "            for train_index, val_index in group_kfold.split(X, Y,groups):\n",
    "                print i\n",
    "                i+=1\n",
    "                X_train, X_val = X.iloc[train_index], X.iloc[val_index]\n",
    "                y_train, y_val = Y.loc[X_train.index], Y.loc[X_val.index]\n",
    "                \n",
    "                print 'fraction of 1s in train set=%s' %(float(y_train.sum())/len(y_train))\n",
    "                print 'fraction of 1s in test set=%s' %(float(y_val.sum())/len(y_val))\n",
    "\n",
    "                # creating the model object\n",
    "                m = model(**model_params)\n",
    "\n",
    "                # fitting the training\n",
    "                m.fit(X_train, y_train,\n",
    "                        eval_set=[(X_val, y_val)],\n",
    "                        early_stopping_rounds=None, verbose=-1)\n",
    "                # getting the predictions for the test\n",
    "                y_pred_proba = m.predict_proba(X_val)\n",
    "                y_pred_df.loc[y_val.index, :] = np.expand_dims(y_pred_proba[:,1], 1)\n",
    "        else:\n",
    "            test_size = 0.33\n",
    "            print 'using normal train_test split with test_size=%s' %test_size\n",
    "            from sklearn.model_selection import train_test_split  \n",
    "            # seed = 7\n",
    "            \n",
    "            X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=test_size, stratify=Y)\n",
    "            print 'fitting model...'\n",
    "            model = model\n",
    "            model.fit(X_train, y_train)\n",
    "            # make predictions for test data\n",
    "            print 'predicting...'\n",
    "            y_pred = model.predict(X_test)\n",
    "            predictions = [round(value) for value in y_pred]\n",
    "            # evaluate predictions\n",
    "            from sklearn.metrics import accuracy_score\n",
    "            accuracy = accuracy_score(y_test, y_pred)\n",
    "            print(\"Accuracy: %.2f%%\" % (accuracy * 100.0))\n",
    "            y_pred_df = pd.DataFrame(index=Y.index, data={'pred':y_pred})\n",
    "\n",
    "        #(4) plots:\n",
    "        print 'generating plots...'\n",
    "\n",
    "        # this plot shows the probabilities returned by the predictor colored by the class\n",
    "        plt.figure(figsize=(3,2))\n",
    "        plt.scatter(range(y_pred_df.shape[0]), y_pred_df.pred_proba, c=Y)\n",
    "        plt.show()\n",
    "\n",
    "        # plot ROC and PR curves\n",
    "\n",
    "        from sklearn import metrics\n",
    "        fpr, tpr, thresholds = metrics.roc_curve(Y+1, y_pred_df.pred_proba, pos_label=2)\n",
    "        roc_auc = metrics.auc(fpr, tpr)\n",
    "        print roc_auc\n",
    "\n",
    "        plt.figure(figsize=(20,7))\n",
    "        plt.subplot(1,2,1)\n",
    "        lw = 2\n",
    "        plt.plot(fpr, tpr, color='darkorange', lw=lw, label='ROC curve (area = %0.3f)' % roc_auc)\n",
    "        plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlabel('False Positive Rate', fontsize=15)\n",
    "        plt.ylabel('True Positive Rate', fontsize=15)\n",
    "        plt.title('ROC curve - ' , fontsize=20)\n",
    "        plt.legend(loc=\"lower right\", fontsize=15)\n",
    "\n",
    "        plt.subplot(1,2,2)\n",
    "        precision, recall, _ = metrics.precision_recall_curve(Y, y_pred_df.pred_proba)\n",
    "        pr_auc = metrics.auc(recall, precision)\n",
    "\n",
    "        plt.step(recall, precision, color='b', alpha=0.2, where='post')\n",
    "        plt.fill_between(recall, precision, step='post', alpha=0.5,\n",
    "                         color='darkorange', label='Precision Recall curve - AUC = {0:0.3f}'.format(pr_auc))\n",
    "        plt.plot([0, 1], [Y.sum()/Y.shape[0], Y.sum()/Y.shape[0]], color='navy', lw=lw, linestyle='--')\n",
    "        plt.xlabel('Recall', fontsize=15)\n",
    "        plt.ylabel('Precision', fontsize=15)\n",
    "        plt.ylim([0.0, 1.05])\n",
    "        plt.xlim([0.0, 1.0])\n",
    "        plt.title('Precision Recall curve', fontsize=20)\n",
    "        plt.legend(loc=\"upper right\", fontsize=15)\n",
    "\n",
    "        if roc_auc>0.55:\n",
    "            predResultsFigfile='%s/%s_ROC-PR.png' %(predResultsfigFolder,predResultsDFName)\n",
    "            plt.savefig(predResultsFigfile, bbox_inches='tight')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "        #(5) generate summarizing df:\n",
    "        print 'generating summarizing df'\n",
    "        predResultsDF.loc[0,'Yname']=YName\n",
    "        predResultsDF.loc[0,'Xname']=XName\n",
    "        predResultsDF.loc[0,'model_name']=model_name\n",
    "        predResultsDF.loc[0,'roc_auc']=round(roc_auc,3)\n",
    "        predResultsDF.loc[0,'pr_auc']=round(pr_auc,3)\n",
    "        predResultsDF.loc[0,'useCV']=useCV\n",
    "        if useCV:\n",
    "            predResultsDF.loc[0,'n_splits']=n_splits\n",
    "        \n",
    "        \n",
    "        for (key, value) in OrderedDict(sorted(model_params.items(), key=lambda t: t[0])).items():\n",
    "            predResultsDF.loc[0,key]=value\n",
    "        \n",
    "        nPos=int(Y.sum())\n",
    "        nNeg=len(Y)-nPos\n",
    "        \n",
    "        print nPos, nNeg\n",
    "\n",
    "        predResultsDF.loc[0,'nPos']=nPos\n",
    "        predResultsDF.loc[0,'nNeg']=nNeg\n",
    "        \n",
    "        \n",
    "        predResultsDF.to_pickle(predResultsDFfile)\n",
    "        print predResultsDFfile\n",
    "        \n",
    "    else:\n",
    "        print 'this prediction already exists'\n",
    "    \n",
    "    return predResultsDF\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:59:49.256896Z",
     "start_time": "2018-07-08T20:59:47.705248Z"
    }
   },
   "outputs": [],
   "source": [
    "Y=y\n",
    "YName='isCardio'\n",
    "X=X\n",
    "XName='PNP530Cardio126Matchedss9000_onlyPhenotypes'\n",
    "ResultFolder='%s/TCR_real_data/isCardioPredictions' %MyPath\n",
    "if not isdir(ResultFolder):\n",
    "    makedirs(ResultFolder)\n",
    "model= lgb.LGBMClassifier\n",
    "model_name='LGBMClassifier'\n",
    "n_splits=3\n",
    "useCV=True\n",
    "stratifiedCV=True\n",
    "\n",
    "learning_rate=0.1\n",
    "n_estimators=100\n",
    "max_depth=3\n",
    "model_params={'learning_rate': learning_rate, 'n_estimators': n_estimators,'max_depth': max_depth,'num_threads':2}\n",
    "\n",
    "\n",
    "\n",
    "predResultsDF=predictBinaryByDistMat(Y,YName,X,XName,ResultFolder,model,model_name,model_params,n_splits,useCV=True,stratifiedCV=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-07-08T20:55:29.903255Z",
     "start_time": "2018-07-08T20:55:29.895624Z"
    }
   },
   "outputs": [],
   "source": [
    "predResultsDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run both models for the All samples (not only matched) using all features/drop TCR sequences/drop also TCR features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## add phenotypes? (CRP, blood pressure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "457px",
    "left": "2px",
    "right": "20px",
    "top": "135px",
    "width": "285px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
