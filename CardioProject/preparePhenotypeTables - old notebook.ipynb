{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from os import listdir,mkdir\n",
    "from os.path import isfile, join, isdir,exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from myplots import roundup, rounddown, find_decimal_fold, percentile_cut_off, rarefaction_calc, rarefaction_plot,draw_correlation_scatter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import cPickle as pickle\n",
    "from Bio.SeqUtils import GC\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "from skbio.diversity.alpha import shannon, simpson, berger_parker_d\n",
    "\n",
    "from pop_organize import get_sample_data, get_sample_with_dfs\n",
    "from SufficientStatistics import *\n",
    "from MyFunctionsShani import *\n",
    "import math\n",
    "from myplots import roundup, rounddown, find_decimal_fold\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import time\n",
    "cdate=str(time.strftime(\"%d%m%Y\"))\n",
    "cdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "roundup(1,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate a file to convert from BD (blood DNA) to FD (fecal DNA) samples\n",
    "as phoenotypic data tables I get from people in the lab are indexed by FD numbers:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate a file with BD numbers and dates "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I queried the database for all BD samples with their userIDs and storage using the following SQL synthas:\n",
    "select DnaID,UserID,StorageDT from Lab.hostdna \n",
    "\n",
    "and saved te results in bloodDNAID_userID_storageDate_111217.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#open this file as dataframe:\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/bloodDNAID_userID_storageDate_111217.csv'\n",
    "BDsWithDates=pd.read_csv(file1)\n",
    "BDsWithDates.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BDsWithDates[BDsWithDates['DnaID']=='BD78']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "now I don't want the userID column as it might be wrong and need to be corrected according to the reg num correction done by Daphna"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BDsWithDates2=BDsWithDates[['DnaID','StorageDT']]\n",
    "BDsWithDates2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get corrected reg num for each BD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#open the file with corrected userIDs for each BD number based on Daphna's correction for registration number:\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/CleanCorrectBloodDNASamples'\n",
    "CleanCorrectBloodDNASamples=pd.read_pickle(file1)\n",
    "CleanCorrectBloodDNASamples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_correctReg=CleanCorrectBloodDNASamples[['DnaID','correct registration code','correction status (reg number)']]\n",
    "BD_correctReg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get list of reg num+userIDs:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following file was generated by the following query to the database: \n",
    "select UserID,RegistrationCode from pnp.users "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/UserIDs_RegNum_171217.csv'\n",
    "UserIDs_RegNum_171217=pd.read_csv(file1)\n",
    "UserIDs_RegNum_171217.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge BD+date with BD+correct reg num:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_date_correctReg=pd.merge(BDsWithDates2,BD_correctReg,how='inner',left_on='DnaID',right_on='DnaID')\n",
    "print len(BD_date_correctReg)\n",
    "print len(BDsWithDates2)\n",
    "print len(BD_correctReg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_date_correctReg.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge with user ID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_date_correctReg_userID=pd.merge(BD_date_correctReg,UserIDs_RegNum_171217,how='left',left_on='correct registration code',\n",
    "                                   right_on='RegistrationCode')\n",
    "print len(BD_date_correctReg)\n",
    "print len(UserIDs_RegNum_171217)\n",
    "print len(BD_date_correctReg_userID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_date_correctReg_userID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_date_correctReg_userID[BD_date_correctReg_userID['correction status (reg number)']=='corrected'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "corrected=BD_date_correctReg_userID[BD_date_correctReg_userID['correction status (reg number)']=='corrected']\n",
    "correctedBDList=list(corrected['DnaID'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## extract the production/storage year and combine it with the userID to generate an identifier to be compared with the FD sample information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_date_correctReg_userID['Blood_Year']=BD_date_correctReg_userID['StorageDT'].str.split('-').str[0]\n",
    "BD_date_correctReg_userID['UserID']=BD_date_correctReg_userID['UserID'].astype(str)\n",
    "BD_date_correctReg_userID['UserID']=BD_date_correctReg_userID['UserID'].str.split('.').str[0]\n",
    "BD_date_correctReg_userID['UserID_bYear']=BD_date_correctReg_userID['UserID'].astype(str).str.cat(BD_date_correctReg_userID['Blood_Year'],sep='_')\n",
    "BD_date_correctReg_userID.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save to excel and pickles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/BD_date_correctReg_userID'\n",
    "BD_date_correctReg_userID.to_pickle(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/BD_date_correctReg_userIDn.xlsx'\n",
    "BD_date_correctReg_userID.to_excel(file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate FD sample file to converge with the BD sample file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/all_fd_connid.csv'\n",
    "all_fd_connids=pd.read_csv(file1)\n",
    "all_fd_connids.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_fd_connid2=all_fd_connids[['DnaID','UserID','StorageDT']]\n",
    "all_fd_connid2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "all_fd_connid2['f_Year']=all_fd_connid2['StorageDT'].str.split('-').str[0]\n",
    "all_fd_connid2['UserID']=all_fd_connid2['UserID'].astype(str)\n",
    "all_fd_connid2['UserID']=all_fd_connid2['UserID'].str.split('.').str[0]\n",
    "all_fd_connid2['UserID_fYear']=all_fd_connid2['UserID'].astype(str).str.cat(all_fd_connid2['f_Year'],sep='_')\n",
    "all_fd_connid2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "combine the relevant columns from the BD and FD tables according to the userID_year combination:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BDsWithDates2=BD_date_correctReg_userID[['DnaID','UserID','UserID_bYear']]\n",
    "all_fd_connid3=all_fd_connid2[['DnaID','UserID','UserID_fYear']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_FD=pd.merge(BDsWithDates2,all_fd_connid3,how='left',left_on=['UserID','UserID_bYear'],\n",
    "               right_on=['UserID','UserID_fYear'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_FD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print len(BD_FD)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#rename columns:\n",
    "BD_FD=BD_FD.rename(columns={'DnaID_x':'BD','DnaID_y':'FD','UserID_bYear':'UserID_Year_BDsample',\n",
    "                           'UserID_fYear':'UserID_Year_FDsample','UserID_x':'UserID_BDsample',\n",
    "                            'UserID_y':'UserID_FDsample'})\n",
    "BD_FD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## go over all BD samples that don't have matched FD sample and try to find FD sample by userID only\n",
    "add comment column, and mark that the years are not the same between the BD and FD sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_FD[BD_FD['BD']=='BD344']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_FD['Comment']=''\n",
    "for n in BD_FD[BD_FD['FD'].isnull()].index:\n",
    "        userID=BD_FD.loc[n,'UserID']\n",
    "        relevantDF=all_fd_connid3[all_fd_connid3['UserID']==userID]\n",
    "        DFlength=len(relevantDF)\n",
    "        FDlist=list(relevantDF['DnaID'])\n",
    "        UserFlist=list(relevantDF['UserID'])\n",
    "        FDyearList=list(relevantDF['UserID_fYear'])\n",
    "        BDlist=BD_FD.loc[n,'BD']\n",
    "        UserID_Year_BDsample_list=BD_FD.loc[n,'UserID_Year_BDsample']\n",
    "        newDF=pd.DataFrame({'BD':BDlist,'UserID':userID,'UserID_Year_BDsample':UserID_Year_BDsample_list,\n",
    "                          'FD':FDlist,'UserID_Year_FDsample': FDyearList,'Comment':'Not the same year!!'})\n",
    "        \n",
    "        print newDF.columns.values\n",
    "        print BD_FD.columns.values\n",
    "        BD_FD=pd.concat([BD_FD,newDF])\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "final_BD_FD=BD_FD[BD_FD['FD'].notnull()]\n",
    "final_BD_FD=final_BD_FD.reset_index()\n",
    "final_BD_FD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print len(final_BD_FD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save into pickle and excel files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/BD_FD_sample_conversion'\n",
    "final_BD_FD.to_pickle(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/BD_FD_sample_conversion.xlsx'\n",
    "final_BD_FD.to_excel(file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sanity check for samples that their userIDs were corrected:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "correctBD_FD=final_BD_FD.set_index('BD')\n",
    "correctBD_FD=correctBD_FD.loc[correctedBDList,:]\n",
    "correctBD_FD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for n in final_BD_FD.index:\n",
    "    if str(final_BD_FD.loc[n,'UserID']) not in str(final_BD_FD.loc[n,'UserID_Year_BDsample']):\n",
    "        print final_BD_FD.loc[n,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for n in final_BD_FD.index:\n",
    "    if str(final_BD_FD.loc[n,'UserID']) not in str(final_BD_FD.loc[n,'UserID_Year_FDsample']):\n",
    "        print final_BD_FD.loc[n,:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Index the phenotypic data I got from Liron by BD numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# the table from Liron;\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/full_x_nov19.csv'\n",
    "full_x_nov19=pd.read_csv(file1)\n",
    "full_x_nov19.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_x_nov19.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in full_x_nov19.columns.values:\n",
    "    if full_x_nov19[column].dtype!='float64':\n",
    "        print column, full_x_nov19[column].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge BD numbers into the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_FD_to_use=final_BD_FD[['BD','FD','Comment','UserID','UserID_Year_BDsample']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXwithBDs=pd.merge(full_x_nov19,BD_FD_to_use,how='left',left_on='FD',right_on='FD')\n",
    "print len(fullXwithBDs)\n",
    "print len(full_x_nov19)\n",
    "print len(BD_FD_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXwithBDs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## group data by BD numbers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if there are categorial variables that can't be averaged: (the answer is no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in fullXwithBDs.columns.values:\n",
    "    if fullXwithBDs[column].dtype!='float64':\n",
    "        print column, fullXwithBDs[column].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate a list of the binary variables:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in case of several entries to the same BD sample - average the other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXgroupbyBD=fullXwithBDs.groupby('BD').mean()\n",
    "fullXgroupbyBD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate FD lists per BD and integrate them to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "FDlistperBD=pd.DataFrame(fullXwithBDs.groupby('BD')['FD'].apply(list))\n",
    "FDlistperBD.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fullXgroupbyBD=pd.merge(fullXgroupbyBD,FDlistperBD,how='left',right_index=True, left_index=True)\n",
    "fullXgroupbyBD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the grouping of the binary variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binaryVariableList=[]\n",
    "for column in fullXwithBDs.columns.values:\n",
    "    values=fullXwithBDs[column].unique()\n",
    "    if len(values)<4:\n",
    "        print column, values\n",
    "        binaryVariableList.append(column)\n",
    "\n",
    "binaryVariableList.remove('Comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "print binaryVariableList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXgroupbyBD[binaryVariableList].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "binary=fullXgroupbyBD[binaryVariableList]\n",
    "for column in binary.columns.values:\n",
    "    print column, binary[column].unique()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***most of the binary variables kept their binary format after the grouping, except for the variables: Regular defecation,Regular period,IsGenotek***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/binaryVariableList.txt'\n",
    "with open(file1, \"wb\") as fp:   #Pickling\n",
    "    pickle.dump(binaryVariableList, fp)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## clean the binary variables:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXgroupbyBD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXgroupbyBD['IsGenotek'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for column in binary.columns.values:\n",
    "    condition1=fullXgroupbyBD[column]==0\n",
    "    condition2=fullXgroupbyBD[column]==1\n",
    "    fullXgroupbyBD[column]=np.where(condition1,0,(np.where(condition2,1,np.nan)))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXgroupbyBD['IsGenotek'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/fullXgroupbyBD'\n",
    "fullXgroupbyBD=pd.read_pickle(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/fullXgroupbyBD'\n",
    "fullXgroupbyBD.to_pickle(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/fullXgroupbyBD.xlsx'\n",
    "fullXgroupbyBD.to_excel(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/fullXwithBDs'\n",
    "fullXwithBDs.to_pickle(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/fullXwithBDs.xlsx'\n",
    "fullXwithBDs.to_excel(file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sanity check for the feature files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXwithBDs.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "UserIDs with many FD samples - top 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXwithBDs.groupby('UserID').count()['FD'].sort_values().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFgroupedByBD'\n",
    "SampleSpeciesDFgroupedByBD.to_pickle(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFgroupedByBD.xlsx'\n",
    "SampleSpeciesDFgroupedByBD.to_excel(file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BDs with many FD samples - top 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXwithBDs.groupby('BD').count()['FD'].sort_values().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "FD samples  with many BD samples - top 5:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXwithBDs.groupby('FD').count()['BD'].sort_values().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXwithBDs.groupby('FD').count()['UserID'].sort_values().tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get lists of BDs per userIDs for users with more than one BD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BDlistperUserID=pd.DataFrame(fullXwithBDs.groupby('UserID')['BD'].apply(list))\n",
    "BDlistperUserID_DF=pd.DataFrame()\n",
    "for n,user in enumerate(BDlistperUserID.index):\n",
    "    uniqueBDsPerUserID=list(set(BDlistperUserID.loc[user,'BD']))\n",
    "    if len(uniqueBDsPerUserID)>1:\n",
    "#         print str(uniqueFDsPerUserID)\n",
    "        BDlistperUserID_DF.loc[n,'UserID']=user\n",
    "        BDlistperUserID_DF.loc[n,'BDs']=str(uniqueBDsPerUserID)\n",
    "        BDlistperUserID_DF.loc[n,'n_BDs']=len(uniqueBDsPerUserID)\n",
    "BDlistperUserID_DF=BDlistperUserID_DF.sort_values(by='n_BDs', ascending=False)\n",
    "BDlistperUserID_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get lists of FDs per userIDs for users with more than one FD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FDlistperUserID=pd.DataFrame(fullXwithBDs.groupby('UserID')['FD'].apply(list))\n",
    "FDlistperUserID_DF=pd.DataFrame()\n",
    "for n,user in enumerate(FDlistperUserID.index):\n",
    "    uniqueFDsPerUserID=list(set(FDlistperUserID.loc[user,'FD']))\n",
    "    if len(uniqueFDsPerUserID)>1:\n",
    "#         print str(uniqueFDsPerUserID)\n",
    "        FDlistperUserID_DF.loc[n,'UserID']=user\n",
    "        FDlistperUserID_DF.loc[n,'FDs']=str(uniqueFDsPerUserID)\n",
    "        FDlistperUserID_DF.loc[n,'n_FDs']=len(uniqueFDsPerUserID)\n",
    "FDlistperUserID_DF=FDlistperUserID_DF.sort_values(by='n_FDs', ascending=False)\n",
    "FDlistperUserID_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### get lists of FDs per BD for BDs with more than one FD:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "FDlistperBD=pd.DataFrame(fullXwithBDs.groupby('BD')['FD'].apply(list))\n",
    "FDlistperBD_DF=pd.DataFrame()\n",
    "for n,BD in enumerate(FDlistperBD.index):\n",
    "    uniqueFDsPerBD=list(set(FDlistperBD.loc[BD,'FD']))\n",
    "    if len(uniqueFDsPerBD)>1:\n",
    "#         print str(uniqueFDsPerUserID)\n",
    "        FDlistperBD_DF.loc[n,'BD']=BD\n",
    "        FDlistperBD_DF.loc[n,'FDs']=str(uniqueFDsPerBD)\n",
    "        FDlistperBD_DF.loc[n,'n_FDs']=len(uniqueFDsPerBD)\n",
    "FDlistperBD_DF=FDlistperBD_DF.sort_values(by='n_FDs', ascending=False)\n",
    "FDlistperBD_DF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# process phenotypes from Izhak"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the table from Izhak;\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/PhenotypesIzhak.dat'\n",
    "PhenotypesIzhak=pd.read_pickle(file1)\n",
    "PhenotypesIzhak.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "PhenotypesIzhak.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "this phenotypes are not so interesting at this stage!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get some cohort phenotypes:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## generate df only for samples we already sequenced:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_folder='TCR_real_data'\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "print filenames[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate list of PNP434 samples without '_' and 'b' in the sample name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "PNP434samples=[]\n",
    "for sample in filenames:\n",
    "    if '_' in sample:\n",
    "        NewName=sample.split('_')[0]\n",
    "    else:\n",
    "        NewName=sample\n",
    "    if 'b' in NewName:\n",
    "        print NewName\n",
    "        NewName=NewName.split('b')[0]\n",
    "        print NewName \n",
    "    PNP434samples.append(NewName)\n",
    "# PNP434samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print len(PNP434samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/PNP434samples'\n",
    "with open(file3,'wb') as fp:\n",
    "    pickle.dump(PNP434samples,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXgroupbyBD_only434=fullXgroupbyBD.loc[PNP434samples,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fullXgroupbyBD_only434.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/fullXgroupbyBD_only434'\n",
    "fullXgroupbyBD_only434.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## calculate descriptive statistice for all cohort and for the 434 cohort:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def roundup2(a, digits=0):\n",
    "    n = 10**-digits\n",
    "    return round(math.ceil(a / n) * n, digits)\n",
    "\n",
    "\n",
    "numericalFeatures=['Age','Hemoglobin','BMI','CRP (WIDE RANGE)']\n",
    "binaryFeatures=['Gender','Ever smoked']\n",
    "\n",
    "fig1=plt.figure(figsize=(8,18))\n",
    "fig1.suptitle('Main Phenotype Distributions', fontsize=22)\n",
    "\n",
    "for n,feature in enumerate(numericalFeatures):\n",
    "    print n,feature\n",
    "    dataAll=fullXgroupbyBD[feature]\n",
    "    dataAll=list(dataAll[~np.isnan(dataAll)])\n",
    "    weightsAll=np.ones_like(dataAll)/len(dataAll)\n",
    "    meanAll=round(np.mean(dataAll),2)\n",
    "    stdAll=round(np.std(dataAll),2)\n",
    "    \n",
    "    data434=fullXgroupbyBD_only434[feature]\n",
    "    data434=list(data434[~np.isnan(data434)])\n",
    "    weights434=np.ones_like(data434)/len(data434)\n",
    "    mean434=round(np.mean(data434),2)\n",
    "    std434=round(np.std(data434),2)\n",
    "    \n",
    "    Xmin=min(dataAll)\n",
    "    Xmax=max(dataAll)\n",
    "    freqs,bins=np.histogram(dataAll,range=(Xmin,Xmax),bins=10,weights=weightsAll)\n",
    "    Ymax=roundup2(np.max(freqs),1)\n",
    "     \n",
    "        \n",
    "    ax= fig1.add_subplot(6,2,2*n+1)\n",
    "    \n",
    "    plot=ax.hist(dataAll,range=(Xmin,Xmax),bins=10,weights=weightsAll) \n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylim(0,Ymax)\n",
    "    ax.annotate(\"mean=%s+-%s\" %(meanAll,stdAll),  xy=(0.02, 0.96), xycoords='axes fraction', fontsize=12,\n",
    "    horizontalalignment='left', verticalalignment='top', fontweight='bold')\n",
    "\n",
    "    ax= fig1.add_subplot(6,2,2*n+2)\n",
    "    plot=ax.hist(data434,range=(Xmin,Xmax),bins=10,weights=weights434)\n",
    "    ax.set_xlabel(feature)\n",
    "    ax.set_ylim(0,Ymax)\n",
    "    ax.annotate(\"mean=%s+-%s\" %(mean434,std434),  xy=(0.02, 0.96), xycoords='axes fraction', fontsize=12,\n",
    "    horizontalalignment='left', verticalalignment='top', fontweight='bold')\n",
    "\n",
    "for n,Bfeature in enumerate(binaryFeatures):\n",
    "    print n,Bfeature\n",
    "    if Bfeature=='Gender':\n",
    "        ticklabels=['Male','Female']\n",
    "    elif Bfeature=='Ever smoked':\n",
    "        ticklabels=['No','Yes']\n",
    "    \n",
    "    ax= fig1.add_subplot(6,2,2*n+9)   \n",
    "    a=fullXgroupbyBD[Bfeature].value_counts(normalize=True)\n",
    "    Ymax=roundup2(a.max(), 1)\n",
    "    ax.bar([0,1],a,align='center',width=0.6,tick_label=ticklabels)\n",
    "    ax.set_xlabel(Bfeature)\n",
    "    ax.set_ylim(0,Ymax)\n",
    "    \n",
    "    ax= fig1.add_subplot(6,2,2*n+10)   \n",
    "    a=fullXgroupbyBD_only434[Bfeature].value_counts(normalize=True)\n",
    "    ax.bar([0,1],a,align='center',width=0.6,tick_label=ticklabels)\n",
    "    ax.set_xlim(-0.5,1.5)\n",
    "    ax.set_xlabel(Bfeature)\n",
    "    ax.set_ylim(0,Ymax)\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "fig1.text(0,0.5,\"Frequency\",  ha = 'left',fontsize=18, rotation=90)\n",
    "fig1.text(0.25,0.94,\"All Samples\",  ha = 'center',fontsize=18)\n",
    "fig1.text(0.75,0.94,\"434 cohort\",  ha = 'center',fontsize=18)\n",
    "\n",
    "\n",
    "fig1.subplots_adjust(left=0.09, right=0.98, top=0.92, bottom=0.02, wspace=0.22,hspace=0.30)\n",
    "\n",
    "\n",
    "\n",
    "filename='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/MainPhenotypeDistribution_%s' %cdate\n",
    "fig1.savefig(filename, bbox_inches='tight', dpi = 200)    \n",
    "    \n",
    "\n",
    "plt.show()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/Distance Matrices/PNP434_Age_EucDistMat'\n",
    "PNP434_Age_EucDistMat.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate microbiome species phenotype table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## load the table from Noam:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAP = '/net/mraid08/export/jafar/Microbiome/Analyses/AllSeqProjects/DFOut/MPASpid.dat'\n",
    "\n",
    "m = pd.read_pickle(MAP)\n",
    "SampleSpeciesDF=m.loc['s'] \n",
    "SampleSpeciesDF=SampleSpeciesDF.T\n",
    "SampleSpeciesDF.head()\n",
    "# only species\n",
    "# species over samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(SampleSpeciesDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check indices:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in SampleSpeciesDF.index:\n",
    "    if 'FD999' in n:\n",
    "        print n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the connection IDs seems to be wrong.\n",
    "generate column of only FD with split, and check whether there are repeats\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## merge file with BD_FD file based on FD numbers ONLY!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDF=SampleSpeciesDF.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(SampleSpeciesDF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDF['FD']=SampleSpeciesDF['index'].str.split('_').str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#there are no repeating FDs!\n",
    "SampleSpeciesDF['FD'].value_counts().tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'FD235' in list(SampleSpeciesDF['FD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#load BD_FD sample \n",
    "\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/BD_FD_sample_conversion'\n",
    "final_BD_FD=pd.read_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "BD_FD_to_use=final_BD_FD[['BD','FD','Comment','UserID','UserID_Year_BDsample']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SampleSpeciesDFwithBDs=pd.merge(SampleSpeciesDF,BD_FD_to_use,how='left',left_on='FD',right_on='FD')\n",
    "print len(SampleSpeciesDFwithBDs)\n",
    "print len(SampleSpeciesDF)\n",
    "print len(BD_FD_to_use)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SampleSpeciesDFwithBDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDFwithBDs=SampleSpeciesDFwithBDs.fillna(0)\n",
    "SampleSpeciesDFwithBDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDFwithBDs=SampleSpeciesDFwithBDs[SampleSpeciesDFwithBDs['BD']!=0]\n",
    "SampleSpeciesDFwithBDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(SampleSpeciesDFwithBDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'FD238_32' in list(SampleSpeciesDFwithBDs['index'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'FD235' in list(SampleSpeciesDFwithBDs['FD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'FD959' in list(SampleSpeciesDFwithBDs['FD'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDFwithBDs[SampleSpeciesDFwithBDs['FD']=='FD235'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file: \n",
    "\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFwithBDs'\n",
    "SampleSpeciesDFwithBDs.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check if there are categorial variables that can't be averaged: (the answer is no)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for column in SampleSpeciesDFwithBDs.columns.values:\n",
    "    if SampleSpeciesDFwithBDs[column].dtype!='float64':\n",
    "        print column, SampleSpeciesDFwithBDs[column].dtype"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in case of several entries to the same BD sample - average the other parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SampleSpeciesDFgroupedByBD=SampleSpeciesDFwithBDs.groupby('BD').mean()\n",
    "SampleSpeciesDFgroupedByBD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(SampleSpeciesDFgroupedByBD)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "generate FD lists per BD and integrate them to the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "FDlistperBD2=pd.DataFrame(SampleSpeciesDFwithBDs.groupby('BD')['FD'].apply(list))\n",
    "FDlistperBD2.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "SampleSpeciesDFgroupedByBD=pd.merge(SampleSpeciesDFgroupedByBD,FDlistperBD2,how='left',right_index=True, left_index=True)\n",
    "SampleSpeciesDFgroupedByBD.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check the grouping of the binary variables:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "binaryVariableList2=[]\n",
    "for column in SampleSpeciesDFwithBDs.columns.values:\n",
    "    values=SampleSpeciesDFwithBDs[column].unique()\n",
    "    if len(values)<4:\n",
    "#         print column, values\n",
    "        binaryVariableList2.append(column)\n",
    "\n",
    "binaryVariableList2.remove('Comment')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "# print binaryVariableList2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prepare sampleSpecies DF with only the 434 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/PNP434samples'\n",
    "with open(file3,'rb') as fp:\n",
    "    PNP434samples=pickle.load(fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SampleSpeciesDFgroupedByBD_only434=SampleSpeciesDFgroupedByBD.loc[PNP434samples,:]\n",
    "print len(SampleSpeciesDFgroupedByBD_only434)\n",
    "SampleSpeciesDFgroupedByBD_only434=SampleSpeciesDFgroupedByBD_only434.dropna(axis=(0,1),how='all')\n",
    "print len(SampleSpeciesDFgroupedByBD_only434)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "SampleSpeciesDFgroupedByBD_only434.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## transform SampleSpeciesDFgroupedByBD_only434 to log2 scale and save:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in SampleSpeciesDFgroupedByBD_only434.columns.values:\n",
    "\n",
    "    SampleSpeciesDFgroupedByBD_only434[column]=pd.to_numeric(SampleSpeciesDFgroupedByBD_only434[column],errors='coerce')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDFgroupedByBD_only434_log2scale = SampleSpeciesDFgroupedByBD_only434.applymap(np.log2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDFgroupedByBD_only434_log2scale.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inf=SampleSpeciesDFgroupedByBD_only434_log2scale.loc['BD438','Abiotrophia_defectiva']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDFgroupedByBD_only434_log2scale=SampleSpeciesDFgroupedByBD_only434_log2scale.replace(inf,-1000)\n",
    "SampleSpeciesDFgroupedByBD_only434_log2scale.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFwithBDs'\n",
    "SampleSpeciesDFwithBDs.to_pickle(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFwithBDs.xlsx'\n",
    "SampleSpeciesDFwithBDs.to_excel(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFgroupedByBD'\n",
    "SampleSpeciesDFgroupedByBD.to_pickle(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFgroupedByBD.xlsx'\n",
    "SampleSpeciesDFgroupedByBD.to_excel(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFgroupedByBD_only434'\n",
    "SampleSpeciesDFgroupedByBD_only434.to_pickle(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFgroupedByBD_only434.xlsx'\n",
    "SampleSpeciesDFgroupedByBD_only434.to_excel(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFgroupedByBD_only434_log2scale'\n",
    "SampleSpeciesDFgroupedByBD_only434_log2scale.to_pickle(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/SampleSpeciesDFgroupedByBD_only434_log2scale.xlsx'\n",
    "SampleSpeciesDFgroupedByBD_only434_log2scale.to_excel(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SampleSpeciesDFgroupedByBD_only434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# check phenotypic data from the database to validate the fullX file\n",
    "\n",
    "for several phenotypes, there is data for only small number of samples. for example, total protein data is available for only 18 samples out of the 434 that I work with.\n",
    "to check if this correlates with the data in the database, I extracted directly from the DB using SQL the pnp.questionnaire and pnp.questions tables and looked for how many subjects we have the relevant data. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for how many users we have data for question 1089 - total protein:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proteintotal=questWitjLookup_bloodTest[questWitjLookup_bloodTest['QuestionID']==1089]\n",
    "print len(proteintotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(proteintotal['UserID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(questWitjLookup_bloodTest['UserID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is total protein data for 1.5% of the unique UserIDs\n",
    "float(25)/1642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the PNP434 cohort, I found total protein data for 4.1% of the unique UserIDs\n",
    "\n",
    "float(18)/434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check for how many users we have data for question 1013 - CRP (WIDE RANGE):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CRPwide=questWitjLookup_bloodTest[questWitjLookup_bloodTest['QuestionID']==1013]\n",
    "print len(CRPwide)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(CRPwide['UserID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is CRPwide data for 36% of the unique UserIDs\n",
    "float(589)/1642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the PNP434 cohort, I found total protein data for 53% of the unique UserIDs\n",
    "\n",
    "float(232)/434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### check for how many users we have data for question 1085 - iron:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "iron=questWitjLookup_bloodTest[questWitjLookup_bloodTest['QuestionID']==1085]\n",
    "print len(iron)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(iron['UserID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# there is iron data for 36% of the unique UserIDs\n",
    "float(20)/1642"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# In the PNP434 cohort, I found iron data for 53% of the unique UserIDs\n",
    "\n",
    "float(18)/434"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# generate a new phenotype file by merging files that I extracted from the DB:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pnp.questionaire table extracted on 3/1/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/pnp_questionaire table from the database.csv'\n",
    "quest=pd.read_csv(file1)\n",
    "print len(quest)\n",
    "quest.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pnp.questions table extracted on 3/1/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/pnp_questions_lookupTable_fromDB.csv'\n",
    "lookup=pd.read_csv(file2)\n",
    "print len(lookup)\n",
    "lookup.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merging and processing the table:\n",
    "dropping unncessary rows\n",
    "extract the yesr and generate a UserID_year identifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questWithLookup=pd.merge(quest,lookup,how='left',left_on='QuestionID',right_on='QuestionID')\n",
    "print len(questWithLookup)\n",
    "questWithLookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questWithLookup=questWithLookup[['UserID','QuestionID','Question','Answer','Timestamp']]\n",
    "questWithLookup.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/questWithLookup.csv'\n",
    "questWithLookup.to_csv(file3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interestingQuestions=range(1005,1039)+range(1083,1092)+range(1680,1689)+[1045]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interestingQuestionsDF=pd.DataFrame(interestingQuestions)\n",
    "interestingQuestionsDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questWithLookup_Interesting=pd.merge(interestingQuestionsDF,questWithLookup,how='left',left_on=0,right_on='QuestionID')\n",
    "print len(questWithLookup_Interesting)\n",
    "questWithLookup_Interesting.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n in questWithLookup_Interesting.index:\n",
    "    m=re.search('(?<=20)\\w+', questWithLookup_Interesting.loc[n,'Timestamp'])\n",
    "    if m is not None:\n",
    "        questWithLookup_Interesting.loc[n,'year']='20'+m.group(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questWithLookup_Interesting.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questWithLookup_Interesting=questWithLookup_Interesting.drop(0,axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "no rows with no userID or quedtionID"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questWithLookup_Interesting[questWithLookup_Interesting['QuestionID'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file4='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/questWithLookup_Interesting.csv'\n",
    "questWithLookup_Interesting.to_csv(file4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questWithLookup_Interesting['year'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questWithLookup_Interesting['UserID_Year']=questWithLookup_Interesting['UserID'].astype(str).str.cat(questWithLookup_Interesting['year'],sep='_')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questWithLookup_Interesting.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### merge with BD table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/Sample files/BD_date_correctReg_userID'\n",
    "BD_date_correctReg_userID=pd.read_pickle(file1)\n",
    "BD_date_correctReg_userID.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BD_date_correctReg_userID[BD_date_correctReg_userID['DnaID']=='BD345']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BD_to_use=BD_date_correctReg_userID[['DnaID','UserID','UserID_bYear']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BD_to_use['UserID']=BD_to_use['UserID'].replace('nan',np.nan)\n",
    "BD_to_use=BD_to_use[BD_to_use['UserID'].notnull()]\n",
    "BD_to_use['UserID']=BD_to_use['UserID'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BD_to_use[BD_to_use['UserID']==82]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BD_to_use[BD_to_use['DnaID']=='BD345']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTableWithBDs=pd.merge(questWithLookup_Interesting,BD_to_use,how='left',left_on='UserID_Year',right_on='UserID_bYear')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** very important!!! now we need to delete BD nummbers from row in which the UserID_year is nan ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTableWithBDs['DnaID']=np.where(newPhenotypeTableWithBDs['UserID_Year'].isnull(),np.nan,\n",
    "                                          newPhenotypeTableWithBDs['DnaID'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(newPhenotypeTableWithBDs)\n",
    "newPhenotypeTableWithBDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(newPhenotypeTableWithBDs[newPhenotypeTableWithBDs['DnaID']=='BD345'])\n",
    "newPhenotypeTableWithBDs[newPhenotypeTableWithBDs['DnaID']=='BD345']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### go over all rows that don't have matched BD sample and try to find BD sample by userID only\n",
    "add comment column, and mark that the years are not the same between the BD and FD sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "problem=newPhenotypeTableWithBDs[newPhenotypeTableWithBDs['DnaID'].isnull()]\n",
    "problem=problem.rename(columns={'UserID_x':'UserID'})\n",
    "problem=problem[['UserID','QuestionID','Question','Answer','year','UserID_Year','UserID_bYear']]\n",
    "problem.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedByUserOnly=pd.merge(problem,BD_to_use,how='left',left_on='UserID',right_on='UserID')\n",
    "mergedByUserOnly.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(mergedByUserOnly)\n",
    "mergedByUserOnly=mergedByUserOnly[mergedByUserOnly['DnaID'].notnull()]\n",
    "print len(mergedByUserOnly)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mergedByUserOnly['comment']='Not the same year'\n",
    "newPhenotypeTableWithBDs['comment']=''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTableWithBDs=newPhenotypeTableWithBDs.rename(columns={'UserID_x':'UserID'})\n",
    "newPhenotypeTableWithBDs=newPhenotypeTableWithBDs[['UserID','DnaID','QuestionID','Question','Answer','Timestamp','year','UserID_Year','UserID_bYear','comment']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(newPhenotypeTableWithBDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTableWithBDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(newPhenotypeTableWithBDs)\n",
    "newPhenotypeTableWithBDs=pd.concat([newPhenotypeTableWithBDs,mergedByUserOnly])\n",
    "print len(newPhenotypeTableWithBDs)\n",
    "newPhenotypeTableWithBDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(newPhenotypeTableWithBDs)\n",
    "newPhenotypeTableWithBDs=newPhenotypeTableWithBDs[newPhenotypeTableWithBDs['DnaID'].notnull()]\n",
    "print len(newPhenotypeTableWithBDs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTableWithBDs.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTableWithBDs=newPhenotypeTableWithBDs[['DnaID','UserID','UserID_Year','UserID_bYear','year','QuestionID',\n",
    "                                                  'Question','Answer']]\n",
    "newPhenotypeTableWithBDs=newPhenotypeTableWithBDs.reset_index()\n",
    "newPhenotypeTableWithBDs=newPhenotypeTableWithBDs.drop('index',axis=1)\n",
    "print len(newPhenotypeTableWithBDs)\n",
    "newPhenotypeTableWithBDs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sanity check for this file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(newPhenotypeTableWithBDs['DnaID'].unique())\n",
    "print len(newPhenotypeTableWithBDs['UserID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BD_userID=newPhenotypeTableWithBDs[['DnaID','UserID']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BD_userID=BD_userID.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(newPhenotypeTableWithBDs['DnaID'].unique())\n",
    "print len(newPhenotypeTableWithBDs['UserID'].unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups=BD_userID.groupby('UserID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name,group in groups:\n",
    "    print name,group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTableWithBDs[newPhenotypeTableWithBDs['UserID']==26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "questionList=newPhenotypeTableWithBDs['Question'].unique()\n",
    "print len(questionList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(newPhenotypeTableWithBDs[newPhenotypeTableWithBDs['DnaID']=='BD345'])\n",
    "newPhenotypeTableWithBDs[newPhenotypeTableWithBDs['DnaID']=='BD345']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file3='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/newPhenotypeTableWithBDs.csv'\n",
    "newPhenotypeTableWithBDs.to_csv(file3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AVERAGE ANSWERS OVER BDs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check which questions have very few answers and should be removed from the file\n",
    "for question in questionList:\n",
    "    df=newPhenotypeTableWithBDs[newPhenotypeTableWithBDs['Question']==question]\n",
    "    if len(df['Answer'].unique())<5:\n",
    "        print question\n",
    "        print df['Answer'].value_counts()\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### organize the file so each question has its own column\n",
    "do not include questions with less than 5 unique answers\n",
    "average answers for the same question in the same BD sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTable_groupedByBD=pd.DataFrame(newPhenotypeTableWithBDs['DnaID'].unique())\n",
    "for n,question in enumerate(questionList):\n",
    "    df=newPhenotypeTableWithBDs[newPhenotypeTableWithBDs['Question']==question]\n",
    "    if len(df['Answer'].unique())>4:\n",
    "        print question\n",
    "        df=df[['DnaID','Answer']]\n",
    "        df['Answer']=pd.to_numeric(df['Answer'],errors='coerce')\n",
    "        df=df.rename(columns={'Answer':question})\n",
    "        grouped=df.groupby('DnaID').mean()\n",
    "        \n",
    "        if n==0:\n",
    "            newPhenotypeTable_groupedByBD=grouped\n",
    "        else:\n",
    "            newPhenotypeTable_groupedByBD=pd.merge(newPhenotypeTable_groupedByBD,grouped,how='left',\n",
    "                                                   left_index=True,right_index=True)\n",
    "    else:\n",
    "        print '%s have only %s values and was not included' %(question, len(df['Answer'].unique()))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTable_groupedByBD.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describe=newPhenotypeTable_groupedByBD.describe()\n",
    "describe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in describe.columns.values:\n",
    "    if describe.loc['count',column]<50:\n",
    "        print column\n",
    "        print describe.loc['count',column]\n",
    "    if 'Neutrophils' in column:\n",
    "        print column\n",
    "        print describe.loc['count',column]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTable_groupedByBD=newPhenotypeTable_groupedByBD.drop('Urine Erythrocytes',axis=1)\n",
    "newPhenotypeTable_groupedByBD=newPhenotypeTable_groupedByBD.drop('Neutrophils No.',axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/newPhenotypeTable_groupedByBD.xlsx'\n",
    "newPhenotypeTable_groupedByBD.to_excel(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/newPhenotypeTable_groupedByBD'\n",
    "newPhenotypeTable_groupedByBD.to_pickle(file2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newPhenotypeTable_groupedByBD_only434=newPhenotypeTable_groupedByBD.loc[PNP434samples,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/newPhenotypeTable_groupedByBD_only434.xlsx'\n",
    "newPhenotypeTable_groupedByBD_only434.to_excel(file1)\n",
    "\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/newPhenotypeTable_groupedByBD_only434'\n",
    "newPhenotypeTable_groupedByBD_only434.to_pickle(file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# compare the new phenotype file to Liron's file\n",
    "look for columns that doesn't exist in Liron's file\n",
    "look for column that exist but I have more data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/fullXgroupbyBD'\n",
    "fullXgroupbyBD=pd.read_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oldColumns=fullXgroupbyBD.columns.values\n",
    "newColumns=newPhenotypeTable_groupedByBD.columns.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "allcolumns=list(np.unique(list(oldColumns)+list(newColumns)))\n",
    "allcolumns.remove('FD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describeNew=newPhenotypeTable_groupedByBD.describe()\n",
    "describeNew"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "describeOld=fullXgroupbyBD.describe()\n",
    "describeNew=newPhenotypeTable_groupedByBD.describe()\n",
    "\n",
    "\n",
    "columnsList=allcolumns\n",
    "nSamplesOldList=[]\n",
    "nSamplesNewList=[]\n",
    "\n",
    "for column in allcolumns:\n",
    "    print column\n",
    "    \n",
    "    \n",
    "    if column in oldColumns:\n",
    "        print describeOld.loc['count',column]\n",
    "        if column!='FD':\n",
    "            nSamplesOld=describeOld.loc['count',column]\n",
    "            nSamplesOldList.append(nSamplesOld)\n",
    "    else:\n",
    "        nSamplesOldList.append(np.nan)\n",
    "        \n",
    "    if column in newColumns:\n",
    "        print describeNew.loc['count',column]\n",
    "        nSamplesNew=describeNew.loc['count',column]\n",
    "        nSamplesNewList.append(nSamplesNew)\n",
    "    else:\n",
    "        nSamplesNewList.append(np.nan)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsDF=pd.DataFrame({'Column':columnsList,'nSamplesOld':nSamplesOldList,'nSamplesNew':nSamplesNewList})\n",
    "columnsDF                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsDF[columnsDF['nSamplesOld']>columnsDF['nSamplesNew']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TotalNotInProd=[column for column in TotalColumns if column not in ProdColumns ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToAnalyzeFromNewFile=list(columnsDF[columnsDF['nSamplesNew'].notnull()]['Column'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsToAnalyzeFromNewFile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/PhenotypicData/columnsToAnalyzeFromNewFile'\n",
    "with open(file1,'wb') as fp:\n",
    "    pickle.dump(columnsToAnalyzeFromNewFile,fp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "506px",
    "left": "0px",
    "right": "1027px",
    "top": "111px",
    "width": "371px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
