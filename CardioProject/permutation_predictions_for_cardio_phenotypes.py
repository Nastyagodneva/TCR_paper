######################################################################################################
# File: permutation_predictions_for_cardio_phenotypes.py
# Version: 0.0
# Date: 10.12.18
# Updated: 13.12.18
# Shani Ben-Ari Fuchs, shani.ben-ari@weizmann.ac.il
# 
# Python version: 2.7
###################################################################################################
#
# directories used:
# (1) shuf_dir (shuffled X files, not specific for target but specific for cohort)
# (2) Yfolder - a folder containing diffferent Y targets
# (3) pred_dir  -the folder containing all data from original prediction
# (4) output_dir_Y - the folder to contain the plots generated by this module and summary info.
#
# other arguments: Yname, Xpath,shuf_dir,n_shuf,shuf_size, n_permut 
#
# flow: parse arguments and save, generate shuffle files, generate bootstrappedY's, plot correlations, prediction for
# all shuffle files, Ybs, nad using predictedAgeGender. plot summary figure
#########################################################################################################
#
# add:
# 1. check prediction existance before sending the job
# 2. start from specific prediction number?
# 3. dont forget to use -shuffleX 1 if more permutation than usual are needed!
#
#
#
#

# from __future__ import print_function
import matplotlib
matplotlib.use('Agg')

import sys
import numpy as np
from ShaniBA.PredictionPipeline import PredictionModuleShani
from SegalQueue.qp import qp, fakeqp
import os
from addloglevels import sethandlers
from os import listdir, mkdir, makedirs
from os.path import isfile, join, isdir, exists
import pandas as pd
from ShaniBA.myplots import *
from ShaniBA.MyFunctionsShani import *
import argparse
import json
import matplotlib.pyplot as plt


XGB_predictor_params = '\\\'{"learning_rate":[0.1,0.05,0.01,0.005],"n_estimators":\
[200,600,1000,1400],"reg_alpha":[0,1,5,10],"gamma":[0,1,5,10],"subsample":[0.5,0.7],"max_depth":[1,3,5,7,9]}\\\''


# from joblib import Parallel, delayed
# import multiprocessing
# 
# 
# 
# from multiprocessing import Pool


    
    
def gen_shuffled_x_matrices(command_args):
    
    Xpath = command_args.Xpath
    shuf_dir = command_args.shuf_dir
    if not isdir(shuf_dir): 
        print 'made new shuf_dir...'
        makedirs(shuf_dir)
    n_permut_X = command_args.n_permut_X
    shuf_size = command_args.shuf_size
    
    print 'generating %s shuffled X matrices with %s samples...' % (n_permut_X, shuf_size)
   
    try:
        X = pd.read_pickle(Xpath)
    except:
        try:
            X = pd.read_excel(Xpath).set_index('BD')
        except:
            X = pd.read_excel(Xpath)
            
    print ('X shape is: ', X.shape)
    if shuf_size > X.shape[0]:
        shuf_size = X.shape[0]
    
    for i in range(n_permut_X):
        x_shuf = pd.DataFrame(index=X.index, data=X.sample(frac=1).values)
        x_shuf = x_shuf.iloc[:shuf_size, :]
        print (i, x_shuf.shape)
        x_shuf_name = shuf_dir + 'shuf%s.dat' % i
        x_shuf.to_pickle(x_shuf_name)
        
    return


def generate_bsYs(command_args):
    
    Yname = command_args.Yname
    Yname = Yname.replace(' ', '')
    Yfolder = command_args.Yfolder
    shuf_size = command_args.shuf_size
    n_permut_Y = command_args.n_permut_Y
    
    print 'generating %s bs Y files with %s samples...' % (n_permut_Y, shuf_size)
        
    Y_file = Yfolder + Yname + '.xlsx'
    Y_file = Y_file.replace(' ', '')
    target = pd.read_excel(Y_file).set_index('BD')
    if shuf_size > target.shape[0]:
        shuf_size = target.shape[0]
    Y_bs_folder = '%s/%s_bsFiles' % (Yfolder, Yname)
    Y_bs_folder = Y_bs_folder.replace(' ', '')
    if not isdir(Y_bs_folder):
        makedirs(Y_bs_folder)

    for i in range(n_permut_Y):
        target_b = target.sample(n=shuf_size)
        target_b = target_b.sort_index()
        f1 = '%s/bs_%s.xlsx' % (Y_bs_folder, i)
        target_b.to_excel(f1)

        print (i, target_b.shape)
    
    return
    

def plot_ypred_y_corr(command_args):
    
    print 'plotting y_ypred correlations'
    
    Yname = command_args.Yname
    Yname = Yname.replace(' ', '')
    Yfolder = command_args.Yfolder
    pred_dir = command_args.pred_dir
    output_dir_Y = command_args.output_dir_Y
#     figsize= tuple([command_args.figsize_w, command_args.figsize_h])
    figsize = (10, 9)
    
    Y_file = Yfolder + Yname + '.xlsx'
    Y_file = Y_file.replace(' ', '')
    Y = pd.read_excel(Y_file).set_index('BD')
    col = Y.columns[0]
    Y = Y.rename(columns={col:'Y'})
    
    Y_pred_file = pred_dir + 'predictions_df.pkl'
    Y_pred = pd.read_pickle(Y_pred_file)
    for col in Y_pred.columns:
        if col.replace(' ', '') == Yname:
            Y_pred = Y_pred.rename(columns={col:'Y_pred'})
    Y_pred = Y_pred['Y_pred']
    
    merged = pd.merge(Y, pd.DataFrame(Y_pred), how='inner', right_index=True, left_index=True)
    data1 = merged['Y'].tolist()
    data2 = merged['Y_pred'].tolist()
    data1name = 'Y'
    data2name = 'Y_pred'
    fig, ax = plt.subplots(figsize=(10, 9))  # need to correct
    
    if command_args.ClassificationProblem:
        title = Yname + ' Predicted values distribution'
        ax, nsamples,r,p,text, handles, labels = plot_corr(data1, data2, data1name, data2name, ax, title, corrType='pearson',
                                        toAnnotate=False, plotTrendLine=False)
    else:
        title = Yname + ' correlation between real and predicted values'
        ax, nsamples, r, p, text, handles, labels = plot_corr(data1, data2, data1name, data2name, ax, title, corrType='pearson', toAnnotate=True)
   
    
    maxV = np.nanmax(data1 + data2)
    lim_val = adjusted_roundup(maxV)
    
    ax.set_ylim(0, lim_val)
    ax.set_xlim(0, lim_val)
    ticks = np.linspace(0, lim_val, 5)
    ax.set_yticks(ticks)
    ax.set_xticks(ticks)
                                                            
    plot_name = Yname + '_YYpredCorrPlot.png'
    plot_file = output_dir_Y + plot_name
    fig.savefig(plot_file, dpi=300)
    
    print 'saved correlation plot'
                                                            
    plt.show()
    
    return


def run_prediction(output_dir, Xpath, Ypath, parameter_search_type, n_random, model, nPreSelectedFeatures, k_folds, pathToModelParams,
                   multiclass):
    print ('Xpath: ', Xpath)
    print ('Ypath: ', Ypath)
    os.system('python /home/sbenari/workspace/Microbiome/ShaniBA/PredictionPipeline/PredictionModuleShani.py %(output_dir)s\
 -path_to_X %(Xpath)s -path_to_Y %(Ypath)s -multiclass %(multiclass)s -parameter_search_type %(parameter_search_type)s\
 -n_random %(n_random)s -model %(model)s -useShortVersion True -mem_def 1 -n_cols_per_job 1\
 -nPreSelectedFeatures %(nPreSelectedFeatures)s -k_folds %(k_folds)s -pathToModelParams %(pathToModelParams)s'\
 % {'output_dir': output_dir, 'Xpath':Xpath, 'Ypath': Ypath, 'parameter_search_type':parameter_search_type, 'n_random':n_random, 'model':model,
   'nPreSelectedFeatures':nPreSelectedFeatures, 'k_folds':k_folds, 'pathToModelParams':pathToModelParams, 'multiclass':multiclass})
    
    return


def run_all_predictions(i, command_args):
           
    # get parameters:
    n_permut_X = command_args.n_permut_X
    n_permut_Y = command_args.n_permut_Y
    nloops = n_permut_X + n_permut_Y + 1
    outputname = command_args.pred_dir.split('/')[-2]
    pathToModelParams = command_args.pathToModelParams
    # run predictions with shuffled X:
    if i < n_permut_X:
        
        print ('running shuffled prediction #%s' % i)
         
        XpathShuf = command_args.shuf_dir + 'shuf%s.dat' % i
        Ypath = command_args.Yfolder + command_args.Yname + '.xlsx'
        Ypath = Ypath.replace(' ', '')
        output_dir_shuf = command_args.output_dir_Y + 'shuf%s_%s/' % (i, outputname)
        if isdir(output_dir_shuf):
            if 'results_df.pkl' in listdir(output_dir_shuf):
                print 'output_dir_shuf already exist, breaking out....'
                return

        run_prediction(output_dir=output_dir_shuf, Xpath=XpathShuf, Ypath=Ypath, parameter_search_type=command_args.parameter_search_type,
                       n_random=command_args.n_random, model=command_args.model,
                       nPreSelectedFeatures=command_args.nPreSelectedFeatures, k_folds=command_args.k_folds,
                       pathToModelParams=pathToModelParams, multiclass=command_args.multiclass)

        
    # run predictions with bootstrapped y:
    elif i < (n_permut_X + n_permut_Y):
        k = i - n_permut_X
        print ('running bs prediction #%s, total prediction number is %s' % (k, i))
        Xpath = command_args.Xpath
        Ybs_path = command_args.Yfolder + command_args.Yname + '_bsFiles/bs_%s.xlsx' % k
        Ybs_path = Ybs_path.replace(' ', '')
        output_dir_bs = command_args.output_dir_Y + 'bs%s_%s/' % (k, outputname)  
        
        if isdir(output_dir_bs):
            if 'results_df.pkl' in listdir(output_dir_bs):
                print 'output_dir_bs already exist, breaking out....'
                return
        
        run_prediction(output_dir=output_dir_bs, Xpath=Xpath, Ypath=Ybs_path, parameter_search_type=command_args.parameter_search_type,
                       n_random=command_args.n_random, model=command_args.model,
                       nPreSelectedFeatures=command_args.nPreSelectedFeatures, k_folds=command_args.k_folds,
                       pathToModelParams=pathToModelParams, multiclass=command_args.multiclass)
        
     # run predictions with predictedAge and gender only as X:
     # note- here 1 -nPreSelectedFeatures should not be specified, to use all features (predAge and predGender...)
    else:
        # run with parameters for predAgeGender
        print ('running prediction with predictedAgeGender only')
        XpathPredAge = command_args.XpredAgeGenderfile
        Ypath = command_args.Yfolder + command_args.Yname + '.xlsx'
        Ypath = Ypath.replace(' ', '')
        outputname_b = '_'.join(outputname.split('_')[:-2]) + '_byPredictedAgeGender'
        output_dir_predAG = command_args.output_dir_Y + '%s/' % outputname_b
        
        if isdir(output_dir_predAG):
            if 'results_df.pkl' in listdir(output_dir_predAG):
                print 'output_dir_predAG already exist, breaking out....'
                return
        
        run_prediction(output_dir=output_dir_predAG, Xpath=XpathPredAge, Ypath=Ypath, parameter_search_type=command_args.parameter_search_type,
                       n_random=command_args.n_random, model=command_args.model,
                       nPreSelectedFeatures=2, k_folds=command_args.k_folds,
                       pathToModelParams=pathToModelParams, multiclass=command_args.multiclass)
       
    return


def gen_pos_neg_controls_plot(command_args):
    
    print 'plotting pos_neg+control+prediction plot'
    Yname = command_args.Yname
    Yname = Yname.replace(' ', '')
    pred_dir = command_args.pred_dir
    n_permut_X = command_args.n_permut_X
    n_permut_Y = command_args.n_permut_Y
    nloops = n_permut_X + n_permut_Y + 1
    output_dir_Y = command_args.output_dir_Y
    outputname = command_args.pred_dir.split('/')[-2]
    eval_metric1 = command_args.eval_metric1
    eval_metric2 = command_args.eval_metric2
    
    YnameNoSpace = Yname.replace(' ', '')
    sum_df = pd.DataFrame()
    
    # shuffled data-negative controls:
    shuf_list = []
    for i in range(n_permut_X):
        shuf_list.append('shuf%s' % i)
        output_dir_shuf = output_dir_Y + 'shuf%s_%s/' % (i, outputname)
        shuf_res_file = output_dir_shuf + 'results_df.pkl' 
        try:
            shuf_res = pd.read_pickle(shuf_res_file)
        except:
            print '%s file doesnt exist' % shuf_res_file
            continue
        for row in shuf_res.index:
            if row.replace(' ', '') == Yname:
                shuf_res.rename(index={row:Yname}, inplace=True)
        sum_df.loc['shuf%s' % i, eval_metric1] = shuf_res.loc[Yname, eval_metric1]
        sum_df.loc['shuf%s' % i, eval_metric2] = shuf_res.loc[Yname, eval_metric2]
        sum_df.loc['shuf%s' % i, 'color'] = 0  
        if i == 0: sum_df.loc['shuf%s' % i, 'label'] = True
        else: sum_df.loc['shuf%s' % i, 'label'] = False
#         except:
#                 print 'the file  %s doesnt exist' %shuf_res_file
   
    # positive controls:  
    bs_list = []          
    for k in range(n_permut_Y):
        bs_list.append('bs%s' % k)
        output_dir_bs = output_dir_Y + 'bs%s_%s/' % (k, outputname)
        bs_res_file = output_dir_bs + 'results_df.pkl' 
        try:
            bs_res = pd.read_pickle(bs_res_file)
        except:
            print '%s file doesnt exist' % bs_res_file
            continue
        for row in bs_res.index:
            if row.replace(' ', '') == Yname:
                bs_res.rename(index={row:Yname}, inplace=True) 
        sum_df.loc['bs%s' % k, eval_metric1] = bs_res.loc[Yname, eval_metric1]
        sum_df.loc['bs%s' % k, eval_metric2] = bs_res.loc[Yname, eval_metric2]
        sum_df.loc['bs%s' % k, 'color'] = 1      
        if k == 0: sum_df.loc['bs%s' % k, 'label'] = True
        else: sum_df.loc['bs%s' % k, 'label'] = False
#         except:
#                 print 'the file  %s doesnt exist' %bs_res_file

    # real experiment:
    real_results_file = pred_dir + 'results_df.pkl'
    real = pd.read_pickle(real_results_file)
    for row in real.index:
        if row.replace(' ', '') == Yname:
            real.rename(index={row:Yname}, inplace=True) 
#     print real
    real_eval_metric1 = real.loc[Yname, eval_metric1]
    real_eval_metric2 = real.loc[Yname, eval_metric2]
    sum_df.loc['real' , eval_metric1] = real_eval_metric1
    sum_df.loc['real' , eval_metric2] = real_eval_metric2
    sum_df.loc['real' , 'color'] = 2
    sum_df.loc['real', 'label'] = True

    # X=predictedAgeGenderOnly:
    try:
        outputname_b = '_'.join(outputname.split('_')[:-2]) + '_byPredictedAgeGender'
        output_dir_predAG = command_args.output_dir_Y + '%s/' % outputname_b
        AgeGender_file = output_dir_predAG + 'results_df.pkl' 
        AgeGender = pd.read_pickle(AgeGender_file)
        for row in AgeGender.index:
            if row.replace(' ', '') == Yname:
                AgeGender.rename(index={row:Yname}, inplace=True)
        sum_df.loc['predAgeGender' , eval_metric1] = AgeGender.loc[Yname, eval_metric1]
        sum_df.loc['predAgeGender' , eval_metric2] = AgeGender.loc[Yname, eval_metric2]
        sum_df.loc['predAgeGender' , 'color'] = 3
        sum_df.loc['predAgeGender', 'label'] = True
    except:
        print 'no predAgeGender file'
    
    
    sum_df = sum_df.dropna(how='any')
    fig2, ax2 = plt.subplots(figsize=(7, 7))
    colorList = ['red', 'green', 'navy', 'orange']
    labelList = ['neg control (shuffled X)', 'pos control (bootstrapped y)', 'real data', 'onlyByPredAgeGender']
#     xlist=[]
#     ylist=[]
    for i in range(sum_df.shape[0]):
        x_val = sum_df.iloc[i, 0]
        y_val = sum_df.iloc[i, 1]
#         xlist.append(x_val)
#         ylist.append(y_val)
        if sum_df.iloc[i, 3]:
            ax2.scatter(x_val, y_val, color=colorList[int(sum_df.iloc[i, 2])], label=labelList[int(sum_df.iloc[i, 2])], s=100)
        else:
            ax2.scatter(x_val, y_val, color=colorList[int(sum_df.iloc[i, 2])], s=100)
    ax2.set_xlabel(eval_metric1, fontsize='large')
    ax2.set_ylabel(eval_metric2, fontsize='large')
    ax2.set_title('Model performance - %s' % Yname)
    ax2.legend(loc=4)
    
    shuf_data_1 = sum_df.loc[shuf_list, eval_metric1].dropna().tolist()
    shuf_data_2 = sum_df.loc[shuf_list, eval_metric2].dropna().tolist()
       
    # calculate MW test between permutations and bootstrapping:
    try:
        bs_data_1 = sum_df.loc[bs_list, eval_metric1].dropna().tolist()
        bs_data_2 = sum_df.loc[bs_list, eval_metric2].dropna().tolist()
           
        MW_s_1, MW_p_1 = stats.mannwhitneyu(shuf_data_1, bs_data_1)
        MW_s_2, MW_p_2 = stats.mannwhitneyu(shuf_data_2, bs_data_2)
        ttest_s_1, ttest_p_1 = stats.ttest_ind(shuf_data_1, bs_data_1)
        ttest_s_2, ttest_p_2 = stats.ttest_ind(shuf_data_2, bs_data_2)
        mean_shuf_1 = np.nanmean(shuf_data_1)
        mean_shuf_2 = np.nanmean(shuf_data_2)
        mean_bs_1 = np.nanmean(bs_data_1)
        mean_bs_2 = np.nanmean(bs_data_2)
        max_bs_1 = np.nanmax(bs_data_1)
        max_bs_2 = np.nanmax(bs_data_2)
        max_shuf_1 = np.nanmax(shuf_data_1)
        max_shuf_2 = np.nanmax(shuf_data_2)
        
        sum_df.loc['MannWhitney_s', eval_metric1] = MW_s_1
        sum_df.loc['MannWhitney_s', eval_metric2] = MW_s_2
        sum_df.loc['MannWhitney_p', eval_metric1] = MW_p_1
        sum_df.loc['MannWhitney_p', eval_metric2] = MW_p_2
        sum_df.loc['ttest_s', eval_metric1] = ttest_s_1
        sum_df.loc['ttest_s', eval_metric2] = ttest_s_2
        sum_df.loc['ttest_p', eval_metric1] = ttest_p_1
        sum_df.loc['ttest_p', eval_metric2] = ttest_p_2
        sum_df.loc['mean_shuf', eval_metric1] = mean_shuf_1
        sum_df.loc['mean_shuf', eval_metric2] = mean_shuf_2
        sum_df.loc['mean_bs', eval_metric1] = mean_bs_1
        sum_df.loc['mean_bs', eval_metric2] = mean_bs_2
        sum_df.loc['max_bs', eval_metric1] = max_bs_1
        sum_df.loc['max_bs', eval_metric2] = max_bs_2
        sum_df.loc['max_shuf', eval_metric1] = max_shuf_1
        sum_df.loc['max_shuf', eval_metric2] = max_shuf_2
    except:
        print 'couldnt calculate MW test'
    
    
    # calculate observed p-value:
    moreSig_metric1 = [x for x in shuf_data_1 if x > real_eval_metric1]
    p_obs_metric1 = (float(len(moreSig_metric1) + 1)) / (1 + (len(shuf_data_1)))
    moreSig_metric2 = [x for x in shuf_data_2 if x > real_eval_metric2]
    p_obs_metric2 = (float(len(moreSig_metric2) + 1)) / (1 + (len(shuf_data_2)))
    
#     ax2.annotate('%s_MW_p=%s\n%s_MW_p=%s' %(eval_metric1,round(MW_p_1,6),eval_metric2,round(MW_p_2,6)),
#                  xy=(0.02, 0.96), xycoords='axes fraction', fontsize='large', horizontalalignment='left',
#                 verticalalignment='top', fontweight='bold',color='red')
    
    
    sum_df.loc['p_observbed', eval_metric1] = p_obs_metric1
    sum_df.loc['p_observbed', eval_metric2] = p_obs_metric2
    
    
    plot_name2 = Yname + '_PerformancePlot.png'
    plot_file2 = output_dir_Y + plot_name2
    fig2.savefig(plot_file2, dpi=300)
    
    print sum_df
    sum_df_file = output_dir_Y + 'sum_df_%s.xlsx' % Yname
    sum_df.to_excel(sum_df_file)
    
    print 'saved prediction plot'
    
    plt.show()


def get_args():
    print ('getting arguments')
    parser = argparse.ArgumentParser()
    parser.add_argument('output_dir_Y', help='Path to output directory', type=str, default=None)
#     parser.add_argument('output_dir', help='Path to output directory for the prediction results', type=str, default=None)
    parser.add_argument('-Yname', help='target name', type=str, default=None)
    parser.add_argument('-Xpath', help='path to feature file (will be used to predict bootstrapped Ys and to generate shuffled Xs',
                        type=str, default='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/Predictions/featureDFs/X_withPredictedAgeGender_Cardio126.dat')
    parser.add_argument('-XpredAgeGenderfile', help='path to feature file that contains only predicted Age and gender',
                        type=str, default='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/Predictions/featureDFs/PredictedAgeGender_Cardio126.dat')
    
    parser.add_argument('-shuf_dir', help='dir to save shuffled files and to use them for predictions', type=str,
                        default='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/Predictions/featureDFs/X_withPredictedAgeGender_Cardio126_shuffling/')
    parser.add_argument('-n_permut_X', help='number of permutated predictions with shuffled X', type=int,
                        default=10)
    parser.add_argument('-n_permut_Y', help='number of repeated "real" predictions', type=int,
                        default=1)
    parser.add_argument('-shuf_size', help='number of samples to include in the shuffled Xs and in the bootstrapped Ys',
                        type=int, default=126)
    parser.add_argument('-Yfolder', help='the folder where the target file is located', type=str,
                        default='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/CardioSamples/phenotypicData/')
    parser.add_argument('-pred_dir', help='prediction directory, the dir of the original prediction which is being validated',
                        type=str, default='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/predictions2/Cardio126_diseasePhenotypes/XGBreg20LOO_randomSearch_25_byRepFeatPCA10percVDJ0999PredictedAgeGender_expVar/')
    parser.add_argument('-figsize_w', help='figure width', type=int, default=10)
    parser.add_argument('-figsize_h', help='figure height', type=int, default=9)
    parser.add_argument('-n_random', help='Number of random samples', type=int, default=25)
    parser.add_argument('-k_folds', help='Number of folds, for leave one out design use 0, default is 10', type=int, default=10)
    parser.add_argument('-mem_def', help='mem_def', type=int, default=1)
    parser.add_argument('-predictor_params', help='model parameters (insert the dictionary directly. use '' to encapsulate the\
    whole dict, and "" for each string in the dicitonary. use only lists as values', type=json.loads, default={})
    parser.add_argument('-parameter_search_type', help='randomSearch or gridSearch or None. None will use default model parameters', \
    type=str, default=None)
    parser.add_argument('-model', help='which model to use - "LGBM"/"XGB"/"lin"', type=str, default="XGB")
    parser.add_argument('-score_binclass', help='scoring metric used for binary classification hyperparameter tuning', type=str, default=None)
    parser.add_argument('-score_multiclass', help='scoring metric used for multiclass classification hyperparameter tuning', type=str, default=None)
    parser.add_argument('-score_reg', help='scoring metric used for reg hyperparameter turession', type=str, default=None)
    parser.add_argument('-binary_threshold', help='float, the probablity value from which onwards the prediction is considered positive for scoring calculations',
    type=float, default=0.5)
    parser.add_argument('-multiclass', help='bolean, execute multiclass classification or not (will default into regression in case of more than two targets',
    type=bool, default=False)
    parser.add_argument('-nPreSelectedFeatures', help='int, number of features to be selected by univariate selection before model\
    application', type=int, default=999999)
    parser.add_argument('-useShortVersion', help='boolean, if True, do not calculate shap/coefs', type=bool, default=False)
    parser.add_argument('-shuffleX', help='boolean, if True, generate shuffle X files in the number of n_permute_X', type=bool,
                        default=False)
    parser.add_argument('-bsY', help='boolean, if True, generate BOOTSTRAPPED Y files in the number of n_permute_Y', type=bool,
                        default=False)
    parser.add_argument('-runPredictions', help='boolean, if True, run all predictions', type=bool, default=1)
    parser.add_argument('-generatePlots', help='boolean, if True, generate correlation plots and permutation plot',
                        type=bool, default=True)
    parser.add_argument('-pathToModelParams', help='path to excel file containing model params, first column is param\
name and the other columns in the row are the possible values. if this value is not None, then the parameters in this file\
override what is written in the argument predictor_params', type=str, default=None)
    parser.add_argument('-runOnlyPredictedAG', help='boolean, if True, run only prediction based on predictedAG. note that -runPrediction must by True',
                         type=bool, default=False)
    parser.add_argument('-eval_metric1', help='string, performance metric to be used to evaluate model performace',
                        type=str, default='pearson_r')
    parser.add_argument('-eval_metric2', help='string, performance metric to be used to evaluate model',
                        type=str, default='explained_variance_score')
    parser.add_argument('-ClassificationProblem', help='boolean, whether a classification problem or\
this arguement is used only for plotting and not passed to the prediction model', type=bool, default=False)
    command_args = parser.parse_args()

    return command_args

def main():
    command_args = get_args()
    output_dir_Y = command_args.output_dir_Y
    if not isdir(output_dir_Y):
        makedirs(output_dir_Y)
    else:
        if 'results_df.pkl' in listdir(output_dir_Y):
            print 'this directory already exist'
            return
        
    # save parameters to a text file:
    print ('saving parameters to file')
    argFile = command_args.output_dir_Y + 'argFile.txt'
    new_file = open(argFile, mode="w")
    for arg in vars(command_args): 
        new_file.write(str(arg) + ": " + str(getattr(command_args, arg)) + "\n")  
    new_file.close()
    
    if command_args.shuffleX:
        gen_shuffled_x_matrices(command_args)
    if command_args.bsY:   
        generate_bsYs(command_args)
    if command_args.runPredictions:
        print ('setting handlers...')
        sethandlers()
        
        n_permut_X = command_args.n_permut_X
        n_permut_Y = command_args.n_permut_Y
        nloops = n_permut_X + n_permut_Y + 1
        if not isdir(output_dir_Y):
            makedirs(output_dir_Y)
        tempDir = "/net/mraid08/export/jafar/Microbiome/Analyses/ShaniBAF/temp_q_dir"
        if not isdir(tempDir):
            makedirs(tempDir)
        os.chdir(tempDir)
        print 'start'
        ## the inputs for qp are: jobname, q=machine list, *** add max_r to prevent exploding the cluster!!***
        with qp(jobname='pw%s' % command_args.Yname, q=['himem7.q'], mem_def="2G", trds_def=2, deleteCSHwithnoerr=True,
                 tryrerun=False, max_u=350) as q:
            q.startpermanentrun()
            wait_on = []
            
            
        if command_args.runOnlyPredictedAG:
            print 'running only PredictedAG'
            for i in range(nloops - 1, nloops):
                print i
                wait_on.append(q.method(run_all_predictions, kwargs={'i':i, 'command_args':command_args})) 
            try:                     
                res = q.waitforresults(wait_on)
            except:
                print 'some error occured'
        else:
            for i in range(nloops):
                print i
                wait_on.append(q.method(run_all_predictions, kwargs={'i':i, 'command_args':command_args}))                      
            try:
                res = q.waitforresults(wait_on)
            except:
                print 'some error occured'
                
    if command_args.generatePlots:
        plot_ypred_y_corr(command_args)
        gen_pos_neg_controls_plot(command_args)
    
    print 'Done!'    
    return

if __name__ == "__main__":
    main()
