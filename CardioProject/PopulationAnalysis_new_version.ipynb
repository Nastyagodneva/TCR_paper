{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:24:46.119736Z",
     "start_time": "2018-06-13T13:24:41.932915Z"
    }
   },
   "outputs": [],
   "source": [
    "from os import listdir,mkdir\n",
    "from os.path import isfile, join, isdir,exists\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import re\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.backends.backend_pdf import PdfPages\n",
    "from myplots import roundup, rounddown, find_decimal_fold, percentile_cut_off, rarefaction_calc, rarefaction_plot,draw_correlation_scatter\n",
    "from matplotlib.ticker import FormatStrFormatter\n",
    "import cPickle as pickle\n",
    "from Bio.SeqUtils import GC\n",
    "import seaborn as sns\n",
    "import random\n",
    "from scipy.stats import pearsonr\n",
    "from skbio.diversity.alpha import shannon, simpson, berger_parker_d\n",
    "\n",
    "from pop_organize import get_sample_data, get_sample_with_dfs\n",
    "from SufficientStatistics import *\n",
    "from MyFunctionsShani import *\n",
    "\n",
    "from TCR_feature_generation_functions import *\n",
    "\n",
    "MyPath='/net/mraid08/export/genie/Lab/Personal/ShaniBAF'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:24:46.133040Z",
     "start_time": "2018-06-13T13:24:46.123403Z"
    }
   },
   "outputs": [],
   "source": [
    "import time\n",
    "cdate=str(time.strftime(\"%d%m%Y\"))\n",
    "cdate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run feature extraction functions on pnp530 samples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first, calculate nTemplates for cardioSamples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder='TCR_real_data'\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "print len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTemplates=pd.DataFrame() #generate empty dataframe\n",
    "\n",
    "#there is a mistake in the column names in the batch released on 25/2/18:\n",
    "#get right column names:\n",
    "f='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/SamplesForAnalysis_corrected/BD438.tsv'\n",
    "BD438=pd.read_table(f)\n",
    "right_column_names=BD438.columns.values\n",
    "newColumnList=right_column_names[:-3]\n",
    "\n",
    "for n, sample_name in enumerate(filenames):\n",
    "    print n,sample_name\n",
    "    sample_df=pd.read_table(\"/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected/%s.tsv\" %(data_folder,sample_name))\n",
    "    if newColumnList is not None: #make sure column names are correct:\n",
    "        sample_df=sample_df.iloc[:,:44]\n",
    "        sample_df.columns=newColumnList\n",
    "    sample_df=sample_df.rename(columns={'count (templates/reads)':'count (templates)'})\n",
    "\n",
    "    sample_df['prod_stat']=np.where(sample_df['sequenceStatus'] == 'In',1,0)\n",
    "    interesting_columns=['nucleotide','aminoAcid','count (templates)','frequencyCount (%)','cdr3Length',\n",
    "                         'vDeletion', 'n1Insertion', 'd5Deletion', 'd3Deletion',\n",
    "                         'n2Insertion','jDeletion','prod_stat']    \n",
    "\n",
    "    sample_df=sample_df[interesting_columns]\n",
    "    prod_df=sample_df[sample_df['prod_stat']==1]\n",
    "    nonprod_df=sample_df[sample_df['prod_stat']==0]\n",
    "    \n",
    "    n_templates_total_nt=sample_df['count (templates)'].sum()\n",
    "    n_templates_prod_nt=prod_df['count (templates)'].sum()\n",
    "    n_templates_nonprod_nt=nonprod_df['count (templates)'].sum()\n",
    "    n_templates_total_aa=sample_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "    n_templates_prod_aa=prod_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "    n_templates_nonprod_aa=nonprod_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "        \n",
    "    \n",
    "    nTemplates.loc[n,'Sample']=sample_name\n",
    "    \n",
    "    nTemplates.loc[n,'n_templates_total_nt']=n_templates_total_nt\n",
    "    nTemplates.loc[n,'n_templates_prod_nt']=n_templates_prod_nt\n",
    "    nTemplates.loc[n,'n_templates_nonprod_nt']=n_templates_nonprod_nt\n",
    "    \n",
    "    nTemplates.loc[n,'n_temp_total_aa']=n_templates_total_aa\n",
    "    nTemplates.loc[n,'n_templates_prod_aa']=n_templates_prod_aa\n",
    "    nTemplates.loc[n,'n_templates_nonprod_aa']=n_templates_nonprod_aa\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save n templates dataframe\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/nTemplatesSummary_%s_%s' %(len(filenames), cdate)\n",
    "nTemplates.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "nTemplates.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now run feature calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:39:27.407034Z",
     "start_time": "2018-06-13T13:39:20.123177Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder='TCR_real_data'\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "print len(filenames)\n",
    "\n",
    "# #there is a mistake in the column names in the batch released on 25/2/18:\n",
    "# #get right column names:\n",
    "# f='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/SamplesForAnalysis_corrected/BD438.tsv'\n",
    "# BD438=pd.read_table(f)\n",
    "# right_column_names=BD438.columns.values\n",
    "# newColumnList=right_column_names[:-3]\n",
    "\n",
    "for n,sample_name in enumerate(filenames): \n",
    "    if n<3:\n",
    "        print  n,sample_name\n",
    "        gen_descriptive_stats(sample_name,data_folder,newColumnList=None)\n",
    "        gen_geneUsageCount(sample_name,data_folder,newColumnList=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## plot sample percentiles according to number of templates:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "the function plot_nTemplates_percentile was copied to TCR_feature_generation_functions.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_nTemplates_percentile(nTemplates, datasetName,data_folder):\n",
    "    templates=list(nTemplates['n_templates_total_nt'])\n",
    "    ymax=roundup(np.max(templates),10000)\n",
    "    fig,ax=plt.subplots(figsize=(12,9))\n",
    "    perc=[0,1,2,5,7.5,10,15,20,30,40,50,60,70,80,90,95,99,100]\n",
    "    temps=[]\n",
    "    for n in perc:\n",
    "        print n,np.percentile(templates,n)\n",
    "        temps.append(np.percentile(templates,n))\n",
    "    ax.plot(perc,temps)\n",
    "    percToShow=[1,5,15]\n",
    "    tempsToShow=[]\n",
    "    for p in percToShow:\n",
    "        ind=perc.index(p)\n",
    "        t=temps[ind]\n",
    "        ax.scatter(p,t,color='r',s=20)\n",
    "        ax.annotate('%sperc-%s templates' %(p,t), xy=(p,t),\n",
    "                             xytext=(p * 1.05, t * 1.05), fontsize=8,color='r')\n",
    "    ax.set_xlabel('percent of samples',fontsize=20)\n",
    "    ax.set_ylabel('number of templates',fontsize=20)\n",
    "    ax.set_title('Cumulative distribution of #templates per sample - %s' %datasetName,fontsize=26)\n",
    "    ax.set_xlim(0,100)\n",
    "    ax.set_ylim(0,ymax)\n",
    "    \n",
    "    file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/realAnalysis/CumDistNtemplates_%s' %(data_folder,datasetName)\n",
    "    fig.savefig(file1,dpi=200)\n",
    "    \n",
    "    return fig\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/nTemplatesSummary_515_08042018' \n",
    "nTemplates=pd.read_pickle(file1)\n",
    "\n",
    "nTemplates=nTemplates\n",
    "datasetName='PNP515'\n",
    "data_folder='TCR_real_data'\n",
    "\n",
    "fig=plot_nTemplates_percentile(nTemplates, datasetName,data_folder)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(templates,bins=100)\n",
    "plt.xticks(range(0,100000,5000),rotation=90)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run feature extraction functions on Cardio126 samples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first, calculate nTemplates for cardioSamples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder='TCR_real_data/CardioSamples'\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "print len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTemplates=pd.DataFrame() #generate empty dataframe\n",
    "\n",
    "#there is a mistake in the column names in the batch released on 25/2/18:\n",
    "#get right column names:\n",
    "f='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/SamplesForAnalysis/BD438.tsv'\n",
    "BD438=pd.read_table(f)\n",
    "right_column_names=BD438.columns.values\n",
    "newColumnList=right_column_names[:-3]\n",
    "\n",
    "for n, sample_name in enumerate(filenames):\n",
    "    print n,sample_name\n",
    "    sample_df=pd.read_table(\"/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis/%s.tsv\" %(data_folder,sample_name))\n",
    "    if newColumnList is not None: #make sure column names are correct:\n",
    "        sample_df=sample_df.iloc[:,:44]\n",
    "        sample_df.columns=newColumnList\n",
    "    sample_df=sample_df.rename(columns={'count (templates/reads)':'count (templates)'})\n",
    "\n",
    "    sample_df['prod_stat']=np.where(sample_df['sequenceStatus'] == 'In',1,0)\n",
    "    interesting_columns=['nucleotide','aminoAcid','count (templates)','frequencyCount (%)','cdr3Length',\n",
    "                         'vDeletion', 'n1Insertion', 'd5Deletion', 'd3Deletion',\n",
    "                         'n2Insertion','jDeletion','prod_stat']    \n",
    "\n",
    "    sample_df=sample_df[interesting_columns]\n",
    "    prod_df=sample_df[sample_df['prod_stat']==1]\n",
    "    nonprod_df=sample_df[sample_df['prod_stat']==0]\n",
    "    \n",
    "    n_templates_total_nt=sample_df['count (templates)'].sum()\n",
    "    n_templates_prod_nt=prod_df['count (templates)'].sum()\n",
    "    n_templates_nonprod_nt=nonprod_df['count (templates)'].sum()\n",
    "    n_templates_total_aa=sample_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "    n_templates_prod_aa=prod_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "    n_templates_nonprod_aa=nonprod_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "        \n",
    "    \n",
    "    nTemplates.loc[n,'Sample']=sample_name\n",
    "    \n",
    "    nTemplates.loc[n,'n_templates_total_nt']=n_templates_total_nt\n",
    "    nTemplates.loc[n,'n_templates_prod_nt']=n_templates_prod_nt\n",
    "    nTemplates.loc[n,'n_templates_nonprod_nt']=n_templates_nonprod_nt\n",
    "    \n",
    "    nTemplates.loc[n,'n_temp_total_aa']=n_templates_total_aa\n",
    "    nTemplates.loc[n,'n_templates_prod_aa']=n_templates_prod_aa\n",
    "    nTemplates.loc[n,'n_templates_nonprod_aa']=n_templates_nonprod_aa\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save n templates dataframe\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/CardioSamples/nTemplatesSummary_%s_%s' %(len(filenames), cdate)\n",
    "nTemplates.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTemplates.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion: using 2000 as minimal number of nucleotides and 200 as minimal number of aa is ok. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate nTemplates cumulative distribution for Cardio91:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/CardioSamples/nTemplatesSummary_91_08042018' \n",
    "nTemplates=pd.read_pickle(file1)\n",
    "\n",
    "nTemplates=nTemplates\n",
    "datasetName='Cardio91'\n",
    "data_folder='TCR_real_data/CardioSamples'\n",
    "\n",
    "fig=plot_nTemplates_percentile(nTemplates, datasetName,data_folder)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now run feature calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:42:31.754952Z",
     "start_time": "2018-06-13T13:39:39.683867Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder='TCR_real_data/CardioSamples'\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "print len(filenames)\n",
    "\n",
    "# #there is a mistake in the column names in the batch released on 25/2/18:\n",
    "# #get right column names:\n",
    "# f='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/SamplesForAnalysis/BD438.tsv'\n",
    "# BD438=pd.read_table(f)\n",
    "# right_column_names=BD438.columns.values\n",
    "# newColumnList=right_column_names[:-3]\n",
    "\n",
    "for n,sample_name in enumerate(filenames): \n",
    "#     if n>3:\n",
    "        print  n,sample_name\n",
    "        gen_descriptive_stats(sample_name,data_folder,newColumnList=None)\n",
    "        gen_geneUsageCount(sample_name,data_folder,newColumnList=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run feature extraction functions on Ravidsamples:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### first, calculate nTemplates for cardioSamples\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:43:25.450919Z",
     "start_time": "2018-06-13T13:43:25.442290Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder='TCR_real_data/RavidSamples'\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "print len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:44:13.929127Z",
     "start_time": "2018-06-13T13:44:13.407645Z"
    }
   },
   "outputs": [],
   "source": [
    "nTemplates=pd.DataFrame() #generate empty dataframe\n",
    "\n",
    "# #there is a mistake in the column names in the batch released on 25/2/18:\n",
    "# #get right column names:\n",
    "# f='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/SamplesForAnalysis_corrected/BD438.tsv'\n",
    "# BD438=pd.read_table(f)\n",
    "# right_column_names=BD438.columns.values\n",
    "# newColumnList=right_column_names[:-3]\n",
    "\n",
    "for n, sample_name in enumerate(filenames):\n",
    "    print n,sample_name\n",
    "    sample_df=pd.read_table(\"/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected/%s.tsv\" %(data_folder,sample_name))\n",
    "#     if newColumnList is not None: #make sure column names are correct:\n",
    "#         sample_df=sample_df.iloc[:,:44]\n",
    "#         sample_df.columns=newColumnList\n",
    "    sample_df=sample_df.rename(columns={'count (templates/reads)':'count (templates)'})\n",
    "\n",
    "    sample_df['prod_stat']=np.where(sample_df['sequenceStatus'] == 'In',1,0)\n",
    "    interesting_columns=['nucleotide','aminoAcid','count (templates)','frequencyCount (%)','cdr3Length',\n",
    "                         'vDeletion', 'n1Insertion', 'd5Deletion', 'd3Deletion',\n",
    "                         'n2Insertion','jDeletion','prod_stat']    \n",
    "\n",
    "    sample_df=sample_df[interesting_columns]\n",
    "    prod_df=sample_df[sample_df['prod_stat']==1]\n",
    "    nonprod_df=sample_df[sample_df['prod_stat']==0]\n",
    "    \n",
    "    n_templates_total_nt=sample_df['count (templates)'].sum()\n",
    "    n_templates_prod_nt=prod_df['count (templates)'].sum()\n",
    "    n_templates_nonprod_nt=nonprod_df['count (templates)'].sum()\n",
    "    n_templates_total_aa=sample_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "    n_templates_prod_aa=prod_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "    n_templates_nonprod_aa=nonprod_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "        \n",
    "    \n",
    "    nTemplates.loc[n,'Sample']=sample_name\n",
    "    \n",
    "    nTemplates.loc[n,'n_templates_total_nt']=n_templates_total_nt\n",
    "    nTemplates.loc[n,'n_templates_prod_nt']=n_templates_prod_nt\n",
    "    nTemplates.loc[n,'n_templates_nonprod_nt']=n_templates_nonprod_nt\n",
    "    \n",
    "    nTemplates.loc[n,'n_temp_total_aa']=n_templates_total_aa\n",
    "    nTemplates.loc[n,'n_templates_prod_aa']=n_templates_prod_aa\n",
    "    nTemplates.loc[n,'n_templates_nonprod_aa']=n_templates_nonprod_aa\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:44:17.979483Z",
     "start_time": "2018-06-13T13:44:17.972773Z"
    }
   },
   "outputs": [],
   "source": [
    "#save n templates dataframe\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/RavidSamples/nTemplatesSummary_%s_%s' %(len(filenames), cdate)\n",
    "nTemplates.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:44:19.735330Z",
     "start_time": "2018-06-13T13:44:19.688213Z"
    }
   },
   "outputs": [],
   "source": [
    "nTemplates.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "conclusion: using 2000 as minimal number of nucleotides and 200 as minimal number of aa is ok. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### generate nTemplates cumulative distribution for Cardio91:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:48:11.542741Z",
     "start_time": "2018-06-13T13:48:10.553083Z"
    }
   },
   "outputs": [],
   "source": [
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/RavidSamples/nTemplatesSummary_4_13062018' \n",
    "nTemplates=pd.read_pickle(file1)\n",
    "\n",
    "nTemplates=nTemplates\n",
    "datasetName='RavidSamples'\n",
    "data_folder='TCR_real_data/RavidSamples'\n",
    "\n",
    "fig=plot_nTemplates_percentile(nTemplates, datasetName,data_folder)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### now run feature calculations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-06-13T13:49:17.665047Z",
     "start_time": "2018-06-13T13:49:08.452270Z"
    }
   },
   "outputs": [],
   "source": [
    "data_folder='TCR_real_data/RavidSamples'\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis_corrected' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "print len(filenames)\n",
    "\n",
    "# #there is a mistake in the column names in the batch released on 25/2/18:\n",
    "# #get right column names:\n",
    "# f='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/SamplesForAnalysis/BD438.tsv'\n",
    "# BD438=pd.read_table(f)\n",
    "# right_column_names=BD438.columns.values\n",
    "# newColumnList=right_column_names[:-3]\n",
    "\n",
    "for n,sample_name in enumerate(filenames): \n",
    "#     if n>3:\n",
    "        print  n,sample_name\n",
    "        gen_descriptive_stats(sample_name,data_folder,newColumnList=None)\n",
    "        gen_geneUsageCount(sample_name,data_folder,newColumnList=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run feature extraction functions on PNP_ss18000 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTemplates=18000\n",
    "data_folder='TCR_real_data/SubSampled%s data' %nTemplates ## change here for the relevant folder\n",
    "\n",
    "\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "filenames=[f.strip('.xlsx') for f in filenames]\n",
    "print len(filenames)\n",
    "\n",
    "# #there is a mistake in the column names in the batch released on 25/2/18:\n",
    "# #get right column names:\n",
    "# f='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis/BD438_%s.xlsx' %(data_folder, nTemplates)\n",
    "# BD438=pd.read_excel(f)\n",
    "# right_column_names=BD438.columns.values\n",
    "newColumnList=None\n",
    "\n",
    "for n,sample_name in enumerate(filenames): \n",
    "    if n>91: \n",
    "        print  n,sample_name\n",
    "        if 'nSampled' not in sample_name:\n",
    "            gen_descriptive_stats(sample_name,data_folder,newColumnList)\n",
    "            gen_geneUsageCount(sample_name,data_folder,newColumnList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run feature extraction functions on PNP515_ss12500 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTemplates=12500\n",
    "data_folder='TCR_real_data/SubSampled%s data' %nTemplates ## change here for the relevant folder\n",
    "\n",
    "\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "filenames=[f.strip('.xlsx') for f in filenames]\n",
    "print len(filenames)\n",
    "\n",
    "# #there is a mistake in the column names in the batch released on 25/2/18:\n",
    "# #get right column names:\n",
    "# f='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis/BD438_%s.xlsx' %(data_folder, nTemplates)\n",
    "# BD438=pd.read_excel(f)\n",
    "# right_column_names=BD438.columns.values\n",
    "newColumnList=None\n",
    "\n",
    "for n,sample_name in enumerate(filenames): \n",
    "#     if n<92: \n",
    "        print  n,sample_name\n",
    "        if 'nSampled' not in sample_name:\n",
    "            gen_descriptive_stats(sample_name,data_folder,newColumnList)\n",
    "            gen_geneUsageCount(sample_name,data_folder,newColumnList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run feature extraction functions on PNP515_ss9000 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTemplates=9000\n",
    "data_folder='TCR_real_data/SubSampled%s data' %nTemplates ## change here for the relevant folder\n",
    "\n",
    "\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "filenames=[f.strip('.xlsx') for f in filenames]\n",
    "print len(filenames)\n",
    "\n",
    "# #there is a mistake in the column names in the batch released on 25/2/18:\n",
    "# #get right column names:\n",
    "# f='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis/BD438_%s.xlsx' %(data_folder, nTemplates)\n",
    "# BD438=pd.read_excel(f)\n",
    "# right_column_names=BD438.columns.values\n",
    "newColumnList=None\n",
    "\n",
    "for n,sample_name in enumerate(filenames): \n",
    "#     if n<92: \n",
    "        print  n,sample_name\n",
    "        if 'nSampled' not in sample_name:\n",
    "            gen_descriptive_stats(sample_name,data_folder,newColumnList)\n",
    "            gen_geneUsageCount(sample_name,data_folder,newColumnList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run feature extraction functions on REPEATED PNP515_ss9000 samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTemplates=9000\n",
    "data_folder='TCR_real_data/SubSampled%sdataRepeated' %nTemplates ## change here for the relevant folder\n",
    "\n",
    "\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "filenames=[f.strip('.xlsx') for f in filenames]\n",
    "print len(filenames)\n",
    "\n",
    "# #there is a mistake in the column names in the batch released on 25/2/18:\n",
    "# #get right column names:\n",
    "# f='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis/BD438_%s.xlsx' %(data_folder, nTemplates)\n",
    "# BD438=pd.read_excel(f)\n",
    "# right_column_names=BD438.columns.values\n",
    "newColumnList=None\n",
    "\n",
    "for n,sample_name in enumerate(filenames): \n",
    "#     if n>91: \n",
    "        print  n,sample_name\n",
    "        if 'nSampled' not in sample_name:\n",
    "            gen_descriptive_stats(sample_name,data_folder,newColumnList)\n",
    "            gen_geneUsageCount(sample_name,data_folder,newColumnList)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# develop feature extraction statistics:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all functions below were copied to 'TCR_feature_generation_functions.py' -use from there and\n",
    "update there!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define functions to calculate statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### non-gene usage functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function gets as input the tuple (df type, df data)\n",
    "#df type can be 'Total', 'Prod' or 'nonProd', and the df data is the dataframe itself. \n",
    "def gen_LengthFeaturesAndMore(df):\n",
    "    \n",
    "    file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/LengthFeaturesAndMore/%s' %(data_folder,df[0],sample_name) \n",
    "    dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/LengthFeaturesAndMore' %(data_folder,df[0])\n",
    "    if not isdir(dfs_folder):\n",
    "        mkdir(dfs_folder) \n",
    "    files=[f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "\n",
    "    \n",
    "    if sample_name not in files:\n",
    "        print('calculating length features...')\n",
    "        DF=df[1] #DF is only the data\n",
    "        DF=DF.drop(['nucleotide','aminoAcid'],axis=1) #drop those columns as they interfere with the mean,max,std calculations\n",
    "        LengthFeaturesAndMore=pd.DataFrame() #generate empty dataframe\n",
    "        LengthFeaturesAndMore.loc[0,'Sample']=sample_name \n",
    "        LengthFeaturesAndMore.loc[0,'df type']=df[0]\n",
    "        for column in DF.columns.values: #loop over each column and calculate its mean, std and max, store information in the dataframe\n",
    "            LengthFeaturesAndMore.loc[0,'%s_mean' %column]=DF[column].mean()\n",
    "            LengthFeaturesAndMore.loc[0,'%s_std' %column]=DF[column].std()\n",
    "            LengthFeaturesAndMore.loc[0,'%s_max' %column]=DF[column].max()\n",
    "    #     if df[0]=='Total':\n",
    "    #         LengthFeaturesAndMore.loc[0,'perc_prod']=DF['prod_stat'].mean()\n",
    "    #     else:\n",
    "    #         LengthFeaturesAndMore.loc[0,'perc_prod']=np.nan\n",
    "\n",
    "        #save dataframe for each df type in each sample that contains length features:\n",
    "        LengthFeaturesAndMore.to_pickle(file1)\n",
    "    else:\n",
    "        print('found length features for this sample...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# calculate the mean %gc in all NT sequences in a specific df:\n",
    "#this function is used within gen_generalFeatures\n",
    "def gc_content(df):\n",
    "    seqs=list(df['nucleotide'])\n",
    "    gc_values = [GC(seq) for seq in seqs]\n",
    "    mean_gc=np.mean(gc_values)\n",
    "    return mean_gc\n",
    "\n",
    "\n",
    "# this function gets as input the tuple (df type, df data)\n",
    "#df type can be 'Total', 'Prod' or 'nonProd', and the df data is the dataframe itself. \n",
    "\n",
    "def gen_generalFeatures(df):\n",
    "    \n",
    "    file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/GeneralFeatures/%s' %(data_folder,df[0],sample_name)   \n",
    "    dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/GeneralFeatures' %(data_folder,df[0])\n",
    "    if not isdir(dfs_folder):\n",
    "            mkdir(dfs_folder)    \n",
    "    files=[f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "    \n",
    "    if sample_name not in files:\n",
    "        print('calculating general features...')\n",
    "\n",
    "        generalFeatures=pd.DataFrame() #generate empty dataframe\n",
    "        generalFeatures.loc[0,'Sample']=sample_name\n",
    "        generalFeatures.loc[0,'df type']=df[0]\n",
    "        #calculate general features:\n",
    "        generalFeatures.loc[0,'NT count']=len(df[1])\n",
    "        n_aa_in_total=len(df[1].groupby('aminoAcid'))\n",
    "        generalFeatures.loc[0,'AA count']=n_aa_in_total\n",
    "        nt_per_aa=df[1].groupby(['aminoAcid'])[['nucleotide']].count() #for each aa sequence, count how many nt sequence generate the same one\n",
    "        max_nt_per_aa=max(nt_per_aa['nucleotide'])\n",
    "        mean_nt_per_aa=round(np.mean(nt_per_aa['nucleotide']),3)\n",
    "        generalFeatures.loc[0,'max_nt_per_aa']=max_nt_per_aa\n",
    "        generalFeatures.loc[0,'mean_nt_per_aa']=mean_nt_per_aa\n",
    "        generalFeatures.loc[0,'gc_content']=gc_content(df[1])\n",
    "\n",
    "\n",
    "        #save dataframe for each df type in each sample that contains general  features:\n",
    "        generalFeatures.to_pickle(file1)\n",
    "    \n",
    "    else:\n",
    "        print('found General Features for this sample...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function counts the number of unique sequences per defined number of templates, using random sampling without replacement:\n",
    "def norm_uniqe_nt_sequences(df): \n",
    "    repeats=10\n",
    "    samp_size=2000 # this number was selected based on the PNP cohort data, can be changed but need to change the column name in the df!\n",
    "    reads=list(df['count (templates)'])\n",
    "    df=df.set_index('nucleotide')\n",
    "    seqs=[str(i) for i in list(df.index)]\n",
    "    seq_popped=[]\n",
    "    for i in range(0,len(seqs)):\n",
    "        for j in range(0,reads[i]):\n",
    "            seq_popped.append(seqs[i])        \n",
    "    seq_n_list=[]\n",
    "    n_templates_NT=len(seq_popped)\n",
    "    if len(seq_popped)>samp_size:\n",
    "        for t in range(repeats): #as the calculation has a random component, repeat this calculation several times and average\n",
    "            rand_seq=np.random.choice(seq_popped, samp_size, replace=False)\n",
    "            seq_n=len(set(rand_seq))\n",
    "            seq_n_list.append(seq_n)\n",
    "            mean_seq_n=np.mean(seq_n_list)\n",
    "    else:\n",
    "        mean_seq_n=np.NaN\n",
    "        \n",
    "    return mean_seq_n \n",
    "\n",
    "\n",
    "\n",
    "#this function counts the number of unique sequences per defined number of templates, using random sampling without replacement:\n",
    "def norm_uniqe_aa_sequences(df): \n",
    "    repeats=10\n",
    "    samp_size=200 # this number was selected based on the PNP cohort data, can be changed but need to change the column name in the df!\n",
    "    reads=list(df['count (templates)'])\n",
    "    list_aa=list(df['aminoAcid'])  \n",
    "    seq_aa_popped=[]\n",
    "    for i in range(0,len(list_aa)):\n",
    "        for j in range(0,reads[i]):\n",
    "            seq_aa_popped.append(list_aa[i])\n",
    "    seq_aa_popped_new=[i for i in seq_aa_popped if isinstance(i, str)]\n",
    "    seq_n_list=[]\n",
    "    n_templates_aa=len(seq_aa_popped_new)\n",
    "    if len(seq_aa_popped_new)>samp_size:\n",
    "        for t in range(repeats): #as the calculation has a random component, repeat this calculation several times and average\n",
    "            rand_seq=np.random.choice(seq_aa_popped_new, samp_size, replace=False)\n",
    "            seq_n=len(set(rand_seq))\n",
    "            seq_n_list.append(seq_n)\n",
    "        mean_seq_n=np.mean(seq_n_list)\n",
    "    else:\n",
    "        mean_seq_n=np.NaN\n",
    "    return mean_seq_n         \n",
    "\n",
    "\n",
    "\n",
    "def gen_normSeqNums(df):\n",
    "    \n",
    "    file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/normSeqNums/%s' %(data_folder,df[0],sample_name)   \n",
    "    dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/normSeqNums'  %(data_folder, df[0])\n",
    "    if not isdir(dfs_folder):\n",
    "            mkdir(dfs_folder)  \n",
    "    files=[f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "    \n",
    "    if sample_name not in files:\n",
    "        print('calculating normSeqNums features...')\n",
    "\n",
    "        normSeqNums=pd.DataFrame() #generate empty dataframe\n",
    "        normSeqNums.loc[0,'Sample']=sample_name\n",
    "        normSeqNums.loc[0,'df type']=df[0]\n",
    "\n",
    "        DF=df[1]\n",
    "\n",
    "        #calculate general features:\n",
    "        normSeqNums.loc[0,'normSeqNums_per2000_NT']=norm_uniqe_nt_sequences(DF)\n",
    "        normSeqNums.loc[0,'normSeqNums_per200_AA']=norm_uniqe_aa_sequences(DF)\n",
    "\n",
    "        #save dataframe for each df type in each sample that contains general  features:\n",
    "\n",
    "        normSeqNums.to_pickle(file1)\n",
    "    else:\n",
    "        print('found normSeqNums for this sample...')\n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function gets as input the tuple (df type, df data)\n",
    "#df type can be 'Total', 'Prod' or 'nonProd', and the df data is the dataframe itself. \n",
    "\n",
    "def gen_clonalityFeatures(df):\n",
    "    \n",
    "    \n",
    "    file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/ClonalityFeatures/%s' %(data_folder,df[0],sample_name)\n",
    "    dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/ClonalityFeatures' %(data_folder,df[0])\n",
    "    if not isdir(dfs_folder):\n",
    "            mkdir(dfs_folder)   \n",
    "    files=[f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "    \n",
    "    if sample_name not in files:\n",
    "        print('calculating clonality features...')\n",
    "\n",
    "        DF=df[1] #DF is only the data\n",
    "        DF_aa=pd.DataFrame(DF.groupby('aminoAcid').sum()['frequencyCount (%)'])\n",
    "        DF['clonality_nt']=DF['frequencyCount (%)']/DF['frequencyCount (%)'].sum()\n",
    "        DF_aa['clonality_aa']=DF_aa['frequencyCount (%)']/DF_aa['frequencyCount (%)'].sum()\n",
    "        clonalityList_nt=list(DF['clonality_nt'].sort_values(ascending=False))\n",
    "        clonalityList_aa=list(DF_aa['clonality_aa'].sort_values(ascending=False))\n",
    "\n",
    "        if len(clonalityList_nt)<100:\n",
    "            top100clonal_nt=np.nan\n",
    "        else:\n",
    "            top100clonal_nt=np.sum(clonalityList_nt[:100])\n",
    "\n",
    "\n",
    "        if len(clonalityList_aa)<100:\n",
    "            top100clonal_aa=np.nan\n",
    "        else:\n",
    "            top100clonal_aa=np.sum(clonalityList_nt[:100])\n",
    "\n",
    "        topClonal_nt=np.max(clonalityList_nt)\n",
    "        meanClonal_nt=np.mean(clonalityList_nt)\n",
    "        medianClonal_nt=np.median(clonalityList_nt)\n",
    "        stdClonal_nt=np.std(clonalityList_nt)\n",
    "        percentile1_nt=np.percentile(clonalityList_nt,1)\n",
    "        percentile999_nt=np.percentile(clonalityList_nt,99.9)\n",
    "\n",
    "        topClonal_aa=np.max(clonalityList_aa)\n",
    "        meanClonal_aa=np.mean(clonalityList_aa)\n",
    "        medianClonal_aa=np.median(clonalityList_aa)\n",
    "        stdClonal_aa=np.std(clonalityList_aa)\n",
    "        percentile1_aa=np.percentile(clonalityList_aa,1)\n",
    "        percentile999_aa=np.percentile(clonalityList_aa,99.9)\n",
    "\n",
    "        clonFeatures=pd.DataFrame() #generate empty dataframe\n",
    "        clonFeatures.loc[0,'Sample']=sample_name\n",
    "        clonFeatures.loc[0,'df type']=df[0]\n",
    "        clonFeatures.loc[0,'topClonal_nt']=topClonal_nt\n",
    "        clonFeatures.loc[0,'meanClonal_nt']=meanClonal_nt\n",
    "        clonFeatures.loc[0,'medianClonal_nt']=medianClonal_nt\n",
    "        clonFeatures.loc[0,'stdClonal_nt']=stdClonal_nt\n",
    "        clonFeatures.loc[0,'percentile1_nt']=percentile1_nt\n",
    "        clonFeatures.loc[0,'percentile999_nt']=percentile999_nt\n",
    "        clonFeatures.loc[0,'topClonal_aa']=topClonal_aa\n",
    "        clonFeatures.loc[0,'meanClonal_aa']=meanClonal_aa\n",
    "        clonFeatures.loc[0,'medianClonal_aa']=medianClonal_aa\n",
    "        clonFeatures.loc[0,'stdClonal_aa']=stdClonal_aa\n",
    "        clonFeatures.loc[0,'percentile1_aa']=percentile1_aa\n",
    "        clonFeatures.loc[0,'percentile999_aa']=percentile999_aa\n",
    "\n",
    "        #save dataframe for each df type in each sample that contains general  features:\n",
    "        clonFeatures.to_pickle(file1)\n",
    "        \n",
    "    else:\n",
    "        print('found clonality features for this sample...')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this function gets as input the tuple (df type, df data)\n",
    "#df type can be 'Total', 'Prod' or 'nonProd', and the df data is the dataframe itself. \n",
    "\n",
    "def gen_diversityFeatures(df):\n",
    "    \n",
    "    file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/DiversityFeatures/%s' %(data_folder,df[0],sample_name)\n",
    "    dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/DiversityFeatures' %(data_folder,df[0])\n",
    "    if not isdir(dfs_folder):\n",
    "            mkdir(dfs_folder)\n",
    "    files=[f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "    \n",
    "    if sample_name not in files:\n",
    "        print('calculating diversity features...')\n",
    "\n",
    "        DF=df[1] #DF is only the data\n",
    "        DF_aa=pd.DataFrame(DF.groupby('aminoAcid').sum()['count (templates)'])\n",
    "\n",
    "        shannon_nt=shannon(DF['count (templates)'], base=2)\n",
    "        simpson_nt=simpson(DF['count (templates)'])\n",
    "        berger_nt=berger_parker_d(DF['count (templates)'])\n",
    "        shannon_aa=shannon(DF_aa['count (templates)'], base=2)\n",
    "        simpson_aa=simpson(DF_aa['count (templates)'])\n",
    "        berger_aa=berger_parker_d(DF_aa['count (templates)'])\n",
    "\n",
    "        diversityFeatures=pd.DataFrame() #generate empty dataframe\n",
    "        diversityFeatures.loc[0,'Sample']=sample_name\n",
    "        diversityFeatures.loc[0,'df type']=df[0]\n",
    "        diversityFeatures.loc[0,'shannon_nt']=shannon_nt\n",
    "        diversityFeatures.loc[0,'simpson_nt']=simpson_nt\n",
    "        diversityFeatures.loc[0,'berger_nt']=berger_nt\n",
    "        diversityFeatures.loc[0,'shannon_aa']=shannon_aa\n",
    "        diversityFeatures.loc[0,'simpson_aa']=simpson_aa\n",
    "        diversityFeatures.loc[0,'berger_aa']=berger_aa\n",
    "\n",
    "        #save dataframe for each df type in each sample that contains general  features:\n",
    "        diversityFeatures.to_pickle(file1)\n",
    "    else:\n",
    "        print('found diversityFeatures for this sample...')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### gene usage functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## this function counts independent gene usage **without unresolved!!**:\n",
    "\n",
    "\n",
    "def count_geneUsage(df):\n",
    "    print('counting gene usage features...')\n",
    "    \n",
    "    param_list=['vGeneName','vFamilyName','dFamilyName','jGeneName']\n",
    "    DF=df[1]\n",
    "    \n",
    "    for param in param_list:\n",
    "        file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/%s/%s' %(data_folder, df[0],param,sample_name)\n",
    "        dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/%s/' %(data_folder,df[0],param)\n",
    "        if not isdir(dfs_folder):\n",
    "            mkdir(dfs_folder)\n",
    "        files=[f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "    \n",
    "        if sample_name not in files:\n",
    "            print('calculating gene usage for param %s' %param)\n",
    "            GeneUsage=pd.DataFrame(DF[param].value_counts(normalize=True))\n",
    "            GeneUsage=GeneUsage.rename(columns={'%s' %param: '%s' %sample_name})\n",
    "            GeneUsage=GeneUsage.T\n",
    "            GeneUsage.loc[sample_name,'df type']=df[0]\n",
    "            GeneUsage.to_pickle(file1)\n",
    "        else:\n",
    "            print('found gene usage count for %s' %param)\n",
    "\n",
    "            \n",
    "## this function counts dependent (combined) gene usage **without unresolved!!**:\n",
    "def count_dependent_geneUsage(df):\n",
    "    print('counting dependent gene usage features...')\n",
    "    \n",
    "    dep_param_list=['V-J family combination','D-J gene combination']\n",
    "    DF=df[1]\n",
    "    DF['V-J family combination']=DF['vFamilyName']+'_'+DF['jFamilyName']\n",
    "    DF['D-J gene combination']=DF['dFamilyName']+'_'+DF['jGeneName']\n",
    "    \n",
    "    for dep_param in dep_param_list:\n",
    "        file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/%s/%s' %(data_folder,df[0],dep_param,sample_name)        \n",
    "        dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/descriptiveStatsSamplesForAnalysis/%s/%s/' %(data_folder, df[0],dep_param)\n",
    "        \n",
    "        if not isdir(dfs_folder):\n",
    "            mkdir(dfs_folder) \n",
    "        files=[f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "    \n",
    "        if sample_name not in files:\n",
    "            print('calculating dep gene usage for dep param %s' %dep_param)\n",
    "\n",
    "            depGeneUsage=pd.DataFrame(DF[dep_param].value_counts(normalize=True))\n",
    "            depGeneUsage=depGeneUsage.rename(columns={'%s' %dep_param: '%s' %sample_name})\n",
    "            depGeneUsage=depGeneUsage.T\n",
    "            depGeneUsage.loc[sample_name,'df type']=df[0]\n",
    "            depGeneUsage.to_pickle(file1)\n",
    "        else:\n",
    "            print('found dep gene usage count for %s' %dep_param)        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### playground:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################playground#############\n",
    "param_list=['vGeneName','vFamilyName','dGeneName','jGeneName']\n",
    "sample_name='BD2'\n",
    "data_folder='TCR_real_data'\n",
    "\n",
    "sample_df=pd.read_table(\"/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis/%s.tsv\" %(data_folder,sample_name))\n",
    "sample_df=sample_df.rename(columns={'count (templates/reads)':'count (templates)'})\n",
    "sample_df['prod_stat']=np.where(sample_df['sequenceStatus'] == 'In',1,0)\n",
    "    \n",
    "interesting_columns=['vGeneName','vFamilyName','dFamilyName','jGeneName','jFamilyName','prod_stat']       \n",
    "\n",
    "sample_df=sample_df[interesting_columns]\n",
    "    \n",
    "for column in sample_df.columns.values:\n",
    "    if sample_df[column].dtype!='int64':\n",
    "        sample_df=sample_df[sample_df[column].str.contains('unresolved')==False]\n",
    "        sample_df[column]=sample_df[column].str.replace('TCRB','')\n",
    "sample_df['V-J family combination']=sample_df['vFamilyName']+'_'+sample_df['jFamilyName']\n",
    "sample_df['D-J gene combination']=sample_df['dFamilyName']+'_'+sample_df['jGeneName']\n",
    "sample_df\n",
    "\n",
    "# sample_df=sample_df[['jGeneName','dGeneName']]\n",
    "# sample_df=sample_df[samples_df['jGeneName'] != 'unresolved']\n",
    "# sample_df=sample_df[samples_df['dGeneName'] != 'unresolved']\n",
    "\n",
    "# VJusage=pd.crosstab(index=sample_df['jGeneName'], columns=sample_df['dGeneName'], normalize='index')\n",
    "\n",
    "# VJusage\n",
    "    \n",
    "\n",
    "        \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder=r'TCR_demo_data'\n",
    "sample_name='HIP00110'\n",
    "gen_descriptive_stats(sample_name)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### calculate n templates in each sample and each df type:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "nTemplates=pd.DataFrame() #generate empty dataframe\n",
    "\n",
    "\n",
    "\n",
    "for n, sample_name in enumerate(filenames):\n",
    "    print n,sample_name\n",
    "    sample_df=pd.read_table(\"/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/SamplesForAnalysis/%s.tsv\" %sample_name)\n",
    "    sample_df=sample_df.rename(columns={'count (templates/reads)':'count (templates)'})\n",
    "\n",
    "    sample_df['prod_stat']=np.where(sample_df['sequenceStatus'] == 'In',1,0)\n",
    "    interesting_columns=['nucleotide','aminoAcid','count (templates)','frequencyCount (%)','cdr3Length',\n",
    "                         'vDeletion', 'n1Insertion', 'd5Deletion', 'd3Deletion',\n",
    "                         'n2Insertion','jDeletion','prod_stat']    \n",
    "\n",
    "    sample_df=sample_df[interesting_columns]\n",
    "    prod_df=sample_df[sample_df['prod_stat']==1]\n",
    "    nonprod_df=sample_df[sample_df['prod_stat']==0]\n",
    "    \n",
    "    n_templates_total_nt=sample_df['count (templates)'].sum()\n",
    "    n_templates_prod_nt=prod_df['count (templates)'].sum()\n",
    "    n_templates_nonprod_nt=nonprod_df['count (templates)'].sum()\n",
    "    n_templates_total_aa=sample_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "    n_templates_prod_aa=prod_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "    n_templates_nonprod_aa=nonprod_df.groupby('aminoAcid').sum()['count (templates)'].sum()\n",
    "        \n",
    "    \n",
    "    nTemplates.loc[n,'Sample']=sample_name\n",
    "    \n",
    "    nTemplates.loc[n,'n_templates_total_nt']=n_templates_total_nt\n",
    "    nTemplates.loc[n,'n_templates_prod_nt']=n_templates_prod_nt\n",
    "    nTemplates.loc[n,'n_templates_nonprod_nt']=n_templates_nonprod_nt\n",
    "    \n",
    "    nTemplates.loc[n,'n_temp_total_aa']=n_templates_total_aa\n",
    "    nTemplates.loc[n,'n_templates_prod_aa']=n_templates_prod_aa\n",
    "    nTemplates.loc[n,'n_templates_nonprod_aa']=n_templates_nonprod_aa\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save n templates dataframe\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/nTemplatesSummary_%s_%s' %(len(filenames), cdate)\n",
    "nTemplates.to_pickle(file1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTemplates.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## define highest function to call all feature calculating functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gen_descriptive_stats(sample_name):\n",
    "    # (1) read sample data, add indications for productive, get only interesting\n",
    "    # columns and generate dfs for total, only productive, only non productive\n",
    "\n",
    "    sample_df=pd.read_table(\"/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis/%s.tsv\" %(data_folder,sample_name))\n",
    "    sample_df=sample_df.rename(columns={'count (templates/reads)':'count (templates)','count (reads)':'count (templates)'})\n",
    "\n",
    "    sample_df['prod_stat']=np.where(sample_df['sequenceStatus'] == 'In',1,0)\n",
    "    interesting_columns=['nucleotide','aminoAcid','count (templates)','frequencyCount (%)','cdr3Length',\n",
    "                         'vDeletion', 'n1Insertion', 'd5Deletion', 'd3Deletion',\n",
    "                         'n2Insertion','jDeletion','prod_stat']    \n",
    "\n",
    "    sample_df=sample_df[interesting_columns]\n",
    "    prod_df=sample_df[sample_df['prod_stat']==1]\n",
    "    nonprod_df=sample_df[sample_df['prod_stat']==0]\n",
    "    \n",
    "    df_dict=[('Total',sample_df),\n",
    "     ('Prod',prod_df),\n",
    "     ('nonProd',nonprod_df)]\n",
    " \n",
    " # (2) call selected functions to calculate statistics for each df\n",
    "    for df in df_dict:\n",
    "        print df[0]\n",
    "        gen_LengthFeaturesAndMore(df)\n",
    "        gen_generalFeatures(df)\n",
    "        gen_normSeqNums(df)\n",
    "        gen_clonalityFeatures(df)\n",
    "        gen_diversityFeatures(df)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# geneUsage count has its own function as the column needed are different\n",
    "\n",
    "def gen_geneUsageCount(sample_name):\n",
    "    # (1) read sample data, add indications for productive, get only interesting\n",
    "    # columns and generate dfs for total, only productive, only non productive\n",
    "\n",
    "    sample_df=pd.read_table(\"/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis/%s.tsv\" %(data_folder, sample_name))\n",
    "    sample_df=sample_df.rename(columns={'count (templates/reads)':'count (templates)','count (reads)':'count (templates)'})\n",
    "    sample_df['prod_stat']=np.where(sample_df['sequenceStatus'] == 'In',1,0)\n",
    "    \n",
    "    interesting_columns=['vGeneName','vFamilyName','dFamilyName','jGeneName','jFamilyName','prod_stat']       \n",
    "\n",
    "    sample_df=sample_df[interesting_columns]\n",
    "    for column in sample_df.columns.values: #remove 'unresolved' counts and calculate frequencies without it. remove\n",
    "                                            # 'TCRB' indication\n",
    "        if sample_df[column].dtype!='int64':\n",
    "            sample_df=sample_df[sample_df[column].str.contains('unresolved')==False]\n",
    "            sample_df[column]=sample_df[column].str.replace('TCRB','')\n",
    "    \n",
    "    prod_df=sample_df[sample_df['prod_stat']==1]\n",
    "    nonprod_df=sample_df[sample_df['prod_stat']==0]\n",
    "    \n",
    "    df_dict=[('Total',sample_df),\n",
    "     ('Prod',prod_df),\n",
    "     ('nonProd',nonprod_df)]\n",
    " \n",
    " # (2) call selected functions to calculate statistics for each df\n",
    "    for df in df_dict:\n",
    "        count_geneUsage(df)\n",
    "        count_dependent_geneUsage(df)\n",
    "    \n",
    "    \n",
    "    \n",
    "      \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## get sample names and run feature generation functions on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder='TCR_real_data'\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis' %data_folder\n",
    "filenames = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames=[f.strip('.tsv') for f in filenames]\n",
    "print len(filenames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,sample_name in enumerate(filenames):    \n",
    "        print  n,sample_name\n",
    "        gen_descriptive_stats(sample_name)\n",
    "#         gen_geneUsageCount(sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#calculating for 4 additional samples (duplicates that were reanalyzed as singles)\n",
    "singles=['BD107_1rep','BD111_1rep','BD113_1rep','BD128_1rep']\n",
    "data_folder='TCR_real_data'\n",
    "for n,sample_name in enumerate(singles):    \n",
    "        print  n,sample_name\n",
    "        gen_descriptive_stats(sample_name)\n",
    "        gen_geneUsageCount(sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Samuels samples: get sample names and run feature generation functions on them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder='TCR_real_data/SamuelsSamples'\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis' %data_folder\n",
    "filenames_samuels = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames_samuels=[f.strip('.tsv') for f in filenames_samuels]\n",
    "print len(filenames_samuels)\n",
    "print dfs_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,sample_name in enumerate(filenames_samuels):\n",
    "#     if n<3:    \n",
    "        print  n,sample_name\n",
    "        gen_descriptive_stats(sample_name)\n",
    "        gen_geneUsageCount(sample_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run all analysis on Adaptive samples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder='TCR_demo_data'\n",
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/%s/SamplesForAnalysis' %data_folder\n",
    "filenames_adaptive = [f for f in listdir(dfs_folder) if isfile(join(dfs_folder, f))]\n",
    "filenames_adaptive=[f.strip('.tsv') for f in filenames_adaptive]\n",
    "print len(filenames_adaptive)\n",
    "print dfs_folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for n,sample_name in enumerate(filenames_adaptive):\n",
    "    if n>607:    \n",
    "        print  n,sample_name\n",
    "        gen_descriptive_stats(sample_name)\n",
    "        gen_geneUsageCount(sample_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#run 4 samples that were problematic before, and I re-saved them:\n",
    "problematic=['HIP01129','HIP14211','HIP01947','HIP14092']\n",
    "\n",
    "for n,sample_name in enumerate(problematic):    \n",
    "        print  n,sample_name\n",
    "        gen_descriptive_stats(sample_name)\n",
    "        gen_geneUsageCount(sample_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### find which adaptive samples needs to be downloaded:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find the full list of adaptive samples according to the QC file I downloaded:\n",
    "\n",
    "file1='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/qcReport.2017-11-26_03-34-38.tsv'\n",
    "\n",
    "AdaptiveSamples=pd.read_table(file1)\n",
    "AdaptiveSamples.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "AdaptiveSamplesList=list(AdaptiveSamples['Sample Name'])\n",
    "print len(AdaptiveSamplesList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the list of samples for which I already have the data downloaded:\n",
    "filenames_adaptive[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find which samples needs to be downloaded and save to excel:\n",
    "missing=[x for x in AdaptiveSamplesList if x not in filenames_adaptive]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(missing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missingDF=pd.DataFrame(missing)\n",
    "file2='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/missingSamples.xlsx'\n",
    "missingDF.to_excel(file2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## concatenate dfs of the same type:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/Prod/GeneralFeatures'\n",
    "Prod_generalFeatures=concat_summarizing_dfs(dfs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prod_generalFeatures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/nonProd/LengthFeaturesAndMore'\n",
    "nonProd_lengthFeatures=concat_summarizing_dfs(dfs_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonProd_lengthFeatures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/Prod/normSeqNums'\n",
    "prod_normSeqNums=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "prod_normSeqNums.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/nonProd/normSeqNums'\n",
    "nonProd_normSeqNums=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonProd_normSeqNums.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/Prod/ClonalityFeatures'\n",
    "Prod_ClonalityFeatures=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prod_ClonalityFeatures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/nonProd/ClonalityFeatures'\n",
    "nonProd_ClonalityFeatures=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonProd_ClonalityFeatures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/Prod/DiversityFeatures'\n",
    "Prod_DiversityFeatures=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prod_DiversityFeatures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/nonProd/DiversityFeatures'\n",
    "nonProd_DiversityFeatures=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonProd_DiversityFeatures.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/Prod/jGeneName'\n",
    "Prod_jGeneName=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Prod_jGeneName.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/nonProd/jGeneName'\n",
    "nonProd_jGeneName=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nonProd_jGeneName.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/SamuelsSamples/descriptiveStatsSamplesForAnalysis/nonProd/dGeneName'\n",
    "Samuels_nonProd_dGeneName=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Samuels_nonProd_dGeneName"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/SamuelsSamples/descriptiveStatsSamplesForAnalysis/nonProd/V-J family combination'\n",
    "Samuels_nonProd_VJfamilycombination=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Samuels_nonProd_VJfamilycombination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_folder='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_real_data/descriptiveStatsSamplesForAnalysis/nonProd/dFamilyName'\n",
    "df=concat_summarizing_dfs(dfs_folder)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "# df['unresolved'].count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "V-J family combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Samuels_nonProd_VJfamilycombination.sum(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# calculate TCR-microbiome diversity interactions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_res_df(result_df, function_list, title, yscale, hspace):\n",
    "    print 'plotting results...'\n",
    "    result_df.dropna(inplace=True)\n",
    "    function_names=[f.__name__ for f in function_list]\n",
    "    fig=plt.figure(figsize=(6,11))\n",
    "    plt.suptitle('%s population features' %title, fontsize=16)\n",
    "    n_plots=len(function_list)\n",
    "    print n_plots\n",
    "    for p in range(n_plots):\n",
    "        print p\n",
    "        function_name=function_names[p]\n",
    "        prod_col=2*p\n",
    "        non_prod_col=2*p+1\n",
    "        ax= plt.subplot2grid((n_plots,1), (p,0)) \n",
    "        plot=plot_population_view(ax, p,  result_df, function_name, yscale, prod_col, non_prod_col)\n",
    "    plt.subplots_adjust(left=0.14,bottom=0.08, right=0.88, top=0.92, wspace=0.24,hspace=hspace)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_1_res_df(result_df, function_list, title,yscale):\n",
    "    print 'plotting results...'\n",
    "    result_df.dropna(inplace=True)\n",
    "    function_names=[f.__name__ for f in function_list]\n",
    "    fig=plt.figure(figsize=(7,8))\n",
    "    plt.suptitle('%s population features' %title, fontsize=16)\n",
    "    n_plots=len(function_list)\n",
    "    print n_plots\n",
    "    for p in range(n_plots):\n",
    "        print p\n",
    "        function_name=function_names[p]\n",
    "        df_col=p\n",
    "        ax= plt.subplot2grid((n_plots,1), (p,0)) \n",
    "        plot=plot_population_view(ax, p,  result_df, function_name, yscale, df_col, non_prod_col=None)\n",
    "    plt.subplots_adjust(left=0.09,bottom=0.11, right=0.95, top=0.89, wspace=0.24,hspace=0.50)\n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_population_view(ax,p, result_df,function_name, yscale, prod_col,non_prod_col):\n",
    "      \n",
    "    prod_l=list(result_df[result_df.columns[prod_col]])\n",
    "    if non_prod_col!=None:\n",
    "        non_prod_l=list(result_df[result_df.columns[non_prod_col]])\n",
    "        plot=ax.hist((prod_l,non_prod_l), bins=50, color=('blue', 'red'), label=('Productive','Non-Productive'), alpha=0.7)\n",
    "        ks_p, t_p=stat_tests(prod_l,non_prod_l)\n",
    "        ax.annotate('KS_p_value=%s\\nt-test_p_value=%s' %(ks_p, t_p), xy=(0.95, 0.95), xycoords='axes fraction', fontsize=8,\n",
    "        horizontalalignment='right', verticalalignment='top', fontweight='bold')\n",
    "        \n",
    "    else:\n",
    "        plot=ax.hist(prod_l, color='blue', bins=50)\n",
    "    ax.set_title(str(function_name), fontsize=8)\n",
    "    ax.set_ylabel('Frequency', fontsize=7)\n",
    "    ax.tick_params(labelsize=6)\n",
    "    ax.set_yscale(yscale)\n",
    "    if p==0:\n",
    "        ax.legend(loc='upper center', fontsize=6)\n",
    "    return plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stat_tests(prod_l,non_prod_l):\n",
    "    ks_s,ks_p=stats.ks_2samp(prod_l,non_prod_l)\n",
    "    t_s,t_p=stats.ttest_ind(prod_l,non_prod_l)\n",
    "    if ks_p<=10**-4:\n",
    "        ks_p='<10^-4'\n",
    "    else:\n",
    "        ks_p=str(round(ks_p,4))\n",
    "    if t_p<=10**-4:\n",
    "        t_p='<10^-4'\n",
    "    else:\n",
    "        t_p=str(round(t_p,4))\n",
    "    return ks_p, t_p\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_df(general_res_df, general_function_list, 'General')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "perProd_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "plot_1_res_df(perProd_res_df, percProd_func_list, 'Percent Productive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_df(clonality_res_df, clonality_func_list, 'Clonality')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_df(clonality_res_df, clonality_func_list, 'Clonality', 'log', 0.68)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "general_res_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr_df=general_res_df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print corr_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_df(diversity_res_df, diversity_func_list, 'Diversity-linear', 'linear', 0.36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_df(diversity_res_df, diversity_func_list, 'Diversity-log', 'log', 0.36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_df(length_res_df, length_func_list, 'length-linear', 'linear', 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_df(length_res_df, length_func_list, 'length-log', 'log', 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "print \"Current date \"  + time.strftime(\"%x\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdate=str(time.strftime(\"%x\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print cdate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_res_fig_linear=plot_res_df(length_res_df, length_func_list, 'length-linear', 'linear', 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_res_fig_log=plot_res_df(length_res_df, length_func_list, 'length-log', 'log', 0.66)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_res_fig_linear=plot_res_df(diversity_res_df, diversity_func_list, 'Diversity-linear', 'linear', 0.36)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diversity_res_fig_log=plot_res_df(diversity_res_df, diversity_func_list, 'Diversity-log', 'log', 0.36)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### plotting public analysis results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "public_res_df_combined is loaded from pickle, the public functions and function list is copied from the 'public' notebook. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/public_analysis/calculate_public_stats/public_res_df_combined', 'rb') as f:\n",
    "    public_res_df_combined=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_res_df_combined.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## public population functions:\n",
    "\n",
    "\n",
    "def perc_public(df):\n",
    "    n_public=len(df[df['n_samples']>1])\n",
    "    perc_public=(float(n_public)/len(df['n_samples']))*100\n",
    "    return perc_public\n",
    "\n",
    "def public10perc(df):\n",
    "    n_public10=len(df[df['n_samples']>57])\n",
    "    perc_public10=(float(n_public10)/len(df['n_samples']))*100\n",
    "    return perc_public10\n",
    "\n",
    "def public50perc(df):\n",
    "    n_public50=len(df[df['n_samples']>286])\n",
    "    perc_public50=(float(n_public50)/len(df['n_samples']))*100\n",
    "    return perc_public50\n",
    "\n",
    "def public95perc(df):\n",
    "    n_public95=len(df[df['n_samples']>544])\n",
    "    perc_public95=(float(n_public95)/len(df['n_samples']))*100\n",
    "    return perc_public95\n",
    "\n",
    "def meanSharedSamples(df):\n",
    "    mean_shared=df['n_samples'].mean()\n",
    "    return mean_shared\n",
    "\n",
    "def cdr3PriToPub(df):\n",
    "    mean_cdr3_pri=df[df['n_samples']==1]['cdr3Length'].mean()\n",
    "    mean_cdr3_pub=df[df['n_samples']>1]['cdr3Length'].mean()\n",
    "    cdr3PriToPub=float(mean_cdr3_pri)/mean_cdr3_pub\n",
    "    return cdr3PriToPub\n",
    "\n",
    "def cdr3PriToPub95(df):\n",
    "    mean_cdr3_pri=df[df['n_samples']==1]['cdr3Length'].mean()\n",
    "    mean_cdr3_pub95=df[df['n_samples']>544]['cdr3Length'].mean()\n",
    "    cdr3PriToPub95=float(mean_cdr3_pri)/mean_cdr3_pub95\n",
    "    return cdr3PriToPub95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_res_df_combined_toPlot=public_res_df_combined.drop(['public50perc_df_0','public50perc_df_1','public95perc_df_0','public95perc_df_1','cdr3PriToPub95_df_0','cdr3PriToPub95_df_1'], axis=1)\n",
    "## remove features which have data only for productive sequences (those features are plotted seperately)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_keep=['public50perc_df_0','public95perc_df_0', 'cdr3PriToPub95_df_0']\n",
    "public_res_df_combined_toPlot1=public_res_df_combined[columns_to_keep]\n",
    "## generate df for features that have data only in productive sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_res_df_combined_toPlot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_func_list_toPlot=[perc_public, public10perc, meanSharedSamples, cdr3PriToPub]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_func_list_toPlot1=[public50perc, public95perc, cdr3PriToPub95]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_plot=plot_res_df(public_res_df_combined_toPlot, public_func_list_toPlot, 'Public-linear', 'linear', 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_plot1=plot_1_res_df(public_res_df_combined_toPlot1, public_func_list_toPlot1, 'Public-linear', 'linear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_res_df(public_res_df_combined_toPlot, public_func_list_toPlot, 'Public-log', 'log', 0.20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### Generating A figures PDF:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdate=str(time.strftime(\"%d%m%Y\"))\n",
    "create_pdf=True\n",
    "figlist=[perc_prod_fig, general_res_fig_linear, general_res_fig_log, clonality_res_fig_linear, clonality_res_fig_log, diversity_res_fig_linear,\n",
    "        diversity_res_fig_log,length_res_fig_linear, length_res_fig_log, public_plot, public_plot1]\n",
    "\n",
    "if create_pdf:\n",
    "    with PdfPages('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Images/population_View_%s_samples_%s.pdf' %(n_samples, cdate)) as pdf:\n",
    "        for fig in figlist:\n",
    "            pdf.savefig(fig)\n",
    "    pdf.close\n",
    "else:\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Images/Public-linear population features-1', dpi=300)\n",
    "\n",
    "'''\n",
    "    name, dpi=None, facecolor='w', edgecolor='w',\n",
    "        orientation='portrait', papertype=None, format=None,\n",
    "        transparent=False, bbox_inches=None, pad_inches=0.1,\n",
    "        frameon=None)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.savefig('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Images/Public-linear population features', dpi=600)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### combining all results dataframes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "public_result_with_tags_df=pickle.load( open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/public_result_with_tags_df', \"rb\"))\n",
    "public_result_with_tags_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "length_res_df_573_samples=pickle.load( open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/length_res_df_573_samples', \"rb\"))\n",
    "clonality_res_df_573_samples=pickle.load( open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/clonality_res_df_573_samples', \"rb\"))\n",
    "perProd_res_df_573_samples=pickle.load( open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/perProd_res_df_573_samples', \"rb\"))\n",
    "general_res_df_573_samples=pickle.load( open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/general_res_df_573_samples', \"rb\"))\n",
    "diversity_res_df_573_samples=pickle.load( open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/diversity_res_df_573_samples', \"rb\"))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_res_with_tags_df=pd.merge(pd.merge(pd.merge(pd.merge(pd.merge(general_res_df_573_samples,perProd_res_df_573_samples,how='outer', \n",
    "                                                     right_index=True,left_index=True), clonality_res_df_573_samples,how='outer',\n",
    "                                                      right_index=True,left_index=True),length_res_df_573_samples, how='outer',\n",
    "                                                      right_index=True,left_index=True),diversity_res_df_573_samples, how='outer',\n",
    "                                                      right_index=True,left_index=True),public_result_with_tags_df,how='outer',\n",
    "                                                      right_index=True,left_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_res_with_tags_describe=combined_res_with_tags_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "excel_writer='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/combined_res_with_tags_describe.xlsx'\n",
    "combined_res_with_tags_describe.to_excel(excel_writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "cdate=str(time.strftime(\"%d%m%Y\"))\n",
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/combined_res_with_tags_df_%s' %cdate, 'wb') as f:\n",
    "        pickle.dump(combined_res_with_tags_df,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/combined_res_with_tags_df_08032017', 'rb') as f:\n",
    "        combined_res_with_tags_df=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_res_with_tags_df.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating correlations over the result df:\n",
    "the significance is tested by both p-value and by permutation analysis:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### define parameters: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=combined_res_with_tags_df #define the results df\n",
    "corr_col='perc_public_df_0' #define the feature to calculate correlations with\n",
    "n_per=10 #define the number of permutations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### calculate real correlations and p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sig_corr(df, corr_col, n_per):\n",
    "    from scipy.stats import pearsonr\n",
    "\n",
    "    ## stage 1: calculate real correlations and generate dataframe\n",
    "    print 'calculating real correlations'\n",
    "    corr_list=[]\n",
    "    n_tests=len(df.columns.values)\n",
    "    for column in list(df.columns.values):\n",
    "        if df[column].dtype == np.float64 or df[column].dtype == np.int64 :\n",
    "            n1=np.isnan(df[column])\n",
    "            n2=np.isnan(df[corr_col])\n",
    "            n=n1|n2\n",
    "            newx=list(df[column][~n])\n",
    "            newy=list(df[corr_col][~n])\n",
    "            r,p = pearsonr(newx,newy)\n",
    "        else:\n",
    "            r=np.nan\n",
    "            p=np.nan\n",
    "        corr_list.append({'column':column,'real_r':r, 'real_p':p})\n",
    "    res_corr_df=pd.DataFrame(corr_list)\n",
    "    res_corr_df.sort(columns='real_p', inplace=1)\n",
    "\n",
    "\n",
    "    ## stage 2: permutate result df and calculate correlations over permutated data:\n",
    "    for i in range(n_per):\n",
    "        print i\n",
    "        print 'start shuffling df'\n",
    "        shuffle=df.apply(np.random.permutation)\n",
    "        shuf_corr_list=[]\n",
    "        #column_list=[]\n",
    "        for column in list(shuffle.columns.values):\n",
    "            #print ('start calculating r for column %s' %column)\n",
    "            #column_list.append(column)\n",
    "            if shuffle[column].dtype == np.float64 or shuffle[column].dtype == np.int64 :\n",
    "                n1=np.isnan(shuffle[column])\n",
    "                n2=np.isnan(shuffle[corr_col])\n",
    "                n=n1|n2\n",
    "                newx=list(shuffle[column][~n])\n",
    "                newy=list(shuffle[corr_col][~n])\n",
    "                r,p = pearsonr(newx,newy)\n",
    "                shuf_corr_list.append(r)\n",
    "            else:\n",
    "                shuf_corr_list.append(np.nan)\n",
    "        #shuffle_r_df.loc[:,('column_shuf_%s'%i)] = column_list\n",
    "        res_corr_df.loc[:,('r_shuf_%s'%i)] = shuf_corr_list\n",
    "    \n",
    "    ## stage 3: calculate confidence interval for shuffled r's:\n",
    "    #print shuffle_r_df.columns.values\n",
    "    col_for_percentile=[col for col in res_corr_df.columns.values if col.startswith('r_shuf_')]\n",
    "    #shuffle_r_df.loc[:,'r_mean']=np.mean(shuffle_r_df[col_for_percentile])\n",
    "    #res_corr_df['avg'] = res_corr_df[col_for_percentile].mean(axis=1)\n",
    "    res_corr_df['r_perc_2_5'] = res_corr_df[col_for_percentile].quantile(q=0.025,axis=1)\n",
    "    res_corr_df['r_perc_97_5'] = res_corr_df[col_for_percentile].quantile(q=0.975,axis=1)\n",
    "    \n",
    "    ## stage 4: check significance of the correlations:\n",
    "    res_correct_p=0.05/n_tests\n",
    "    res_corr_df['real_p_sig']=np.where(res_corr_df['real_p']<0.05,1,0)\n",
    "    res_corr_df['real_p_sig_corrected']=np.where(res_corr_df['real_p']<res_correct_p,1,0)\n",
    "    res_corr_df['r_outof_CI']=np.where((res_corr_df['real_r']<res_corr_df['r_perc_2_5']) | (res_corr_df['real_r']>res_corr_df['r_perc_97_5']) ,1,0)\n",
    "    col_to_keep=['column','real_p','real_r','r_perc_2_5','r_perc_97_5','real_p_sig','real_p_sig_corrected','r_outof_CI']\n",
    "    res_corr_df=res_corr_df[col_to_keep]\n",
    "    res_corr_df.set_index('column',inplace=1)\n",
    "    only_sig_corr_df=res_corr_df[(res_corr_df['real_p_sig']==1) & (res_corr_df['r_outof_CI']==1)]\n",
    "    \n",
    "    return res_corr_df,only_sig_corr_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " df10 = pd.DataFrame(np.random.randint(0,100,(100, 100)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10['r_perc_2_5'] = df10.quantile(q=0.025,axis=1)\n",
    "df10['r_perc_97_5'] = df10.quantile(q=0.975,axis=1)\n",
    "df10['r_perc_3'] = df10.quantile(q=0.03,axis=1)\n",
    "df10['r_perc_97'] = df10.quantile(q=0.97,axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df10[['r_perc_2_5','r_perc_97_5','r_perc_3','r_perc_97']].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percPublicProd_corr_df,percPublicProd_SigCorr_df=calc_sig_corr(combined_res_with_tags_df, 'perc_public_df_0', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/percPublicProd_corr_df', 'wb') as f:\n",
    "        pickle.dump(percPublicProd_corr_df,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/percPublicProd_corr_df', 'rb') as f:\n",
    "        percPublicProd_corr_df=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "percPublicProd_corr_df[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(percPublicProd_SigCorr_df)\n",
    "print len(percPublicProd_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanSharedProd_corr_df,meanSharedProd_SigCorr_df=calc_sig_corr(combined_res_with_tags_df, 'meanSharedSamples_df_0', 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanSharedProd_SigCorr_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(meanSharedProd_SigCorr_df)\n",
    "print len(meanSharedProd_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/meanSharedProd_corr_df', 'wb') as f:\n",
    "        pickle.dump(meanSharedProd_corr_df,f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/meanSharedProd_corr_df', 'rb') as f:\n",
    "        meanSharedProd_corr_df=pickle.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanSharedProd_corr_df[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/public_analysis/meanSharedProd_corr_df.xlsx'\n",
    "meanSharedProd_corr_df.to_excel(writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "writer='/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/public_analysis/percPublicProd_corr_df.xlsx'\n",
    "percPublicProd_corr_df.to_excel(writer, sheet_name='Sheet1', na_rep='', float_format=None, columns=None, header=True, index=True, index_label=None, startrow=0, startcol=0, engine=None, merge_cells=True, encoding=None, inf_rep='inf', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_res_with_tags_df_corr.sort(columns='meanSharedSamples_df_0',ascending=False)['meanSharedSamples_df_0'][:50]\n",
    "                                                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_res_with_tags_df_corr.sort(columns='perc_public_df_0',ascending=False)['perc_public_df_0'][0:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_res_with_tags_df_corr.sort(columns='perc_public_df_0',ascending=False)['perc_public_df_0'][50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_correlation_scatter(x, y, figsize = (3, 3), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = None, ms=4, logd = False,\\\n",
    "                             xlab = None, ylab = None, filename = None, title = None,\n",
    "                             color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False, **figkwargs):\n",
    "    from scipy.stats import pearsonr\n",
    "    fig = plt.figure(figsize = figsize, dpi = dpi)\n",
    "    axB = fig.add_subplot(111)\n",
    "    if contour:\n",
    "        print \"Contour plot are experimental here\"\n",
    "        axB.hist2d(x,y,bins = 40,norm=LogNorm())\n",
    "    else:\n",
    "        axB.plot(x, y, 'o', color = color, ms=ms, **figkwargs)\n",
    "    if logd:\n",
    "        axB.set_xscale('log',basex=2)\n",
    "        axB.set_yscale('log',basey=2)\n",
    "    if xticks is not None:\n",
    "        axB.set_xticks(xticks)\n",
    "        axB.set_xticklabels(xticks)\n",
    "    if xticklabels is not None:\n",
    "        axB.set_xticklabels(xticklabels)\n",
    "    if yticks is not None:\n",
    "        axB.set_yticks(yticks)\n",
    "        axB.set_yticklabels(yticks)\n",
    "    if xlim is not None:\n",
    "        axB.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        axB.set_ylim(ylim)\n",
    "    if r is not None: \n",
    "        if r == True:\n",
    "            n=np.isnan(x)\n",
    "            newx=list(x[~n])\n",
    "            newy=list(y[~n])\n",
    "            r,p = pearsonr(newx,newy)\n",
    "        axB.text(0.01,0.99,\"r=%.4f p=%.4f\" %(r,p), transform=axB.transAxes, verticalalignment = 'top', ha = 'left',fontsize=14,color='red')\n",
    "    if xlab is not None:\n",
    "        axB.set_xlabel(xlab)\n",
    "    if ylab is not None:\n",
    "        axB.set_ylabel(ylab)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=16)\n",
    "    if grid:\n",
    "        axB.grid()\n",
    "    if filename is not None:\n",
    "        fig.savefig(filename, bbox_inches='tight', dpi = dpi)\n",
    "    return fig, axB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_multiple_correlation_scatter(x, y, ynames=None, figsize = (4, 4), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = None, ms=4, logd = False,\\\n",
    "                             xlab = None, ylab = None, filename = None, title = None,\n",
    "                             color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False, **figkwargs):\n",
    "    from scipy.stats import pearsonr\n",
    "    fig = plt.figure(figsize = figsize, dpi = dpi)\n",
    "    axB = fig.add_subplot(111)\n",
    "    if contour:\n",
    "        print \"Contour plot are experimental here\"\n",
    "        axB.hist2d(x,y,bins = 40,norm=LogNorm())\n",
    "    else:\n",
    "        for i in range(len(y)):\n",
    "            axB.plot(x, y[i], 'o', color = color[i], ms=ms[i], label=ynames[i], **figkwargs)\n",
    "    axB.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.)\n",
    "    #axB.legend(loc='best',fontsize=10)\n",
    "    if logd:\n",
    "        axB.set_xscale('log',basex=2)\n",
    "        axB.set_yscale('log',basey=2)\n",
    "    if xticks is not None:\n",
    "        axB.set_xticks(xticks)\n",
    "        axB.set_xticklabels(xticks)\n",
    "    if xticklabels is not None:\n",
    "        axB.set_xticklabels(xticklabels)\n",
    "    if yticks is not None:\n",
    "        axB.set_yticks(yticks)\n",
    "        axB.set_yticklabels(yticks)\n",
    "    if xlim is not None:\n",
    "        axB.set_xlim(xlim)\n",
    "    if ylim is not None:\n",
    "        axB.set_ylim(ylim)\n",
    "    if r is not None: \n",
    "        if r == True:\n",
    "            n=np.isnan(x)\n",
    "            newx=list(x[~n])\n",
    "            newy_l=[]\n",
    "            r_l=[]\n",
    "            p_l=[]\n",
    "            posR=0.99\n",
    "            for i in range(len(y)):\n",
    "                newy=list(y[i][~n])\n",
    "                r,p = pearsonr(newx,newy)\n",
    "                newy_l.append(newy)\n",
    "                r_l.append(r)\n",
    "                p_l.append(p)\n",
    "                axB.text(0.01,posR,\"r=%.4f p=%.4f\" %(r,p), transform=axB.transAxes, verticalalignment = 'top', ha = 'left',fontsize=10,color=color[i])\n",
    "                posR=posR-0.03\n",
    "    if xlab is not None:\n",
    "        axB.set_xlabel(xlab)\n",
    "    if ylab is not None:\n",
    "        axB.set_ylabel(ylab)\n",
    "    if title is not None:\n",
    "        plt.title(title, fontsize=16)\n",
    "    if grid:\n",
    "        axB.grid()\n",
    "    if filename is not None:\n",
    "        fig.savefig(filename, bbox_inches='tight', dpi = dpi)\n",
    "    return fig, axB\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_res_with_tags_noOutliers=combined_res_with_tags_df[combined_res_with_tags_df['perc_public_df_0']<80]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_nShared_correl_fig=draw_correlation_scatter(combined_res_with_tags_df['Age'], combined_res_with_tags_df['perc_public_df_0'], figsize = (6, 6), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=6, logd = False,\\\n",
    "                             xlab = 'Age', ylab = 'Percent Public-Productive sequences', filename = 'Age-Percent Public correlation', title = 'Age-Percent Public correlation',\n",
    "                             color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_nShared_correl_no_outliers_fig=draw_correlation_scatter(combined_res_with_tags_noOutliers['Age'], combined_res_with_tags_noOutliers['perc_public_df_0'], figsize = (6, 6), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=6, logd = False,\\\n",
    "                             xlab = 'Age', ylab = 'Percent Public-Productive sequences', filename = 'Age-Percent Public correlation-noOutliers', title = 'Age-Percent Public correlation (no outliers)',\n",
    "                             color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_meanShared_correl_fig=draw_correlation_scatter(combined_res_with_tags_df['Age'], combined_res_with_tags_df['meanSharedSamples_df_0'], figsize = (6, 6), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=6, logd = False,\\\n",
    "                             xlab = 'Age', ylab = 'Mean shared samples-Productive sequences', filename = 'Age-Mean shared samples correlation', title = 'Age-Mean shared samples correlation',\n",
    "                             color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Age_meanShared_correl_no_outliers_fig=draw_correlation_scatter(combined_res_with_tags_noOutliers['Age'], combined_res_with_tags_noOutliers['meanSharedSamples_df_0'], figsize = (6, 6), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=6, logd = False,\\\n",
    "                             xlab = 'Age', ylab = 'Mean shared samples-Productive sequences', filename = 'Age-Mean shared samples correlation-noOutliers', title = 'Age-Mean shared samples correlation correlation (no outliers)',\n",
    "                             color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanclonalaa_2sharing_correl_fig=draw_multiple_correlation_scatter(combined_res_with_tags_df['mean_clonal_aa_df_0'], [combined_res_with_tags_df['meanSharedSamples_df_0'], combined_res_with_tags_df['perc_public_df_0']], ynames=['meanSharedSamplesProd','perc_public_Prod'], figsize = (8, 8), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=[6,6], logd = False,\\\n",
    "                             xlab = 'mean clonality (%, productive aa sequences)', ylab = '', filename = 'mean_clonal aa-sharing correlation', title = 'mean_clonal aa-sharing correlation',\n",
    "                             color = ['black','green'], grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topclonalaa_2sharing_correl_fig=draw_multiple_correlation_scatter(combined_res_with_tags_df['top_clonal_aa_df_0'], [combined_res_with_tags_df['meanSharedSamples_df_0'], combined_res_with_tags_df['perc_public_df_0']], ynames=['meanSharedSamplesProd','perc_public_Prod'], figsize = (8, 8), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=[6,6], logd = False,\\\n",
    "                             xlab = 'highest clonality (%, productive aa sequences)', ylab = '', filename = 'top_clonal aa-sharing correlation', title = 'top_clonal aa-sharing correlation',\n",
    "                             color = ['black','green'], grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_clonal_aa_df_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanclonalnt_2sharing_correl_fig=draw_multiple_correlation_scatter(combined_res_with_tags_df['mean_clonal_nt_df_0'], [combined_res_with_tags_df['meanSharedSamples_df_0'], combined_res_with_tags_df['perc_public_df_0']], ynames=['meanSharedSamplesProd','perc_public_Prod'], figsize = (8, 8), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=[6,6], logd = False,\\\n",
    "                             xlab = 'mean clonality (%, productive nt sequences)', ylab = '', filename = 'mean_clonal_nt-sharing correlation', title = 'mean_clonal nt-sharing correlation',\n",
    "                             color = ['black','green'], grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topclonalnt_2sharing_correl_fig=draw_multiple_correlation_scatter(combined_res_with_tags_df['top_clonal_nt_df_0'], [combined_res_with_tags_df['meanSharedSamples_df_0'], combined_res_with_tags_df['perc_public_df_0']], ynames=['meanSharedSamplesProd','perc_public_Prod'], figsize = (8, 8), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=[6,6], logd = False,\\\n",
    "                             xlab = 'highest clonality (%, productive nt sequences)', ylab = '', filename = 'top_clonal_nt-sharing correlation', title = 'top_clonal nt-sharing correlation',\n",
    "                             color = ['black','green'], grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000clonsNonProd_2sharing_correl_fig=draw_multiple_correlation_scatter(combined_res_with_tags_df['top_1000clons_aa_df_1'], [combined_res_with_tags_df['meanSharedSamples_df_0'], combined_res_with_tags_df['perc_public_df_0']], ynames=['meanSharedSamplesProd','perc_public_Prod'], figsize = (8, 8), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=[6,6], logd = False,\\\n",
    "                             xlab = 'fraction of top 1000 clones (%, non-productive nt sequences)', ylab = '', filename = 'top1000clonsNonProd-sharing correlation', title = 'top 1000 clons Non Prod-sharing correlation',\n",
    "                             color = ['black','green'], grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdr3priToPub_2sharing_correl_fig=draw_multiple_correlation_scatter(combined_res_with_tags_df['cdr3PriToPub_df_0'], [combined_res_with_tags_df['meanSharedSamples_df_0'], combined_res_with_tags_df['perc_public_df_0']], ynames=['meanSharedSamplesProd','perc_public_Prod'], figsize = (8, 8), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=[6,6], logd = False,\\\n",
    "                             xlab = 'ratio', ylab = '', filename = 'cdr3PriToPub_prod-sharing correlation', title = 'cdr3PriToPub_prod-sharing correlation',\n",
    "                             color = ['black','green'], grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanCDR3_2sharing_correl_fig=draw_multiple_correlation_scatter(combined_res_with_tags_df['mean_cdr3_df_0'], [combined_res_with_tags_df['meanSharedSamples_df_0'], combined_res_with_tags_df['perc_public_df_0']], ynames=['meanSharedSamplesProd','perc_public_Prod'], figsize = (8, 8), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=[6,6], logd = False,\\\n",
    "                             xlab = 'Cdr3 length (bps)', ylab = '', filename = 'mean_cdr3_prod-sharing correlation', title = 'mean_cdr3_prod-sharing correlation',\n",
    "                             color = ['black','green'], grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normUniqueAA_2sharing_correl_fig=draw_multiple_correlation_scatter(combined_res_with_tags_df['norm_uniqe_aa_sequences_df_0'], [combined_res_with_tags_df['meanSharedSamples_df_0'], combined_res_with_tags_df['perc_public_df_0']], ynames=['meanSharedSamplesProd','perc_public_Prod'], figsize = (8, 8), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=[6,6], logd = False,\\\n",
    "                             xlab = 'number of unique aa sequences per 5,000 sequences ', ylab = '', filename = 'norm_unique_aa_prod-sharing correlation', title = 'norm_unique_aa_prod-sharing correlation',\n",
    "                             color = ['black','green'], grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "normUniqueNT_2sharing_correl_fig=draw_multiple_correlation_scatter(combined_res_with_tags_df['norm_uniqe_nt_sequences_df_0'], [combined_res_with_tags_df['meanSharedSamples_df_0'], combined_res_with_tags_df['perc_public_df_0']], ynames=['meanSharedSamplesProd','perc_public_Prod'], figsize = (8, 8), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=[6,6], logd = False,\\\n",
    "                             xlab = 'number of unique nt sequences per 100,000 sequences ', ylab = '', filename = 'norm_unique_nt_prod-sharing correlation', title = 'norm_unique_nt_prod-sharing correlation',\n",
    "                             color = ['black','green'], grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanN1Insertion_2sharing_correl_fig=draw_multiple_correlation_scatter(combined_res_with_tags_df['mean_n1Insertion_df_0'], [combined_res_with_tags_df['meanSharedSamples_df_0'], combined_res_with_tags_df['perc_public_df_0']], ynames=['meanSharedSamplesProd','perc_public_Prod'], figsize = (8, 8), xticks=None, yticks=None,\\\n",
    "                             xlim = None, ylim = None, r = True, ms=[6,6], logd = False,\\\n",
    "                             xlab = 'insertion length (bps)', ylab = '', filename = 'mean_n1Insertion_prod-sharing correlation', title = 'mean_n1Insertion_prod-sharing correlation',\n",
    "                             color = ['black','green'], grid = True, dpi = 800, xticklabels = None, \n",
    "                             contour = False)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### calculating gender differences for all features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import ttest_ind\n",
    "\n",
    "males = combined_res_with_tags_df[combined_res_with_tags_df['Gender']=='Male']\n",
    "females = combined_res_with_tags_df[combined_res_with_tags_df['Gender']=='Female']\n",
    "\n",
    "\n",
    "ttest_list=[]\n",
    "for column in list(combined_res_with_tags_df.columns.values):\n",
    "    if column == 'Gender' or column == '_merge' :\n",
    "        print column\n",
    "    else:\n",
    "        t,p=ttest_ind(males[column], females[column])\n",
    "        ttest_list.append({'column':column,'p-value':p})\n",
    "genderDiff_df=pd.DataFrame(ttest_list)\n",
    "genderDiff_df.sort(columns='p-value', inplace=1)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderDiff_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderDiff_df['sig']=np.where(genderDiff_df['p-value']<0.0005, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.sandbox.stats.multicomp import multipletests\n",
    "pvals=list(genderDiff_df['p-value'])\n",
    "reject,BHpval_df,x,y=multipletests(pvals, alpha=0.01, method='hs', returnsorted=False)\n",
    "reject,bonferroni_df,x,y=multipletests(pvals, alpha=0.01, method='bonferroni', returnsorted=False)\n",
    "genderDiff_df['BH FDR']=BHpval_df\n",
    "genderDiff_df['bonferroni FDR']=bonferroni_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "genderDiff_df[50:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/genderDiff_df', 'wb') as f:\n",
    "        pickle.dump(genderDiff_df, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gcMaleMean=np.mean(males['gc_content_df_0'])\n",
    "gcFemaleMean=np.mean(females['gc_content_df_0'])\n",
    "gcMaleSTD=np.std(males['gc_content_df_0'])\n",
    "gcFemaleSTD=np.std(females['gc_content_df_0'])\n",
    "means=[gcMaleMean,gcFemaleMean]\n",
    "stds=[gcMaleSTD,gcFemaleSTD ]\n",
    "\n",
    "\n",
    "plt.errorbar([1,2], means, stds, linestyle='None', marker='^')\n",
    "plt.xticks([1,2],['Males','Females'])\n",
    "plt.xlim(0.5,2.5)\n",
    "plt.title('Gender effect on GC% in productive sequences')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('GC%')\n",
    "\n",
    "plt.ylim(55,59)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top1000MaleMean=np.mean(males['top_1000clons_nt_df_1'])\n",
    "top1000FemaleMean=np.mean(females['top_1000clons_nt_df_1'])\n",
    "top1000MaleSTD=np.std(males['top_1000clons_nt_df_1'])\n",
    "top1000FemaleSTD=np.std(females['top_1000clons_nt_df_1'])\n",
    "means=[top1000MaleMean,top1000FemaleMean]\n",
    "stds=[top1000MaleSTD,top1000FemaleSTD ]\n",
    "\n",
    "\n",
    "plt.errorbar([1,2], means, stds, linestyle='None', marker='^')\n",
    "plt.xticks([1,2],['Males','Females'])\n",
    "plt.xlim(0.5,2.5)\n",
    "plt.title('Gender effect on the top 1000 clone fraction in non-productive sequences')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('fraction')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "uniqueAAMaleMean=np.mean(males['unique_aa_n_df_0'])\n",
    "uniqueAAFemaleMean=np.mean(females['unique_aa_n_df_0'])\n",
    "uniqueAAMaleSTD=np.std(males['unique_aa_n_df_0'])\n",
    "uniqueAAFemaleSTD=np.std(females['unique_aa_n_df_0'])\n",
    "means=[uniqueAAMaleMean,uniqueAAFemaleMean]\n",
    "stds=[uniqueAAMaleSTD,uniqueAAFemaleSTD ]\n",
    "\n",
    "\n",
    "plt.errorbar([1,2], means, stds, linestyle='None', marker='^')\n",
    "plt.xticks([1,2],['Males','Females'])\n",
    "plt.xlim(0.5,2.5)\n",
    "plt.title('Gender effect on the number of unique aa sequences')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('sequence number')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percPublicMaleMean=np.mean(males['perc_public_df_0'])\n",
    "percPublicFemaleMean=np.mean(females['perc_public_df_0'])\n",
    "percPublicMaleSTD=np.std(males['perc_public_df_0'])\n",
    "percPublicFemaleSTD=np.std(females['perc_public_df_0'])\n",
    "means=[percPublicMaleMean,percPublicFemaleMean]\n",
    "stds=[percPublicMaleSTD,percPublicFemaleSTD ]\n",
    "\n",
    "GenderOnPercPublicProdFig = plt.figure(figsize = (4,4))\n",
    "plt.errorbar([1,2], means, stds, linestyle='None', marker='^',capsize=10, capthick=2, markerfacecolor='black',elinewidth=2, markersize=9, color='red')\n",
    "plt.xticks([1,2],['Males','Females'])\n",
    "plt.xlim(0.5,2.5)\n",
    "plt.title('Gender effect on the public sequence fraction in productive sequences')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('fraction')\n",
    "GenderOnPercPublicProdFig.savefig('GenderOnPercPublicProdFig', bbox_inches='tight', dpi = 800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percPublicMaleMean=np.mean(males['meanSharedSamples_df_0'])\n",
    "percPublicFemaleMean=np.mean(females['meanSharedSamples_df_0'])\n",
    "percPublicMaleSTD=np.std(males['meanSharedSamples_df_0'])\n",
    "percPublicFemaleSTD=np.std(females['meanSharedSamples_df_0'])\n",
    "means=[percPublicMaleMean,percPublicFemaleMean]\n",
    "stds=[percPublicMaleSTD,percPublicFemaleSTD ]\n",
    "\n",
    "\n",
    "GenderOnMeanSharedSamplesProdFig = plt.figure(figsize = (4,4))\n",
    "plt.errorbar([1,2], means, stds, linestyle='None', marker='^',capsize=10, capthick=2, markerfacecolor='black',elinewidth=2, markersize=9, color='red')\n",
    "plt.xticks([1,2],['Males','Females'])\n",
    "plt.xlim(0.5,2.5)\n",
    "plt.title('Gender effect on the the mean number of shared samples per sequence')\n",
    "plt.xlabel('Gender')\n",
    "plt.ylabel('mean shared samples number')\n",
    "GenderOnMeanSharedSamplesProdFig.savefig('GenderOnMeanSharedSamplesProdFig', bbox_inches='tight', dpi = 800)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "#### calculating correlations between all parameters in the result df:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l=['a','b','c','d']\n",
    "for n1,i1 in enumerate(l):\n",
    "    for n2,i2 in enumerate(l[n1+1:]):\n",
    "        print n1,i1,n2,i2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_sig_corr_all2all(df, n_per):\n",
    "    from scipy.stats import pearsonr\n",
    "\n",
    "    ## stage 1: calculate real correlations and generate dataframe\n",
    "    print 'calculating real correlations...'\n",
    "    corr_list=[]\n",
    "    for n1, column1 in enumerate(list(df.columns.values)):  \n",
    "        for n2, column2 in enumerate(list(df.columns.values)[n1+2:]):\n",
    "            if (df[column1].dtype == np.float64 or df[column1].dtype == np.int64)&(df[column2].dtype == np.float64 or df[column2].dtype == np.int64) :\n",
    "                nc1=np.isnan(df[column1])\n",
    "                nc2=np.isnan(df[column2])\n",
    "                n=nc1|nc2\n",
    "                newx=list(df[column1][~n])\n",
    "                newy=list(df[column2][~n])\n",
    "                r,p = pearsonr(newx,newy)\n",
    "            else:\n",
    "                r=np.nan\n",
    "                p=np.nan\n",
    "            corr_list.append({'column1':column1,'column2':column2, 'real_r':r, 'real_p':p})\n",
    "    print 'finished calculating real correlations'\n",
    "    res_corr_df=pd.DataFrame(corr_list)\n",
    "    res_corr_df['abs_r'] = res_corr_df['real_r'].abs()\n",
    "    res_corr_df.sort_index(by=['real_p','abs_r','column1','column2'], ascending=[True,False,True,True],inplace=1)\n",
    "    res_corr_df.drop('abs_r', axis=1,inplace=1)\n",
    "\n",
    "\n",
    "## stage 2: permutate result df and calculate correlations over permutated data:\n",
    "    print 'calculating suffle correlations...'\n",
    "    for i in range(n_per):\n",
    "        print i\n",
    "        print 'start shuffling df'\n",
    "        shuffle=df.apply(np.random.permutation)\n",
    "        shuf_corr_list=[]\n",
    "        #column_list=[]\n",
    "        for n1, column1 in enumerate(list(shuffle.columns.values)):\n",
    "            for n2, column2 in enumerate(list(shuffle.columns.values)[n1+2:]):\n",
    "                if (shuffle[column1].dtype == np.float64 or shuffle[column1].dtype == np.int64)&(shuffle[column2].dtype == np.float64 or shuffle[column2].dtype == np.int64):\n",
    "                    nc1=np.isnan(shuffle[column1])\n",
    "                    nc2=np.isnan(shuffle[column2])\n",
    "                    n=nc1|nc2\n",
    "                    newx=list(shuffle[column1][~n])\n",
    "                    newy=list(shuffle[column2][~n])\n",
    "                    r,p = pearsonr(newx,newy)\n",
    "                    shuf_corr_list.append(r)\n",
    "                else:\n",
    "                    shuf_corr_list.append(np.nan)\n",
    "            \n",
    "        res_corr_df.loc[:,('r_shuf_%s'%i)] = shuf_corr_list\n",
    "    \n",
    "    print 'finished calculating suffle correlations'\n",
    "    \n",
    "    ## stage 3: calculate confidence interval for shuffled r's:\n",
    "    print 'calculating percentile values...'\n",
    "    #print shuffle_r_df.columns.values\n",
    "    col_for_percentile=[col for col in res_corr_df.columns.values if col.startswith('r_shuf_')]\n",
    "    #shuffle_r_df.loc[:,'r_mean']=np.mean(shuffle_r_df[col_for_percentile])\n",
    "    #res_corr_df['avg'] = res_corr_df[col_for_percentile].mean(axis=1)\n",
    "    res_corr_df['r_perc_2_5'] = res_corr_df[col_for_percentile].quantile(q=0.025,axis=1)\n",
    "    res_corr_df['r_perc_97_5'] = res_corr_df[col_for_percentile].quantile(q=0.975,axis=1)\n",
    "    print 'finished calculating percentile values'\n",
    "    \n",
    "    ## stage 4: check significance of the correlations:\n",
    "    n_tests=sigma(len(df.columns.values))\n",
    "    res_correct_p=0.05/n_tests\n",
    "    res_corr_df['real_p_sig']=np.where(res_corr_df['real_p']<0.05,1,0)\n",
    "    res_corr_df['real_p_sig_corrected']=np.where(res_corr_df['real_p']<res_correct_p,1,0)\n",
    "    res_corr_df['r_outof_CI']=np.where((res_corr_df['real_r']<res_corr_df['r_perc_2_5']) | (res_corr_df['real_r']>res_corr_df['r_perc_97_5']) ,1,0)\n",
    "    col_to_keep=['column1','column2','real_p','real_r','r_perc_2_5','r_perc_97_5','real_p_sig','real_p_sig_corrected','r_outof_CI']\n",
    "    res_corr_df=res_corr_df[col_to_keep]\n",
    "    res_corr_df.set_index('column1',inplace=1)\n",
    "    res_corr_df=res_corr_df[~np.isnan(res_corr_df['real_r'])]\n",
    "    only_sig_corr_df=res_corr_df[(res_corr_df['real_p_sig']==1) & (res_corr_df['r_outof_CI']==1)]\n",
    "    \n",
    "    return res_corr_df,only_sig_corr_df\n",
    "\n",
    "\n",
    "def sigma(x):\n",
    "    sigma=0\n",
    "    for n in range(x):\n",
    "        sigma=+n\n",
    "    return sigma\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_corr_df,only_sig_corr_df =calc_sig_corr_all2all(combined_res_with_tags_df, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/net/mraid08/export/genie/Lab/Personal/ShaniBAF/TCR_demo_data/Pickles/res_corr_df', 'wb') as f:\n",
    "        pickle.dump(res_corr_df, f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print len(res_corr_df)\n",
    "print len(only_sig_corr_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "only_sig_corr_df[['column2','real_r','real_p','real_p_sig','real_p_sig_corrected','r_outof_CI']][:20]\n",
    "                                                                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanClonalAA_public95percCorrFig=draw_correlation_scatter(combined_res_with_tags_df['mean_clonal_aa_df_0'], \n",
    "                                                combined_res_with_tags_df['public95perc_df_0'], figsize = (6, 6), \n",
    "                                                xticks=None, yticks=None,\\\n",
    "                                                 xlim = None, ylim = None, r = True, ms=6, logd = False,\\\n",
    "                                                 xlab = 'Frequency', ylab = 'percent shared among >95% of samples', \n",
    "                                                filename = 'mean_clonal_aa_df_0-public95perc_df_0 correlation', title = 'mean_clonal_aa-public95perc correlation (productive)',\n",
    "                                                 color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                                                 contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meanClonalNT_public95percCorrFig=draw_correlation_scatter(combined_res_with_tags_df['mean_clonal_nt_df_0'], \n",
    "                                                combined_res_with_tags_df['public95perc_df_0'], figsize = (6, 6), \n",
    "                                                xticks=None, yticks=None,\\\n",
    "                                                 xlim = None, ylim = None, r = True, ms=6, logd = False,\\\n",
    "                                                 xlab = 'Frequency', ylab = 'percent shared among >95% of samples', \n",
    "                                                filename = 'mean_clonal_nt_df_0-public95perc_df_0 correlation', title = 'mean_clonal_nt-public95perc correlation (productive)',\n",
    "                                                 color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                                                 contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "percentPublic_CDR3ratio_prod_corrFig=draw_correlation_scatter(combined_res_with_tags_df['perc_public_df_0'], \n",
    "                                                combined_res_with_tags_df['cdr3PriToPub_df_0'], figsize = (6, 6), \n",
    "                                                xticks=None, yticks=None,\\\n",
    "                                                 xlim = None, ylim = None, r = True, ms=6, logd = False,\\\n",
    "                                                 xlab = 'percent public', ylab = 'CDR3 ratio', \n",
    "                                                filename = 'percent public-CDR3 ratio_prod_corr', title = 'percent public-CDR3 ratio correlation (productive)',\n",
    "                                                 color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                                                 contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_n1_n2_insertion_corr_prod_Fig=draw_correlation_scatter(combined_res_with_tags_df['mean_n1Insertion_df_0'], \n",
    "                                                combined_res_with_tags_df['mean_n2Insertion_df_0'], figsize = (6, 6), \n",
    "                                                xticks=None, yticks=None,\\\n",
    "                                                 xlim = None, ylim = None, r = True, ms=6, logd = False,\\\n",
    "                                                 xlab = 'mean n1Insertion (bps)', ylab = 'mean n2Insertion (bps)', \n",
    "                                                filename = 'mean_n1_n2_insertion_corr_prod', title = 'mean n1-n2 insertion correlation (productive)',\n",
    "                                                 color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                                                 contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_Jdel_N2ins_corr_prod_Fig=draw_correlation_scatter(combined_res_with_tags_df['mean_jDeletion_df_0'], \n",
    "                                                combined_res_with_tags_df['mean_n2Insertion_df_0'], figsize = (6, 6), \n",
    "                                                xticks=None, yticks=None,\\\n",
    "                                                 xlim = None, ylim = None, r = True, ms=6, logd = False,\\\n",
    "                                                 xlab = 'mean jDeletion (bps)', ylab = 'mean n2Insertion (bps)', \n",
    "                                                filename = 'mean_jDEL_n2_insertion_corr_prod', title = 'mean j deletion-n2 insertion correlation (productive)',\n",
    "                                                 color = \"#a0a0a0\", grid = True, dpi = 800, xticklabels = None, \n",
    "                                                 contour = False)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res_corr_df[res_corr_df.index=='mean_cdr3_df_0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print 'dsgfd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.8"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": false,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {
    "height": "738px",
    "left": "3.95313px",
    "right": "20px",
    "top": "118.953px",
    "width": "410px"
   },
   "toc_section_display": "block",
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
